{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWzNlE1rUW5w"
   },
   "source": [
    "# Organization:\n",
    "\n",
    "The assignment is divided into\n",
    "1. Original Code: the starter code provided, where the model is wrapped in a function *create_model*\n",
    "2. 5 Parts corresponding to each question asked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tBfi4wKTmEa"
   },
   "source": [
    "# Original Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RO9ywXXSM6u"
   },
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fUn2EAmISK_U"
   },
   "outputs": [],
   "source": [
    "# libraries (do not import additional libraries)\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxk2Im2KSRTh"
   },
   "source": [
    "Initial Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2_xNCQy0SaSd"
   },
   "outputs": [],
   "source": [
    "# parameters for this script\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "data_augmentation = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GA_Cs5yfSf3k"
   },
   "source": [
    "Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "AApoXP29SdaR",
    "outputId": "b10220cd-1829-4580-dd2c-bd467da81104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load the data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# normalize the data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# partition training set into training and validation set\n",
    "x_validate = x_train[40000:,:]\n",
    "x_train = x_train[:40000,:]\n",
    "y_validate = y_train[40000:,:]\n",
    "y_train = y_train[:40000,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rughu8IeSzmk"
   },
   "source": [
    "The Original CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nIoTAAnFSyfB"
   },
   "outputs": [],
   "source": [
    "# A convolutional neural network function\n",
    "\n",
    "def create_model(dropOut=True, data_augmentation=False, optName=\"rmsopt\", activation=\"relu\", size=3, epochs=20):\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, (size, size), padding='same',input_shape=x_train.shape[1:]))\n",
    "  model.add(Activation(activation))\n",
    "  if size == 3:\n",
    "    model.add(Conv2D(32, (size, size), padding='same'))\n",
    "    model.add(Activation(activation))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  if dropOut:\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Conv2D(64, (size, size), padding='same'))\n",
    "  model.add(Activation(activation))\n",
    "  if size == 3:\n",
    "    model.add(Conv2D(64, (size, size), padding='same'))\n",
    "    model.add(Activation(activation))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  if dropOut:\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(512))\n",
    "  model.add(Activation(activation))\n",
    "  if dropOut:\n",
    "    model.add(Dropout(0.5))\n",
    "  model.add(Dense(num_classes))\n",
    "  model.add(Activation('softmax'))\n",
    "\n",
    "  # initiate RMSprop optimizer\n",
    "  if optName == \"rmsopt\":\n",
    "    opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "  elif optName == \"adagrad\":\n",
    "    opt = keras.optimizers.Adagrad()\n",
    "  else:\n",
    "    opt = keras.optimizers.Adam()\n",
    "  # Compile the model before using it\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "  print(model.summary())\n",
    "\n",
    "\n",
    "  # create a callback that will save the best model while training\n",
    "  if dropOut:\n",
    "    appendix = \"DO\"\n",
    "  else:\n",
    "    appendix = \"noDO\"\n",
    "  if data_augmentation:\n",
    "    appendix2 = \"DA\"\n",
    "  else:\n",
    "    appendix2 = \"noDA\"\n",
    "  name = 'best_model_'+str(size)+\"_\"+appendix+\"_\"+appendix2+\"_\"+optName+\"_\"+activation\n",
    "  save_best_model = ModelCheckpoint(name, monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "  # train without data augmentation\n",
    "  if not data_augmentation:\n",
    "      print('Not using data augmentation.')\n",
    "      history = model.fit(x_train, y_train,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs,\n",
    "                          validation_data=(x_validate, y_validate),\n",
    "                          shuffle=True,\n",
    "                          callbacks=[save_best_model])\n",
    "\n",
    "  # train with data augmentation\n",
    "  else:\n",
    "      print('Using real-time data augmentation.')\n",
    "      # This will do preprocessing and realtime data augmentation:\n",
    "      datagen = ImageDataGenerator(\n",
    "          featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "          samplewise_center=False,  # set each sample mean to 0\n",
    "          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "          samplewise_std_normalization=False,  # divide each input by its std\n",
    "          zca_whitening=False,  # apply ZCA whitening\n",
    "          zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "          rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "          # randomly shift images horizontally (fraction of total width)\n",
    "          width_shift_range=0.1,\n",
    "          # randomly shift images vertically (fraction of total height)\n",
    "          height_shift_range=0.1,\n",
    "          shear_range=0.,  # set range for random shear\n",
    "          zoom_range=0.,  # set range for random zoom\n",
    "          channel_shift_range=0.,  # set range for random channel shifts\n",
    "          # set mode for filling points outside the input boundaries\n",
    "          fill_mode='nearest',\n",
    "          cval=0.,  # value used for fill_mode = \"constant\"\n",
    "          horizontal_flip=True,  # randomly flip images\n",
    "          vertical_flip=False,  # randomly flip images\n",
    "          # set rescaling factor (applied before any other transformation)\n",
    "          rescale=None,\n",
    "          # set function that will be applied on each input\n",
    "          preprocessing_function=None,\n",
    "          # image data format, either \"channels_first\" or \"channels_last\"\n",
    "          data_format=None,\n",
    "          # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "          validation_split=0.0)\n",
    "\n",
    "      # Compute quantities required for feature-wise normalization\n",
    "      # (std, mean, and principal components if ZCA whitening is applied).\n",
    "      datagen.fit(x_train)\n",
    "\n",
    "      # Fit the model on the batches generated by datagen.flow().\n",
    "      history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                          steps_per_epoch=math.ceil(x_train.shape[0]/batch_size),\n",
    "                          epochs=epochs,\n",
    "                          validation_data=(x_validate, y_validate),\n",
    "                          callbacks=[save_best_model])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2YKegSnSVaQ"
   },
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e9DXXrkDkgtf",
    "outputId": "84d3db36-1ea8-4839-c4ae-e061d319b48d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Not using data augmentation.\n",
      "Epoch 1/20\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.8210 - accuracy: 0.3384\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44730, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.8194 - accuracy: 0.3393 - val_loss: 1.5515 - val_accuracy: 0.4473\n",
      "Epoch 2/20\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.4915 - accuracy: 0.4598\n",
      "Epoch 00002: val_accuracy improved from 0.44730 to 0.50970, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.4916 - accuracy: 0.4599 - val_loss: 1.3796 - val_accuracy: 0.5097\n",
      "Epoch 3/20\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.3493 - accuracy: 0.5185\n",
      "Epoch 00003: val_accuracy improved from 0.50970 to 0.56140, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.3492 - accuracy: 0.5185 - val_loss: 1.2472 - val_accuracy: 0.5614\n",
      "Epoch 4/20\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.2340 - accuracy: 0.5617\n",
      "Epoch 00004: val_accuracy improved from 0.56140 to 0.60280, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.2337 - accuracy: 0.5620 - val_loss: 1.1425 - val_accuracy: 0.6028\n",
      "Epoch 5/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.1536 - accuracy: 0.5907\n",
      "Epoch 00005: val_accuracy improved from 0.60280 to 0.62710, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.1528 - accuracy: 0.5909 - val_loss: 1.0672 - val_accuracy: 0.6271\n",
      "Epoch 6/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.0882 - accuracy: 0.6162\n",
      "Epoch 00006: val_accuracy improved from 0.62710 to 0.63510, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.0880 - accuracy: 0.6162 - val_loss: 1.0533 - val_accuracy: 0.6351\n",
      "Epoch 7/20\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.0336 - accuracy: 0.6363\n",
      "Epoch 00007: val_accuracy improved from 0.63510 to 0.65430, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.0342 - accuracy: 0.6360 - val_loss: 0.9765 - val_accuracy: 0.6543\n",
      "Epoch 8/20\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.9889 - accuracy: 0.6550\n",
      "Epoch 00008: val_accuracy improved from 0.65430 to 0.67140, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.9884 - accuracy: 0.6551 - val_loss: 0.9302 - val_accuracy: 0.6714\n",
      "Epoch 9/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9493 - accuracy: 0.6677\n",
      "Epoch 00009: val_accuracy improved from 0.67140 to 0.69040, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.9493 - accuracy: 0.6677 - val_loss: 0.8910 - val_accuracy: 0.6904\n",
      "Epoch 10/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9095 - accuracy: 0.6801\n",
      "Epoch 00010: val_accuracy did not improve from 0.69040\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9093 - accuracy: 0.6802 - val_loss: 0.9129 - val_accuracy: 0.6814\n",
      "Epoch 11/20\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.8832 - accuracy: 0.6915\n",
      "Epoch 00011: val_accuracy improved from 0.69040 to 0.70510, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8831 - accuracy: 0.6913 - val_loss: 0.8498 - val_accuracy: 0.7051\n",
      "Epoch 12/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8488 - accuracy: 0.7045\n",
      "Epoch 00012: val_accuracy improved from 0.70510 to 0.71220, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8485 - accuracy: 0.7046 - val_loss: 0.8310 - val_accuracy: 0.7122\n",
      "Epoch 13/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8261 - accuracy: 0.7107\n",
      "Epoch 00013: val_accuracy improved from 0.71220 to 0.72050, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8262 - accuracy: 0.7106 - val_loss: 0.8131 - val_accuracy: 0.7205\n",
      "Epoch 14/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8056 - accuracy: 0.7199\n",
      "Epoch 00014: val_accuracy did not improve from 0.72050\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8055 - accuracy: 0.7200 - val_loss: 0.8080 - val_accuracy: 0.7162\n",
      "Epoch 15/20\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.7865 - accuracy: 0.7264\n",
      "Epoch 00015: val_accuracy improved from 0.72050 to 0.72250, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7861 - accuracy: 0.7264 - val_loss: 0.8172 - val_accuracy: 0.7225\n",
      "Epoch 16/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.7728 - accuracy: 0.7319\n",
      "Epoch 00016: val_accuracy improved from 0.72250 to 0.72920, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7731 - accuracy: 0.7319 - val_loss: 0.7800 - val_accuracy: 0.7292\n",
      "Epoch 17/20\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7540 - accuracy: 0.7390\n",
      "Epoch 00017: val_accuracy improved from 0.72920 to 0.73080, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7543 - accuracy: 0.7390 - val_loss: 0.7794 - val_accuracy: 0.7308\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7474 - accuracy: 0.7419\n",
      "Epoch 00018: val_accuracy improved from 0.73080 to 0.75380, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.7474 - accuracy: 0.7419 - val_loss: 0.7372 - val_accuracy: 0.7538\n",
      "Epoch 19/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.7306 - accuracy: 0.7498\n",
      "Epoch 00019: val_accuracy did not improve from 0.75380\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7309 - accuracy: 0.7497 - val_loss: 0.7307 - val_accuracy: 0.7514\n",
      "Epoch 20/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.7227 - accuracy: 0.7542\n",
      "Epoch 00020: val_accuracy did not improve from 0.75380\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7225 - accuracy: 0.7544 - val_loss: 0.7341 - val_accuracy: 0.7520\n",
      "Epoch 1/20\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 2.0003 - accuracy: 0.2862\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.32940, saving model to best_model_0\n",
      "INFO:tensorflow:Assets written to: best_model_0/assets\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.0003 - accuracy: 0.2862 - val_loss: 1.9034 - val_accuracy: 0.3294\n",
      "Epoch 2/20\n",
      "1232/1250 [============================>.] - ETA: 0s - loss: 1.8642 - accuracy: 0.3454\n",
      "Epoch 00002: val_accuracy improved from 0.32940 to 0.34600, saving model to best_model_0\n",
      "INFO:tensorflow:Assets written to: best_model_0/assets\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8637 - accuracy: 0.3457 - val_loss: 1.8696 - val_accuracy: 0.3460\n",
      "Epoch 3/20\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.8234 - accuracy: 0.3654\n",
      "Epoch 00003: val_accuracy improved from 0.34600 to 0.35470, saving model to best_model_0\n",
      "INFO:tensorflow:Assets written to: best_model_0/assets\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8236 - accuracy: 0.3651 - val_loss: 1.8407 - val_accuracy: 0.3547\n",
      "Epoch 4/20\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.8031 - accuracy: 0.3728\n",
      "Epoch 00004: val_accuracy improved from 0.35470 to 0.36010, saving model to best_model_0\n",
      "INFO:tensorflow:Assets written to: best_model_0/assets\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8028 - accuracy: 0.3727 - val_loss: 1.8372 - val_accuracy: 0.3601\n",
      "Epoch 5/20\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.7873 - accuracy: 0.3806\n",
      "Epoch 00005: val_accuracy improved from 0.36010 to 0.36650, saving model to best_model_0\n",
      "INFO:tensorflow:Assets written to: best_model_0/assets\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7869 - accuracy: 0.3807 - val_loss: 1.8153 - val_accuracy: 0.3665\n",
      "Epoch 6/20\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.7754 - accuracy: 0.3856\n",
      "Epoch 00006: val_accuracy improved from 0.36650 to 0.37320, saving model to best_model_0\n",
      "INFO:tensorflow:Assets written to: best_model_0/assets\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7758 - accuracy: 0.3852 - val_loss: 1.8064 - val_accuracy: 0.3732\n",
      "Epoch 7/20\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.7662 - accuracy: 0.3899\n",
      "Epoch 00007: val_accuracy improved from 0.37320 to 0.38190, saving model to best_model_0\n",
      "INFO:tensorflow:Assets written to: best_model_0/assets\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7663 - accuracy: 0.3899 - val_loss: 1.7895 - val_accuracy: 0.3819\n",
      "Epoch 8/20\n",
      "1238/1250 [============================>.] - ETA: 0s - loss: 1.7564 - accuracy: 0.3945\n",
      "Epoch 00008: val_accuracy did not improve from 0.38190\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7579 - accuracy: 0.3939 - val_loss: 1.8081 - val_accuracy: 0.3663\n",
      "Epoch 9/20\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 1.7510 - accuracy: 0.3944\n",
      "Epoch 00009: val_accuracy improved from 0.38190 to 0.38800, saving model to best_model_0\n",
      "INFO:tensorflow:Assets written to: best_model_0/assets\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7515 - accuracy: 0.3941 - val_loss: 1.7812 - val_accuracy: 0.3880\n",
      "Epoch 10/20\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.7454 - accuracy: 0.3970\n",
      "Epoch 00010: val_accuracy did not improve from 0.38800\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7455 - accuracy: 0.3972 - val_loss: 1.7846 - val_accuracy: 0.3835\n",
      "Epoch 11/20\n",
      "1234/1250 [============================>.] - ETA: 0s - loss: 1.7411 - accuracy: 0.4014\n",
      "Epoch 00011: val_accuracy did not improve from 0.38800\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7411 - accuracy: 0.4011 - val_loss: 1.8031 - val_accuracy: 0.3699\n",
      "Epoch 12/20\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.7352 - accuracy: 0.4027\n",
      "Epoch 00012: val_accuracy improved from 0.38800 to 0.39180, saving model to best_model_0\n",
      "INFO:tensorflow:Assets written to: best_model_0/assets\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7350 - accuracy: 0.4028 - val_loss: 1.7703 - val_accuracy: 0.3918\n",
      "Epoch 13/20\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.7302 - accuracy: 0.4052\n",
      "Epoch 00013: val_accuracy did not improve from 0.39180\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7301 - accuracy: 0.4051 - val_loss: 1.7786 - val_accuracy: 0.3826\n",
      "Epoch 14/20\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.7276 - accuracy: 0.4056\n",
      "Epoch 00014: val_accuracy did not improve from 0.39180\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7275 - accuracy: 0.4056 - val_loss: 1.7842 - val_accuracy: 0.3826\n",
      "Epoch 15/20\n",
      "1234/1250 [============================>.] - ETA: 0s - loss: 1.7231 - accuracy: 0.4048\n",
      "Epoch 00015: val_accuracy improved from 0.39180 to 0.39300, saving model to best_model_0\n",
      "INFO:tensorflow:Assets written to: best_model_0/assets\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7234 - accuracy: 0.4047 - val_loss: 1.7700 - val_accuracy: 0.3930\n",
      "Epoch 16/20\n",
      "1237/1250 [============================>.] - ETA: 0s - loss: 1.7209 - accuracy: 0.4070\n",
      "Epoch 00016: val_accuracy did not improve from 0.39300\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7203 - accuracy: 0.4069 - val_loss: 1.7771 - val_accuracy: 0.3852\n",
      "Epoch 17/20\n",
      "1238/1250 [============================>.] - ETA: 0s - loss: 1.7166 - accuracy: 0.4106\n",
      "Epoch 00017: val_accuracy did not improve from 0.39300\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7164 - accuracy: 0.4108 - val_loss: 1.7765 - val_accuracy: 0.3769\n",
      "Epoch 18/20\n",
      "1237/1250 [============================>.] - ETA: 0s - loss: 1.7144 - accuracy: 0.4108\n",
      "Epoch 00018: val_accuracy did not improve from 0.39300\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7142 - accuracy: 0.4108 - val_loss: 1.7678 - val_accuracy: 0.3895\n",
      "Epoch 19/20\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 1.7115 - accuracy: 0.4129\n",
      "Epoch 00019: val_accuracy did not improve from 0.39300\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7118 - accuracy: 0.4128 - val_loss: 1.7711 - val_accuracy: 0.3907\n",
      "Epoch 20/20\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.7077 - accuracy: 0.4132\n",
      "Epoch 00020: val_accuracy did not improve from 0.39300\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.7082 - accuracy: 0.4131 - val_loss: 1.7673 - val_accuracy: 0.3835\n",
      "Epoch 1/20\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.9921 - accuracy: 0.2798\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.33730, saving model to best_model_1\n",
      "INFO:tensorflow:Assets written to: best_model_1/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.9914 - accuracy: 0.2800 - val_loss: 1.8341 - val_accuracy: 0.3373\n",
      "Epoch 2/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.8305 - accuracy: 0.3460\n",
      "Epoch 00002: val_accuracy improved from 0.33730 to 0.37620, saving model to best_model_1\n",
      "INFO:tensorflow:Assets written to: best_model_1/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8303 - accuracy: 0.3461 - val_loss: 1.7538 - val_accuracy: 0.3762\n",
      "Epoch 3/20\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.7726 - accuracy: 0.3701\n",
      "Epoch 00003: val_accuracy improved from 0.37620 to 0.40170, saving model to best_model_1\n",
      "INFO:tensorflow:Assets written to: best_model_1/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7726 - accuracy: 0.3700 - val_loss: 1.7028 - val_accuracy: 0.4017\n",
      "Epoch 4/20\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.7363 - accuracy: 0.3846\n",
      "Epoch 00004: val_accuracy improved from 0.40170 to 0.40980, saving model to best_model_1\n",
      "INFO:tensorflow:Assets written to: best_model_1/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7363 - accuracy: 0.3844 - val_loss: 1.6857 - val_accuracy: 0.4098\n",
      "Epoch 5/20\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.7049 - accuracy: 0.3979\n",
      "Epoch 00005: val_accuracy improved from 0.40980 to 0.42450, saving model to best_model_1\n",
      "INFO:tensorflow:Assets written to: best_model_1/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7045 - accuracy: 0.3981 - val_loss: 1.6439 - val_accuracy: 0.4245\n",
      "Epoch 6/20\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.6797 - accuracy: 0.4047\n",
      "Epoch 00006: val_accuracy improved from 0.42450 to 0.42460, saving model to best_model_1\n",
      "INFO:tensorflow:Assets written to: best_model_1/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6798 - accuracy: 0.4048 - val_loss: 1.6349 - val_accuracy: 0.4246\n",
      "Epoch 7/20\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.6566 - accuracy: 0.4172\n",
      "Epoch 00007: val_accuracy improved from 0.42460 to 0.43960, saving model to best_model_1\n",
      "INFO:tensorflow:Assets written to: best_model_1/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6567 - accuracy: 0.4171 - val_loss: 1.6010 - val_accuracy: 0.4396\n",
      "Epoch 8/20\n",
      "1235/1250 [============================>.] - ETA: 0s - loss: 1.6407 - accuracy: 0.4239\n",
      "Epoch 00008: val_accuracy did not improve from 0.43960\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6413 - accuracy: 0.4237 - val_loss: 1.6276 - val_accuracy: 0.4321\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6258 - accuracy: 0.4281\n",
      "Epoch 00009: val_accuracy improved from 0.43960 to 0.45720, saving model to best_model_1\n",
      "INFO:tensorflow:Assets written to: best_model_1/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6258 - accuracy: 0.4281 - val_loss: 1.5689 - val_accuracy: 0.4572\n",
      "Epoch 10/20\n",
      "1233/1250 [============================>.] - ETA: 0s - loss: 1.6071 - accuracy: 0.4354\n",
      "Epoch 00010: val_accuracy improved from 0.45720 to 0.46350, saving model to best_model_1\n",
      "INFO:tensorflow:Assets written to: best_model_1/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6065 - accuracy: 0.4356 - val_loss: 1.5504 - val_accuracy: 0.4635\n",
      "Epoch 11/20\n",
      "1232/1250 [============================>.] - ETA: 0s - loss: 1.5937 - accuracy: 0.4387\n",
      "Epoch 00011: val_accuracy did not improve from 0.46350\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5934 - accuracy: 0.4382 - val_loss: 1.5500 - val_accuracy: 0.4536\n",
      "Epoch 12/20\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.5832 - accuracy: 0.4433\n",
      "Epoch 00012: val_accuracy did not improve from 0.46350\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5829 - accuracy: 0.4435 - val_loss: 1.5363 - val_accuracy: 0.4628\n",
      "Epoch 13/20\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.5721 - accuracy: 0.4449\n",
      "Epoch 00013: val_accuracy improved from 0.46350 to 0.46640, saving model to best_model_1\n",
      "INFO:tensorflow:Assets written to: best_model_1/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5716 - accuracy: 0.4453 - val_loss: 1.5282 - val_accuracy: 0.4664\n",
      "Epoch 14/20\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.5596 - accuracy: 0.4517\n",
      "Epoch 00014: val_accuracy improved from 0.46640 to 0.46680, saving model to best_model_1\n",
      "INFO:tensorflow:Assets written to: best_model_1/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5601 - accuracy: 0.4518 - val_loss: 1.5237 - val_accuracy: 0.4668\n",
      "Epoch 15/20\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.5529 - accuracy: 0.4518\n",
      "Epoch 00015: val_accuracy improved from 0.46680 to 0.47810, saving model to best_model_1\n",
      "INFO:tensorflow:Assets written to: best_model_1/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5535 - accuracy: 0.4515 - val_loss: 1.5178 - val_accuracy: 0.4781\n",
      "Epoch 16/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.5435 - accuracy: 0.4583\n",
      "Epoch 00016: val_accuracy did not improve from 0.47810\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5437 - accuracy: 0.4583 - val_loss: 1.5039 - val_accuracy: 0.4776\n",
      "Epoch 17/20\n",
      "1232/1250 [============================>.] - ETA: 0s - loss: 1.5349 - accuracy: 0.4622\n",
      "Epoch 00017: val_accuracy improved from 0.47810 to 0.48960, saving model to best_model_1\n",
      "INFO:tensorflow:Assets written to: best_model_1/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.5340 - accuracy: 0.4626 - val_loss: 1.4910 - val_accuracy: 0.4896\n",
      "Epoch 18/20\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.5268 - accuracy: 0.4656\n",
      "Epoch 00018: val_accuracy did not improve from 0.48960\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5269 - accuracy: 0.4655 - val_loss: 1.5139 - val_accuracy: 0.4791\n",
      "Epoch 19/20\n",
      "1237/1250 [============================>.] - ETA: 0s - loss: 1.5169 - accuracy: 0.4644\n",
      "Epoch 00019: val_accuracy did not improve from 0.48960\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5167 - accuracy: 0.4642 - val_loss: 1.4950 - val_accuracy: 0.4829\n",
      "Epoch 20/20\n",
      "1237/1250 [============================>.] - ETA: 0s - loss: 1.5111 - accuracy: 0.4671\n",
      "Epoch 00020: val_accuracy did not improve from 0.48960\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5105 - accuracy: 0.4674 - val_loss: 1.4752 - val_accuracy: 0.4896\n",
      "Epoch 1/20\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 2.0904 - accuracy: 0.2325\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.33520, saving model to best_model_2\n",
      "INFO:tensorflow:Assets written to: best_model_2/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 2.0893 - accuracy: 0.2333 - val_loss: 1.8804 - val_accuracy: 0.3352\n",
      "Epoch 2/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.9130 - accuracy: 0.3067\n",
      "Epoch 00002: val_accuracy improved from 0.33520 to 0.35520, saving model to best_model_2\n",
      "INFO:tensorflow:Assets written to: best_model_2/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.9131 - accuracy: 0.3066 - val_loss: 1.8087 - val_accuracy: 0.3552\n",
      "Epoch 3/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.8556 - accuracy: 0.3314\n",
      "Epoch 00003: val_accuracy improved from 0.35520 to 0.38640, saving model to best_model_2\n",
      "INFO:tensorflow:Assets written to: best_model_2/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8555 - accuracy: 0.3314 - val_loss: 1.7414 - val_accuracy: 0.3864\n",
      "Epoch 4/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.8194 - accuracy: 0.3452\n",
      "Epoch 00004: val_accuracy improved from 0.38640 to 0.39090, saving model to best_model_2\n",
      "INFO:tensorflow:Assets written to: best_model_2/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8191 - accuracy: 0.3456 - val_loss: 1.7293 - val_accuracy: 0.3909\n",
      "Epoch 5/20\n",
      "1238/1250 [============================>.] - ETA: 0s - loss: 1.7902 - accuracy: 0.3597\n",
      "Epoch 00005: val_accuracy improved from 0.39090 to 0.41530, saving model to best_model_2\n",
      "INFO:tensorflow:Assets written to: best_model_2/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7899 - accuracy: 0.3598 - val_loss: 1.6820 - val_accuracy: 0.4153\n",
      "Epoch 6/20\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.7686 - accuracy: 0.3704\n",
      "Epoch 00006: val_accuracy improved from 0.41530 to 0.41910, saving model to best_model_2\n",
      "INFO:tensorflow:Assets written to: best_model_2/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7689 - accuracy: 0.3704 - val_loss: 1.6680 - val_accuracy: 0.4191\n",
      "Epoch 7/20\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.7482 - accuracy: 0.3761\n",
      "Epoch 00007: val_accuracy improved from 0.41910 to 0.42160, saving model to best_model_2\n",
      "INFO:tensorflow:Assets written to: best_model_2/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7483 - accuracy: 0.3760 - val_loss: 1.6570 - val_accuracy: 0.4216\n",
      "Epoch 8/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.7348 - accuracy: 0.3815\n",
      "Epoch 00008: val_accuracy improved from 0.42160 to 0.42340, saving model to best_model_2\n",
      "INFO:tensorflow:Assets written to: best_model_2/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7347 - accuracy: 0.3814 - val_loss: 1.6519 - val_accuracy: 0.4234\n",
      "Epoch 9/20\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.7175 - accuracy: 0.3886\n",
      "Epoch 00009: val_accuracy improved from 0.42340 to 0.42530, saving model to best_model_2\n",
      "INFO:tensorflow:Assets written to: best_model_2/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7177 - accuracy: 0.3886 - val_loss: 1.6275 - val_accuracy: 0.4253\n",
      "Epoch 10/20\n",
      "1235/1250 [============================>.] - ETA: 0s - loss: 1.7139 - accuracy: 0.3899\n",
      "Epoch 00010: val_accuracy did not improve from 0.42530\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7136 - accuracy: 0.3900 - val_loss: 1.6253 - val_accuracy: 0.4231\n",
      "Epoch 11/20\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.7056 - accuracy: 0.3960\n",
      "Epoch 00011: val_accuracy improved from 0.42530 to 0.42670, saving model to best_model_2\n",
      "INFO:tensorflow:Assets written to: best_model_2/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7059 - accuracy: 0.3958 - val_loss: 1.6286 - val_accuracy: 0.4267\n",
      "Epoch 12/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.6901 - accuracy: 0.4009\n",
      "Epoch 00012: val_accuracy improved from 0.42670 to 0.43000, saving model to best_model_2\n",
      "INFO:tensorflow:Assets written to: best_model_2/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6903 - accuracy: 0.4008 - val_loss: 1.6112 - val_accuracy: 0.4300\n",
      "Epoch 13/20\n",
      "1236/1250 [============================>.] - ETA: 0s - loss: 1.6872 - accuracy: 0.3998\n",
      "Epoch 00013: val_accuracy improved from 0.43000 to 0.45350, saving model to best_model_2\n",
      "INFO:tensorflow:Assets written to: best_model_2/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6871 - accuracy: 0.3998 - val_loss: 1.5795 - val_accuracy: 0.4535\n",
      "Epoch 14/20\n",
      "1236/1250 [============================>.] - ETA: 0s - loss: 1.6747 - accuracy: 0.4049\n",
      "Epoch 00014: val_accuracy did not improve from 0.45350\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6758 - accuracy: 0.4049 - val_loss: 1.5701 - val_accuracy: 0.4513\n",
      "Epoch 15/20\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.6711 - accuracy: 0.4101\n",
      "Epoch 00015: val_accuracy did not improve from 0.45350\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.6710 - accuracy: 0.4104 - val_loss: 1.5717 - val_accuracy: 0.4529\n",
      "Epoch 16/20\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.6642 - accuracy: 0.4115\n",
      "Epoch 00016: val_accuracy did not improve from 0.45350\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6637 - accuracy: 0.4118 - val_loss: 1.5704 - val_accuracy: 0.4532\n",
      "Epoch 17/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.6586 - accuracy: 0.4150\n",
      "Epoch 00017: val_accuracy did not improve from 0.45350\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6586 - accuracy: 0.4151 - val_loss: 1.5856 - val_accuracy: 0.4306\n",
      "Epoch 18/20\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.6502 - accuracy: 0.4122\n",
      "Epoch 00018: val_accuracy improved from 0.45350 to 0.45840, saving model to best_model_2\n",
      "INFO:tensorflow:Assets written to: best_model_2/assets\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6488 - accuracy: 0.4126 - val_loss: 1.5561 - val_accuracy: 0.4584\n",
      "Epoch 19/20\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.6398 - accuracy: 0.4191\n",
      "Epoch 00019: val_accuracy did not improve from 0.45840\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6398 - accuracy: 0.4191 - val_loss: 1.5581 - val_accuracy: 0.4528\n",
      "Epoch 20/20\n",
      "1236/1250 [============================>.] - ETA: 0s - loss: 1.6363 - accuracy: 0.4214\n",
      "Epoch 00020: val_accuracy did not improve from 0.45840\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.6359 - accuracy: 0.4214 - val_loss: 1.5448 - val_accuracy: 0.4570\n",
      "Epoch 1/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 2.1513 - accuracy: 0.1902\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.31190, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.1513 - accuracy: 0.1902 - val_loss: 1.9400 - val_accuracy: 0.3119\n",
      "Epoch 2/20\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.9723 - accuracy: 0.2742\n",
      "Epoch 00002: val_accuracy improved from 0.31190 to 0.33640, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9722 - accuracy: 0.2742 - val_loss: 1.8565 - val_accuracy: 0.3364\n",
      "Epoch 3/20\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.9159 - accuracy: 0.2992\n",
      "Epoch 00003: val_accuracy improved from 0.33640 to 0.34860, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.9157 - accuracy: 0.2995 - val_loss: 1.8187 - val_accuracy: 0.3486\n",
      "Epoch 4/20\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.8822 - accuracy: 0.3154\n",
      "Epoch 00004: val_accuracy improved from 0.34860 to 0.36310, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8820 - accuracy: 0.3154 - val_loss: 1.7842 - val_accuracy: 0.3631\n",
      "Epoch 5/20\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.8486 - accuracy: 0.3296\n",
      "Epoch 00005: val_accuracy improved from 0.36310 to 0.38360, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8485 - accuracy: 0.3297 - val_loss: 1.7532 - val_accuracy: 0.3836\n",
      "Epoch 6/20\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.8247 - accuracy: 0.3412\n",
      "Epoch 00006: val_accuracy improved from 0.38360 to 0.39100, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8253 - accuracy: 0.3409 - val_loss: 1.7361 - val_accuracy: 0.3910\n",
      "Epoch 7/20\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.8082 - accuracy: 0.3517\n",
      "Epoch 00007: val_accuracy improved from 0.39100 to 0.39110, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.8086 - accuracy: 0.3516 - val_loss: 1.7241 - val_accuracy: 0.3911\n",
      "Epoch 8/20\n",
      "1236/1250 [============================>.] - ETA: 0s - loss: 1.7922 - accuracy: 0.3548\n",
      "Epoch 00008: val_accuracy improved from 0.39110 to 0.39880, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7915 - accuracy: 0.3553 - val_loss: 1.7101 - val_accuracy: 0.3988\n",
      "Epoch 9/20\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.7808 - accuracy: 0.3581\n",
      "Epoch 00009: val_accuracy improved from 0.39880 to 0.40830, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7805 - accuracy: 0.3581 - val_loss: 1.7254 - val_accuracy: 0.4083\n",
      "Epoch 10/20\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.7618 - accuracy: 0.3674\n",
      "Epoch 00010: val_accuracy did not improve from 0.40830\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7619 - accuracy: 0.3674 - val_loss: 1.7172 - val_accuracy: 0.3983\n",
      "Epoch 11/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.7515 - accuracy: 0.3692\n",
      "Epoch 00011: val_accuracy improved from 0.40830 to 0.41370, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7518 - accuracy: 0.3689 - val_loss: 1.6863 - val_accuracy: 0.4137\n",
      "Epoch 12/20\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.7383 - accuracy: 0.3767\n",
      "Epoch 00012: val_accuracy improved from 0.41370 to 0.41910, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7389 - accuracy: 0.3764 - val_loss: 1.6881 - val_accuracy: 0.4191\n",
      "Epoch 13/20\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.7346 - accuracy: 0.3806\n",
      "Epoch 00013: val_accuracy improved from 0.41910 to 0.42180, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7344 - accuracy: 0.3806 - val_loss: 1.6799 - val_accuracy: 0.4218\n",
      "Epoch 14/20\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.7331 - accuracy: 0.3789\n",
      "Epoch 00014: val_accuracy did not improve from 0.42180\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7330 - accuracy: 0.3787 - val_loss: 1.6794 - val_accuracy: 0.4146\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.7172 - accuracy: 0.3869\n",
      "Epoch 00015: val_accuracy improved from 0.42180 to 0.42230, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.7172 - accuracy: 0.3869 - val_loss: 1.6861 - val_accuracy: 0.4223\n",
      "Epoch 16/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.7158 - accuracy: 0.3854\n",
      "Epoch 00016: val_accuracy improved from 0.42230 to 0.43070, saving model to best_model_3\n",
      "INFO:tensorflow:Assets written to: best_model_3/assets\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.7158 - accuracy: 0.3853 - val_loss: 1.6754 - val_accuracy: 0.4307\n",
      "Epoch 17/20\n",
      "1236/1250 [============================>.] - ETA: 0s - loss: 1.7090 - accuracy: 0.3896\n",
      "Epoch 00017: val_accuracy did not improve from 0.43070\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7109 - accuracy: 0.3890 - val_loss: 1.6977 - val_accuracy: 0.4275\n",
      "Epoch 18/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.7051 - accuracy: 0.3895\n",
      "Epoch 00018: val_accuracy did not improve from 0.43070\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7052 - accuracy: 0.3895 - val_loss: 1.7216 - val_accuracy: 0.4160\n",
      "Epoch 19/20\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.7083 - accuracy: 0.3917\n",
      "Epoch 00019: val_accuracy did not improve from 0.43070\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7081 - accuracy: 0.3917 - val_loss: 1.6815 - val_accuracy: 0.4260\n",
      "Epoch 20/20\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.6973 - accuracy: 0.3978\n",
      "Epoch 00020: val_accuracy did not improve from 0.43070\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.6970 - accuracy: 0.3976 - val_loss: 1.7153 - val_accuracy: 0.4250\n",
      "Epoch 1/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 2.2198 - accuracy: 0.1508\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.23410, saving model to best_model_4\n",
      "INFO:tensorflow:Assets written to: best_model_4/assets\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.2195 - accuracy: 0.1509 - val_loss: 2.0426 - val_accuracy: 0.2341\n",
      "Epoch 2/20\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 2.0392 - accuracy: 0.2279\n",
      "Epoch 00002: val_accuracy improved from 0.23410 to 0.29590, saving model to best_model_4\n",
      "INFO:tensorflow:Assets written to: best_model_4/assets\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.0388 - accuracy: 0.2278 - val_loss: 1.9309 - val_accuracy: 0.2959\n",
      "Epoch 3/20\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.9730 - accuracy: 0.2631\n",
      "Epoch 00003: val_accuracy improved from 0.29590 to 0.33440, saving model to best_model_4\n",
      "INFO:tensorflow:Assets written to: best_model_4/assets\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.9729 - accuracy: 0.2632 - val_loss: 1.8682 - val_accuracy: 0.3344\n",
      "Epoch 4/20\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.9350 - accuracy: 0.2876\n",
      "Epoch 00004: val_accuracy improved from 0.33440 to 0.35370, saving model to best_model_4\n",
      "INFO:tensorflow:Assets written to: best_model_4/assets\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.9353 - accuracy: 0.2876 - val_loss: 1.8510 - val_accuracy: 0.3537\n",
      "Epoch 5/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.9029 - accuracy: 0.3007\n",
      "Epoch 00005: val_accuracy did not improve from 0.35370\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 1.9029 - accuracy: 0.3007 - val_loss: 1.8515 - val_accuracy: 0.3379\n",
      "Epoch 6/20\n",
      "1237/1250 [============================>.] - ETA: 0s - loss: 1.8782 - accuracy: 0.3137\n",
      "Epoch 00006: val_accuracy improved from 0.35370 to 0.36600, saving model to best_model_4\n",
      "INFO:tensorflow:Assets written to: best_model_4/assets\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.8786 - accuracy: 0.3138 - val_loss: 1.8159 - val_accuracy: 0.3660\n",
      "Epoch 7/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.8619 - accuracy: 0.3211\n",
      "Epoch 00007: val_accuracy did not improve from 0.36600\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 1.8622 - accuracy: 0.3211 - val_loss: 1.8163 - val_accuracy: 0.3645\n",
      "Epoch 8/20\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.8463 - accuracy: 0.3280\n",
      "Epoch 00008: val_accuracy did not improve from 0.36600\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 1.8459 - accuracy: 0.3280 - val_loss: 1.8363 - val_accuracy: 0.3553\n",
      "Epoch 9/20\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.8411 - accuracy: 0.3330\n",
      "Epoch 00009: val_accuracy improved from 0.36600 to 0.37450, saving model to best_model_4\n",
      "INFO:tensorflow:Assets written to: best_model_4/assets\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.8410 - accuracy: 0.3331 - val_loss: 1.8217 - val_accuracy: 0.3745\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.8273 - accuracy: 0.3365\n",
      "Epoch 00010: val_accuracy improved from 0.37450 to 0.38150, saving model to best_model_4\n",
      "INFO:tensorflow:Assets written to: best_model_4/assets\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.8273 - accuracy: 0.3365 - val_loss: 1.8356 - val_accuracy: 0.3815\n",
      "Epoch 11/20\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 1.8211 - accuracy: 0.3416\n",
      "Epoch 00011: val_accuracy did not improve from 0.38150\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.8214 - accuracy: 0.3414 - val_loss: 1.8920 - val_accuracy: 0.3490\n",
      "Epoch 12/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.8110 - accuracy: 0.3465\n",
      "Epoch 00012: val_accuracy improved from 0.38150 to 0.38470, saving model to best_model_4\n",
      "INFO:tensorflow:Assets written to: best_model_4/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.8107 - accuracy: 0.3465 - val_loss: 1.8414 - val_accuracy: 0.3847\n",
      "Epoch 13/20\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 1.8040 - accuracy: 0.3471\n",
      "Epoch 00013: val_accuracy did not improve from 0.38470\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 1.8039 - accuracy: 0.3472 - val_loss: 1.8553 - val_accuracy: 0.3810\n",
      "Epoch 14/20\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.8021 - accuracy: 0.3520\n",
      "Epoch 00014: val_accuracy did not improve from 0.38470\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 1.8023 - accuracy: 0.3519 - val_loss: 1.8667 - val_accuracy: 0.3715\n",
      "Epoch 15/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.7870 - accuracy: 0.3588\n",
      "Epoch 00015: val_accuracy improved from 0.38470 to 0.38600, saving model to best_model_4\n",
      "INFO:tensorflow:Assets written to: best_model_4/assets\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.7873 - accuracy: 0.3588 - val_loss: 1.8388 - val_accuracy: 0.3860\n",
      "Epoch 16/20\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.7861 - accuracy: 0.3539\n",
      "Epoch 00016: val_accuracy did not improve from 0.38600\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 1.7855 - accuracy: 0.3541 - val_loss: 1.8472 - val_accuracy: 0.3807\n",
      "Epoch 17/20\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.7898 - accuracy: 0.3588\n",
      "Epoch 00017: val_accuracy did not improve from 0.38600\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 1.7898 - accuracy: 0.3589 - val_loss: 1.8817 - val_accuracy: 0.3718\n",
      "Epoch 18/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.7869 - accuracy: 0.3609\n",
      "Epoch 00018: val_accuracy did not improve from 0.38600\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 1.7868 - accuracy: 0.3609 - val_loss: 1.8726 - val_accuracy: 0.3589\n",
      "Epoch 19/20\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.7776 - accuracy: 0.3637\n",
      "Epoch 00019: val_accuracy did not improve from 0.38600\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 1.7778 - accuracy: 0.3637 - val_loss: 1.8671 - val_accuracy: 0.3766\n",
      "Epoch 20/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.7800 - accuracy: 0.3655\n",
      "Epoch 00020: val_accuracy did not improve from 0.38600\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7799 - accuracy: 0.3655 - val_loss: 1.8637 - val_accuracy: 0.3799\n"
     ]
    }
   ],
   "source": [
    "# original model\n",
    "history = create_model()\n",
    "\n",
    "# dense nn 0-4 layers\n",
    "dense_nn=[]\n",
    "for i in range(5):\n",
    "  model = Sequential()\n",
    "  model.add(Flatten())\n",
    "  for j in range(i):\n",
    "      model.add(Dense(512))\n",
    "      model.add(Activation('relu'))\n",
    "      model.add(Dropout(0.5))\n",
    "  model.add(Dense(num_classes))\n",
    "  model.add(Activation('softmax'))\n",
    "  # initiate RMSprop optimizer\n",
    "  opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "  # Compile the model before using it\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "  # create a callback that will save the best model while training\n",
    "  best_model = ModelCheckpoint('best_model_'+str(i), monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "\n",
    "  history2 = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_validate, y_validate),\n",
    "                        shuffle=True,\n",
    "                        callbacks=[best_model])\n",
    "  dense_nn.append(history2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 777
    },
    "id": "k1tGstrKThJC",
    "outputId": "dcfc02a1-f705-4780-e182-6a0f2b9a0ad9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd5gcxZm435ocN+ekXSWUJZQQSYBIwke4A0yysXWAcQZkEL4zcGCbYLA5w9n458M+H5wNRgYbGzDB2CBkBAhJKAAyAiGtdlfaHCenrt8fPTs7G7QaSTuaDfU+Tz1VXV3d/fVo9X3VVV99JaSUKBQKhWLiYsi0AAqFQqHILMoQKBQKxQRHGQKFQqGY4ChDoFAoFBMcZQgUCoVigqMMgUKhUExwlCFQjHmEED8XQtwx0m0ViomCUOsIFJlECFELXCel/GumZVEoJirqi0AxqhFCmDItw1hA/U6Ko0EZAkXGEEL8GqgCnhdCeIUQtwohqoUQUghxrRCiDngt3vZpIUSTEKJbCLFeCDE76T6PCSHujpdPF0I0CCFuFkK0CCEahRD/eoRt84UQzwsheoQQm4QQdwsh3hzmfYaT0S6EeFAIsS9+/k0hhD1+7hQhxFtCiC4hRL0QYlW8fp0Q4rqke6xKfn78d/q6EOIT4JN43cPxe/QIIbYIIU5Nam8UQnxHCPGpEMITP18phHhECPHggHd5TgixOsV/SsUYRxkCRcaQUl4N1AEXSCldUsoHkk6fBswEzo0fvwRMA4qA94Anhrl1CZANlAPXAo8IIXKPoO0jgC/e5ovxNBzDyfgjYBFwEpAH3ApoQohJ8et+AhQCC4Bth3hOMv8MnADMih9vit8jD3gSeFoIYYuf+xZwJfAZIAu4BvADjwNXCiEMAEKIAuCs+PWKiYCUUiWVMpaAWuCspONqQAKTh7kmJ94mO378GHB3vHw6EABMSe1bgGWH0xYwAhHguKRzdwNvpvheCRnRO1wBYP4Q7f4dePYg91iHPn/Se7wq+fnx+684hBydvc8FdgEXHaTdP4Cz4+VvAC9m+m9DpWOX1BeBYrRS31uID2n8ID6k0YNuPAAKDnJtu5QymnTsB1yH2bYQMCXLMaDcj0PIWADYgE+HuLTyIPWp0k8mIcQtQoh/xIefutANUe/vNNyzHgc+Hy9/Hvj1UcikGGMoQ6DINAdzW0uuvwq4CH24Ihv9qwFApE8sWoEoUJFUVzlM++FkbAOCwJQhrqs/SD3ow1KOpOOSIdokfqf4fMCtwGVArpQyB+im73ca7lm/AS4SQsxHH5L740HaKcYhyhAoMk0zMPkQbdxACGhHV4z3plsoKWUM+ANwlxDCIYSYAXzhSGSUUmrAr4D/FEKUxb8eThRCWNHnEc4SQlwmhDDFJ6gXxC/dBlwcf/5U9DmM4XCjG69WwCSE+A/0uYBefgl8XwgxTejME0Lkx2VsQJ9f+DXweyll4JA/kmLcoAyBItPcB9we95i55SBt/g/YB+wHdgLvHCPZvoHeu29CV5C/RVf2Q3EoGW8B3kdXth3A/YBBSlmHPnl7c7x+GzA/fs2PgTC6sXyc4SfIAV4BXgY+jssSpP/Q0X8CvwP+AvQA/wPYk84/DsxFDQtNONSCMoUiRYQQ9wMlUspDeQ+NSYQQy9GHiCZJpRgmFOqLQKE4CEKIGfHhEyGEWIo+NPNspuVKB0IIM3Aj8EtlBCYeyhAoFAfHjT5P4APWAg8Cf8qoRGlACDET6AJKgYcyLI4iA6ihIYVCoZjgqC8ChUKhmOCMuUBVBQUFsrq6OtNiKBQKxZhiy5YtbVLKwqHOjTlDUF1dzebNmzMthkKhUIwphBD7DnZODQ0pFArFBEcZAoVCoZjgKEOgUCgUE5wxN0cwFJFIhIaGBoLBYKZFyTg2m42KigrMZnOmRVEoFGOEcWEIGhoacLvdVFdXI0Q6A1KObqSUtLe309DQQE1NTabFUSgUY4RxMTQUDAbJz8+f0EYAQAhBfn6++jJSKBSHxbgwBMCENwK9qN9BoVAcLuNiaEihUCjGE+GoRqs3RKtHTy2eIK2eECtmFDGvImfEn6cMwQjS1NTETTfdxKZNm8jJyaG4uJiHHnqI6dOnZ1o0hUKRYaSU9ASjtHqCtHiSlXx/Zd/iCdHljwx5j3yXVRmC0YyUkn/5l3/hi1/8Ik899RQA27dvp7m5WRkChWICEY5q7Gv3sbvFq6dWPd/T6iMQiQ1qbzEZKHJbKXRbqSlwsrQmjyK3jUK3NVFf5LaR77JgNqZnNF8ZghHi9ddfx2w285WvfCVRN3/+fKSUrFmzhpdeegkhBLfffjuXX34569at46677qKgoIAPPviARYsW8Zvf/IZXXnmF//mf/+Hpp58GYN26dfzoRz/ihRdeyNSrKRSKIfCFonwaV/LJSn9fu5+Y1hfVuTzHzpQiF0tr8ijPsVOYUO5WCt02smymjM/tjTtD8N3nP2TngZ4RveessizuvGD2sG16lflA/vCHP7Bt2za2b99OW1sbS5YsYfny5QBs3bqVDz/8kLKyMk4++WQ2bNjAWWedxfXXX4/P58PpdLJ27VquuOKKEX0fhUIxNDFN4g1F8QQjeILRfuXuQIS9bXpP/9MWLwe6+7zzTAZBdYGT6UVuPjOnlKlFLqYWuZhc6MRhGf1qdvRLOMZ58803ufLKKzEajRQXF3PaaaexadMmsrKyWLp0KRUVFQAsWLCA2tpaTjnlFFauXMnzzz/PpZdeyp///GceeOCBDL+FQjE28Yai1Lb52NvmY1+7jy5/JK7co/QE+8qeYARvMIovPHjoJhmHxciUQhcnTM5napGLKYW6wp+U70jbsM2xYNwZgkP13NPF7NmzeeaZZw7rGqvVmigbjUai0SgAV1xxBT/96U/Jy8tj8eLFuN3uEZVVoRhPhKIx6tr97GnzJZR+b7nFE+rX1m424raZcNtMuGxmsmwmSrNtuKwm3DZz/JwZt9WUKLvi7bNsZvKdFgyG8eeiPe4MQaZYsWIF3/nOd3j00Ue5/vrrAdixYwc5OTmsXbuWL37xi3R0dLB+/Xp++MMf8tFHHx30XqeddhrXXHMNv/jFL9SwkEKBruwbu4LUtuuKvjau7Pe2+TjQFSBpSJ4Cl4XqfCenTS+kptBJTb6TmkInk/Kc2C3GzL3EKEYZghFCCMGzzz7LTTfdxP3334/NZqO6upqHHnoIr9fL/PnzEULwwAMPUFJSMqwhMBqNnH/++Tz22GM8/vjjx/AtFIpjTygao6k7SGN3kKbuIAe6A3reFaSpRy+3ecP9rnFbTdQUOllYlcslCyuYXOikOt9JdYGTbLuKs3W4jLk9ixcvXiwHbkzzj3/8g5kzZ2ZIotGH+j0UowUpJa3eEPUdfuo7AoOUfGNXkHZfeNB1WTYTZTl2SrJtlGbbKc22UZJtozrfSU2BkwKXJeOeNmMNIcQWKeXioc6pLwKFQnFUBMIx6jv91Hf4qYun5HIwovVrn203U5ptozTbxtzynES5NNtOaY6NkiwbTqtSTccS9WsrFIpD0hOMsKvJw772wYq+dcCErNNipDLPQXW+k+XTCqnKd1CZ66Ayz05ptl0p+VGI+hdRKBT9aOkJ8uGBHj480B3Pe6jr8CfOGwSUZtupynOw4rgiKvPsVOY5qIqnPKcathlrKEOgUExQNE1S1+EfpPTbvH09/Op8B3PKs7h8SSWzSrOoKXBSlmPHYhq7PvOKwShDoFBMADzBCPva/exs7GHngXhq7MEb0teumAyCacVuTj+ukNllWcwuy2ZmqRu3TXngTASUIVAoxjhSSroDERo6A/HkZ3+XXt4fP+4JRhPtHRYjM0uzuHhheULpTyt2YTUpH/uJSloNgRBiJfAwYAR+KaX8wYDzPwbOiB86gCIp5cjHWD0GvPzyy9x4443EYjGuu+46/u3f/m1Qm1WrVvHGG2+QlZVFIBBg2bJl3HvvvYkwE9XV1SxatIjf//73ADzzzDO88MILPPbYYzz22GNcc801bNu2jXnz5gEwZ84cXnjhBaqrq4/ZeyoyQySm8VGjh7oO/5CKfmBoBKfFSEWug/JcO4urcynPsVOR62BGqZvqfCfGcbg6VnHkpM0QCCGMwCPA2UADsEkI8ZyUcmdvGynl6qT23wSOT5c86SQWi/H1r3+dV199lYqKCpYsWcKFF17IrFmzBrX94Q9/yKWXXoqUkoceeogVK1bwwQcfYLFYANiyZQs7d+4c8tqKigruuece1q5dm/Z3UmQWKSW17X7+/kkrf/+kjbc/bU8M44DuZ1+R66Aq38FJU/MTir4i105Frp1su1lN2CpSJp1fBEuB3VLKPQBCiKeAi4CdB2l/JXBnGuVJG++++y5Tp05l8uTJgB4r6E9/+tOQyrwXIQSrV6/m2Wef5aWXXuKiiy4C4Oabb+aee+7hiSeeGHTN+eefz/r169m1axfHHXdcel5GkTG6/GE27G7nzd2trP+4jf1dAQAq8+xcML+Mk6fmM6XQRXmunSw1dq8YQdJpCMqB+qTjBuCEoRoKISYBNcBrBzl/PXA9QFVV1fBPfenfoOn9w5d2OErmwnk/OOjp/fv3U1lZmTiuqKhg48aNKd164cKFfPTRRwlDcNlll/Gzn/2M3bt3D2prMBi49dZbuffee1XoiXFAOKrxXl0nb37Sxt8/aWXH/m6k1MMnnDQ1n6+cPoXl0wqYlO/MtKiKcc5omSy+AnhGSjlkDFgp5aPAo6CHmDiWgqWbgSE+jEYja9as4b777uO8884b1P6qq67innvuYe/evcdKRMUIIaXk01Yvf/+kjb9/0sY7e9rxh2MYDYIFlTnceOY0Tp1WwPyKHExjOKSxYuyRTkOwH6hMOq6I1w3FFcDXR+Spw/Tc00V5eTn19X0fPw0NDZSXl6d07datWznzzDP71V199dXcd999zJkzZ1B7k8nEzTffzP333390QivSTu8E75Z9HWyp62LT3g6aevTNTKrzHVyysIJTphVw4pR8NdSjyCjpNASbgGlCiBp0A3AFcNXARkKIGUAu8HYaZUkrS5Ys4ZNPPmHv3r2Ul5fz1FNP8eSTTw57jZSSn/zkJzQ2NrJy5cp+58xmM6tXr+YHP/gBK1asGHTtqlWreOCBB/B4PCP6Hoqjo9MX5r26Trbs09P2hq5EnJ2SLBuLqnM5eUoBp04roDLPkWFpFYo+0mYIpJRRIcQ3gFfQ3Ud/JaX8UAjxPWCzlPK5eNMrgKfkWAuDmoTJZOKnP/0p5557LrFYjGuuuYbZs4feIGfNmjV8//vfx+/3s2zZMl5//fWEx1Ay1157LXffffeQ97BYLNxwww3ceOONI/oeitTRNH2Yp1fpb6nrZE+rD9AXZ80uy+LKpVUsrMpl0aRcynLsGZZYoTg4Kgz1OET9HiNPIBzr19vfWteZWKSV57SwsCqHhZNyWVSVy7yKHLUBimLUocJQKxSHSTiqsa2+i7c+beOtT9vZWtdJJCYRAqYXufmneWUsmqT39qvzHcpnXzGmUYZAoQCiMY0PDvTw1qf64q1NtR0EIxpCwNzybK45uYZlU/JZWJWrdsBSjDuUIVBMSDRN8lGTh7c+1d04N+7pwBNfuXtcsZsrllRx0pR8TqjJJ9uhFL9ifKMMgWJCoPvw+3h7Tztvx3v9nf4IADUFTi5YUMZJU/JZNjmfApc1w9IqFMcWZQgU45b6Dj9vf9qeGOdvie+kVZZtY8WMYk6aks+JU/KVR49iwqMMgWLc0NwT5O1P23Xlv6eN+g49Vk+By8KJUwo4cXI+J0/NpypPTe4qFMmodewjxDXXXENRUdGQq4F7ueuuuygvL2fBggVMmzaNiy++mJ07+2LwnX766Sxe3OfdtXnzZk4//XQA1q1bhxCC559/PnH+/PPPZ926dSP+LmOFTl+Yl95v5I4/fsCZD67jhHv/xk1rt/HSB43MKs3irgtm8ZfVy9l021n85MrjueqEKiblO5URUCgGoL4IRohVq1bxjW98gy984QvDtlu9ejW33HILAGvXrmXFihW8//77FBYWAtDS0sJLL700ZJyh3jDUF1xwwci/wBjAE4ywqbaDt3a389an7exs7AH0jVaW1uRx+ZJKTppSwMzSLBVvX6E4DJQhGCGWL19ObW3tYV1z+eWX8+c//5knn3wysUp4zZo13HPPPUMagvnz5xOJRHj11Vc5++yzR0LsUU80prFuVytrN9fz2kctxDSJxWRg8aRcbjlnOidOKWBeRTZmFaRNoThixp0huP/d+/mo46MRveeMvBl8e+m3R/SevfSGoe7lxBNP5Nlnn+X111/H7XYPan/bbbdxxx13jHtDsK/dx+821/P05gZaPCEKXFauPaWG048rZGFVLjazWrmrUIwU484QjDWGCvFx++23c/fddw8ZYXT58uUAvPnmm2mX7VgTjMR45cMmnnq3nrf3tGMQcMZxRVy2pJIVM4pUr1+hSBPjzhCkq+eeLrZu3dpvghhgxYoV3H777bzzzjtDXnPbbbdx9913YzKNj3++nQd6WLupjj9uO0B3IEJlnp1bzpnOpYsqKcm2ZVo8hWLcMz40yRjl97//PX/5y1948MEHB527/fbb+cpXvpLY/jKZc845hzvuuIPGxsZjIWZa6AlGeH77AdZuqmdHQzcWo4GVc0q4YkklyybnY1CTvQrFMUMZghHiyiuvZN26dbS1tVFRUcF3v/tdrr322kHtfvzjH/Ob3/wGn8/HnDlzeO211xIeQ8l85jOfGbK+l9tuuy2xveVYQUrJptpO1m6q58/vHyAY0ZhR4ubOC2bxzwvKyXUODsetUCjSjwpDPQ4Zbb9Hpy/M799r4Ml369jT6sNlNXHB/DKuWFLJvIps5devUBwDVBhqxTFHSsl7dZ088U4dL7zfSDiqsbAqhx9eOo9/mleKw6L+9BSK0YL636gYUTzBCH/cup8nNtbxUZMHl9XE5YsrueqEKmaWZmVaPIVCMQTKEChGhA/2d/PExjr+tG0//nCM2WVZ3HfxXC6cX4bTqv7MFIrRjPofqjhiAuEYz+84wBMb69he34XNbOCCeWV8btkk5quxf4VizKAMgeKw2d3i4YmNdfx+SwM9wShTi1zcecEsLj6+Qm3iolCMQZQhUKREJKbx0gdNPPHOPjbu7cBsFKycU8rnTqjihJo81ftXKMYwas3+CFBfX88ZZ5zBrFmzmD17Ng8//PCQ7cZiGOqYJnl2awNn/ecb3PDbrRzoDvDtlTN4+9/P5CdXHs+yyfnKCCgUYxxlCEYAk8nEgw8+yM6dO3nnnXd45JFH+in4ZFavXs22bdv45JNPuPzyy1mxYgWtra2J871hqIeiNwz1sUDTJC+938jKh9azeu127GYjj169iDduOYOvnj5FbeeoUIwjlCEYAUpLS1m4cCEAbrebmTNnsn///kNed/nll3POOefw5JNPJup6w1APxfz588nOzubVV18dGcGHQErJax81c8FP3+SrT7xHTEp+etXxvHjDqZwzu0SFflAoxiFpnSMQQqwEHgaMwC+llD8Yos1lwF2ABLZLKa86mmc23XsvoX+MbBhq68wZlHznOym1ra2tZevWrZxwwgkptR9NYajf2t3Gj/6yi/fquqjMs/PgZ+dz0YIyTCrqp0IxrkmbIRBCGIFHgLOBBmCTEOI5KeXOpDbTgH8HTpZSdgohitIlz7HA6/VyySWX8NBDD5GVldriqdEQhnrLvg5+9MrHvL2nndJsG/f+y1w+u7hChX1WKCYI6fwiWArsllLuARBCPAVcBCQPnn8JeERK2QkgpWw52oem2nMfaSKRCJdccgmf+9znuPjii1O+LpNhqD/Y382Df9nF67taKXBZ+I/zZ3HVCVVq0xeFYoKRzi5fOVCfdNwQr0tmOjBdCLFBCPFOfChpEEKI64UQm4UQm5MnVkcLUkquvfZaZs6cybe+9a2Ur+sNQ33llVcOOnf77bfzwAMPDHndOeecQ2dnJzt27DgieT9u9vCVX2/h/J+8yXt1XXx75QzW33oG15xSo4yAQjEByfQ6AhMwDTgdqADWCyHmSim7khtJKR8FHgU9+uixFvJQbNiwgV//+tfMnTuXBQsWAHDvvffymc98ZlDbTIah3tvm4+G/fsyfth/AaTFx45nTuPbUGrJsahGYQjGRSVsYaiHEicBdUspz48f/DiClvC+pzc+BjVLK/40f/w34NynlpoPdV4WhPjQDf49uf4Qf//Vjfv3OPsxGwaqTavjy8skq/r9CMYHIVBjqTcA0IUQNsB+4AhjoEfRH4Ergf4UQBehDRXvSKNOEQtMkT2+p5/6Xd9HlD3PVCVXccOY0itxq+0eFQtFH2gyBlDIqhPgG8Aq6++ivpJQfCiG+B2yWUj4XP3eOEGInEAPWSCnb0yXTRGJbfRd3/ukDtjd0s3hSLt+9aCmzy7IzLZZCoRiFpHWOQEr5IvDigLr/SCpL4FvxpBgBIjGNTn+Yqx7fQJHbykOXL+CiBWUqDIRCoTgomZ4sVowQUkrafWGae4L4QzG+vHwy3zxzGi61F4BCoTgEh9QSQogtwK+AJ3v9/RWjC28oyoGuAMFIDJfVRFGWlX8/SU2eKxSK1EhlHcHlQBn6yuCnhBDnCjXOMCoIRzXq2v3safWiaZJJ+U5qCpxqRbBCoTgsDqkxpJS7pZS3oXv0PIn+dbBPCPFdIUReugUcCwSDQZYuXcr8+fOZPXs2d95555DtVq1aRU1NDfPnz2f69Ol84QtfoKGhIXG+urqaSy65JHH8zDPPsGrVKgAee+wxDAYDO3bsQJOSFk+Q2XPm8I9PdlOcZWN6sZtsu1nNBSgUisMmpa6jEGIe8CDwQ+D3wGeBHuC19Ik2drBarbz22mts376dbdu28fLLLx80PMQPf/hDtm/fzq5duzj++ONZsWIF4XA4cX7Lli0HDWFdUVHBXd/7Pp80e2nqDmIQUFPgpDjLpqKCKhSKI+aQhiA+R/Bj9HUB86SUN0gpN0opH0T5/AMghMDlcgF6zKFIJHLInrkQgtWrV1NSUtJv/4Gbb755yDDUMU3jtLPOZcf7H7Bn9yeJISCLSYWEUCgUR0cqLiWf7Q0cNxApZerR1Y4Rf//dx7TVe0f0ngWVLk69bPqwbWKxGIsWLWL37t18/etfP+ww1L3hIi677DJ+9rOfsXv37kSbYCRGS0+IqCa46Vu38NtfPMx5pzx+5C+kUCgUSaQyNHSdECKn90AIkSuEuDuNMo1JjEYj27Zto6GhgXfffZcPPvggpesGhvgwGo2sWbOG++7TI3FEYxqftnrRgGy7ia9c+0U2vvMOe/fuHelXUCgUE5RUvgjOk1ImYjvH9w34DHB7+sQ6cg7Vc083OTk5nHHGGbz88svMmTPnkO23bt3KmWee2a/u6quv5r777mPK9Bl4QlFMBgPFbiuNRgMmk4mbb755yL0KFAqF4khI5YvAKIRIbFArhLADasPaJFpbW+nq0gOmBgIBXn31VWbMmDHsNVJK/uu//ovGxkZWruwffdtsNvOlr32Tn/zXwxgNgimFzn67hK1atYq//vWvjMaQ3AqFYuyRiiF4AvibEOJaIcS1wKuAGqBOorGxkTPOOIN58+axZMkSzj77bM4///wh265ZsybhPrpp0yZef/11LJa+KKBSShq7A6y48HK0WAy31Txoq0iLxcINN9xAS8tR7+OjUCgUqYWhFkKcB/SOX7wqpXwlrVINw3gOQ61JSUNngC5/mHynlbIc2xGtCxgvv4dCoRg5jjoMtZTyJeClQzZUHDExTWNfux9vKEpJlo1Ct1UtDlMoFMeEVNYRLBNCbBJCeIUQYSFETAjRcyyEmyhEYhqftvrwhWJU5jooyjqyLwGFQqE4ElL5Ivgp+qYyTwOLgS+gh5tQjADBSIzaNh9RTVJd4MCtto1UKBTHmJRCTEgpdwNGKWUsvq3kkJvMKw4PXyiaWCMwpdCpjIBCocgIqXwR+IUQFmCbEOIBoJEUDYji4HQHwtR1BLAYDdQUOFSoCIVCkTFSUehXx9t9A/ABlcAlw16hGJY2b4h97X7sZiNTCp3KCCgUiowyrCEQQhiBe6WUQSllj5Tyu1LKb8WHihQDiMViHH/88QddQ7Bq1SqqJlVz8tJFXHTaEr5789doajyQOJ9qGOpe5syZQ21tbVreRaFQTByGNQRSyhgwKT40pDgEDz/88EH99zUp8YWi3Pid7/Lahnf59JNdLFx4+GGoh4pMqlAoFEdDKkNDe4ANQog7hBDf6k3pFmys0dDQwJ///Geuu+66QeeklOzvDBCOauTYzZTl2DEYDIcVhhrg/PPP58MPP2TXrl1pew+FQjHxSGWy+NN4MgDu9Ipz9Lz+2KO07BvZbRKKJk3mjFXXD9vmpptu4oEHHsDj8Qw61+oJ0ekPY7MYyXZY+q0RSCUMdS8Gg4Fbb72Ve++9l8cfV1E+FArFyHBIQyCl/O6xEGQs88ILL1BUVMSiRYtYt25dv3PdgQhNPUFy7Bbs5sGTwsOFoT7vvPMGtb/qqqu45557VBhqhUIxYhzSEAghXgcGBSSSUq5I4dqVwMOAEfillPIHA86vQt/+cn+86qdSyl8eWuyDc6ieezrYsGEDzz33HC+++CLBYJCenh4+//nP84tfPUZ9hx+HxURFrn3Ia4cLQz1UGGsVhlqhUIw0qcwR3AKsiac7gG3A5mGvIOFx9AhwHjALuFIIMWuIpmullAvi6aiMQKa47777aGhooLa2lqeeeooVK1bwv4//H7XtfowGwaR8x6A9hQ8Vhnr16tX8+Mc/HvJ5Kgy1QqEYSQ5pCKSUW5LSBinlt4DTU7j3UmC3lHKPlDIMPAVcdHTijg2khH3tfmKapDrfgTkpjPShwlD3cu211xKNRoe8vwpDrVAoRpJDhqEWQuQlHRqARcB/SSmPO8R1lwIrpZTXxY+vBk6QUn4jqc0q4D6gFfgYWC2lrB/uvqM9DLWUkvp4KOlJ+Q6y7cfe83Y0/R4KhWJ0cLRhqLegzxEIIArsBa4dIdmeB34rpQwJIb6MvuHNoLkHIcT1wPUAVVVVI/To9NDqCdHlD1OSZcuIEVAoFIrDJRWvoZojvPd+9HAUvVTQNynce1ohbVEAACAASURBVO/2pMNfAg8cRIZHgUdB/yI4QnnSTncgrHsIOSwUutVungqFYmyQyn4EXxdC5CQd5wohvpbCvTcB04QQNfGVyVcAzw24d2nS4YXAP1ITezCp7LSWTgLhKPUdAd1DKMeesf0EMv07KBSKsUcqXkNfklJ29R5IKTuBLx3qIillFD1Q3SvoCv53UsoPhRDfE0JcGG92gxDiQyHEduAGYNXhvgCAzWajvb09Y0owEtOG9RA6VkgpaW9vx2azZeT5CoVibJLKZPH7wDwZbxh3C90hpZx9DOQbxFCTxZFIhIaGBoLB4DGXR0pJqzdMNKZR6Lb28xDKBDabjYqKCsxmtbeBQqHo42gni18G1goh/jt+/OV43ajBbDZTU3OkUxlHjpSSm9Zu40/bDvDzzy9i3pySYy6DQqFQHC2pGIJvo3vsfDV+/Cr6xO6E55HXd/OnbQdYc+5xrFRGQKFQjFFSMQR24BdSyp9DYmjICvjTKdho5+UPGvnRXz7mnxeU8bXTp2RaHIVCoThiUhnQ/hu6MejFDvw1PeKMDT7Y383qtds5viqHH1wyL2MeQgqFQjESpPJFYJNSensPpJReIYQjjTKNalp6gnzp/zaT6zDz31cvwjZERFGFQqE4EoLRID3hHnpCPXgiHnpCPfpxvG55xXJmF4y8n04qhsAnhFgopXwPQAixCAiMuCRjgGAkxpd+vYUuf4RnvnoiRW7lpqlQjCU0qeGL+PCGvXgiHrxhL96IF0/YM3RdxJuo90f8CAQWo0VPBgtmoxmLwZKoMxvMg84l576ID0/Yk1DsvUreE9aVflgLDyt/ni0vY4bgJuBpIcQB9DATJcDlIy7JKEdKya3P7GB7fRf/ffUiZpdlZ1okhWLCI6XEH/XTHminI9hBe6Cd9mB7Ik+u6wh04I14kYOj6vfDZDDhNrtxWVy4zC7cFjeVrkqcZicaGuFYmEgsQlgLE46F8UV9dIW6CMfCibqIFunXpveZAoHb4sZtcZNlySLLmkWRo0gvx4+zLFl95+N1vdeYDelxC08lxMQmIcQMoDfI3C4pZSQt0oxifre5nue26x5C585WHkIKRbqRUtIaaKXeU09dTx37vftpC7T1Kf24wg/Ghl4/lG3NJt+WT749n5l5M8mz5ZFlzUood5fZhcviSij93jqr0Tqi835SSqIySiQWwWayYRCZXWs0FKl8EYBuBGYBNmChEAIp5f+lT6zRhZSS/91Qy6zSLOUhpFCMIFEtSqO3kXpPva7wPXWJcoOnoZ+SNwgDudZc8u355NvyqcqqIs+WlzhOznNtuWnrPR8uQgjMwjxq5BmKVHYouxN9/4FZwIvoG828CUwYQ/BeXRcfNXm491/mKg8hxYQiqkVp8jWx37ufRl8jmtQQCIQQCESidyuEwIAhUZ+cGzCA0MfnD3gPJJR8naeORm8jUdm374bVaKXSXUmFu4ITy06kyl1FpbuSSnclpa7SUa1MxzKpfBFcCswHtkop/1UIUQz8Jr1ijS6e2LgPl9XEhQvKMi2KQjHidIe6afA20OCJp6Ryo6+RmIyN6PPcFjeV7kpm589mZfXKhKKvdFdS6CgclUMn451UDEFASqkJIaJCiCyghf7hpcc1Xf4wL+xo5LOLKnBZUx1JUygyQ0yLEYqFCMaCBKPBvjwaxBfx0ehr7K/svQ14wp5+98i15lLhrmBuwVzOqzmPCncFFa4KSp2lmAwmJBJNavoEqAQNDSklEtkv760HkEgEghJnCdlW5Wgx2khFs22Oh6H+BfomNV7g7bRKNYp4ZksD4ajG506YlGlRFBOEYDRIi7+FZn8zzf5mvexrpi3Qhj/q1xX9ACXfW45oh/bjMBvMlLvKqXBXML9wvq7o48q+3FWOy+I6Bm+pGE2k4jXUu/fAz4UQLwNZUsod6RVrdCCl5Ml36zi+KodZZVmZFkcxxpFS4ol4aPY191P0A4+7Q92DrnWZXRTYC3CandhMNrIsWRSZirAardhNdqxGKzaTDZvRhs1kG7LebrZT6iylyFGkhl8U/TissQ4pZW2a5BiVvLOngz2tPn702fmZFkWRYTSp0R5oxxPx4Av78EV9+MI+vBEvvogvkbwRL/6Iv1/ee84T9gzp6phny6PYUUyZs4zji46n2FFMkaOIYmc8dxTjNDsz8NaKiYIa9B6GJzbuI8tm4vx5pYdurBgX+CN+9vXso7anlr3de6ntrmVvz1729ewjEB1+Qb3JYMJlduE0OxMp15ZLpVtfjOQyuyh0FFLsKE4o+SJ7EWaj8oRRZBZlCA5CqyfEKx82cfWyahVPaJwhpaTZ38ze7r26su9V+j21NPmaEu0EgjJXGTXZNSwuXkxVVhXZlmxcFhcOkwOXpU/pu8wuLEZLBt9KoThyUllHkDdEtWe8ry5+eks9kZjkqhOqMi2K4jCIaBE6Ah39wgz0rkRt9bdS21NLbU9tv9690+ykJktX9jXZNVRnVVOTXUNVVhVWozWDb6NQHBtS+SJ4D91dtBM91lAO0CSEaEbfz3hLGuXLCJom+e27dZxQk8fUIuVBkWmklHSGOtnv2T9IwQ+MKzPURCuA3WSnwF5AVVYVi4oXUZNdk1D6BfYCtVBQMaFJxRC8CjwjpXwFQAhxDnAJ8L/Az4AT0ideZvj77jbqOwKsOXdGpkWZMPSuYE0OL5AoexvwRXyDrnGZXYmwAlNzph403EC+LR+HecJGTleMAWQshhYIoPn9SL8fze9PHGv+3tyHY8kSbNOnj/jzUzEEy6SUX0oILOVfhBA/klJ+WQgxLr+bn3hnH/lOC+fOLs60KOOKQDTQT8EnK/wD3gP9Qg30+rpXuitZVLyISncl5a5yCh2F5NvyybPnqWEbxahFC4eJ7N9PpKGBcF0dkfoGIvv3E/N6kpR9r4L3I0OhlO5b/B93ZMwQNAohvg08FT++HGiOb1mpjbhEGaaxO8DfPmrhS6dOxmpSk8RHQ3eomy3NW9jUtInNzZvZ1bGrXwhgt9lNhbuCGXkzOHvS2f1CDRQ5ijAa1O+vODK0UIhYdzdaTw+xnh697PUhLBYMTidGlxODs38SptR9Z6SUxLq6iNTXE66vJ1LfQLheV/jhhnqijU0g+/7WhdWKuaICY3Y2RpcbQ1ExBocD4bBjcDj0ZI/nSXXCbsfgcGJwOjDY7Rjd7nT8XCkZgquAO4E/xo83xOuMwGVpkSqDrN1UT0yTXLVUTRIfLgdT/FajlQWFC/jy/C9Tk1WTUPbZ1mw1Nq/Qw1KEw8hQKJFr4bBe7k2hEFoohObxEOvWFXuspxutO67oe3rQerr1cz09yODQoamHQ1it/Y1D3FgYew2F1Ua0pSWu8OvRvP2HK425WViKcnBOKcC8dBLmfDuWXCvmbAMmm4aIBkHGdAMhfYA3XtYAGTccEvwSfPGy1PrqpQZLvwzTzxmBX70/qawsbgO+eZDTu0dWnMwSjWk89W49y6cXUpWvxpQPRXeom/ea32NT8yY2N23mo46P+in+ry34GktKljC3YK5yrZwgaIEAkaYmok1NRBqbiDQ1Em1s0utaWtCCAWQo3F/xR47MAdHgdGJwuzC67BgdVix5VgxlxRgtRRgtMYzGMAZjECNejHgxaD3IaAwtKtAiSSkqiEVAiwTRoj16nVegder1kWhfO5M9htkZxVEaxeKKYXbFc2cMg+lAfwF98dRkB4sDTHYwGEEYQAhADCjHjxPlIeqjh2/gUiEV99HpwC1AdXJ7KeWKFK5dCTyM/vXwSynlDw7S7hLgGWCJlHJzSpKngdd3tdLUE+SuC0d+K7jxgFL8Y5RYBMJeCPtBi8Z7mfGkxZKOk8qaNqheC4eIdniJtHcTbesm0tZJpLWLaGs7kZZ2oi1txHo8gx5vzM/DXFKKubwcg92GMAmEyYDBgF42SD0ZNYSIYTBoCBHVExGEDGMQYT2XHoyyG2OsHRFqhIPtNmZxgSM/nirieZ6uiA+GHH7nMgBMNl2pm53x3AEWZ1Ju719ndoBh9IfzSGVo6Gng58AvgZTj0cbnEB4BzgYagE1CiOeklDsHtHMDNwIbU713unhi4z6Ks6ycObMo06JkjO5Qd7/J3OTU4m8BwGKwsKBoAV9d8FWWFC9hbuFcNXF7NEip9/QigQF5UM+jgb5y2AshL4R9ceU+IE+c6633Qmz4fXClhFjIQDRgIBIwEvUbiQaMfcfxciw0WIkaLBpmRwyzI4a9KIZ5kl42Ofpyg/EA8IHeq5UDphUlulaJAYM+DER/hWpxgT0XHJXgLEhS9EnJWQD2PDCr/cQPh1QMQVRK+f+O4N5Lgd1Syj0AQoingIuAnQPafR+4H1hzBM8YMeo7/LzxcSvfXDENs3H0W/AjRZMaLf6Wgyr7gSGJC+2FVLgrWFa6jElZk1hYtFAp/oFoGoS6wdcO/jbwt4MvnieXAx26kh+o8JM+96WEWFhXyr0KONqrjEPxTWAMUh9RMBoQJjOYzQizGWG2ICwWhNmJsOSBxYaw2hAWO8LmAKOFqCdItNNLtNNDtNNLpKOHaJcXogP6eEJgzHZhys/BXJmDPT8XU0Eu5vxsTPluzPnZmPOcGMwG/StDi+pfHr3lxHFE/+roPWd26D1pi7OvV50oO5N62/HetZpDOiakYgieF0J8DXgWSPg4SSk7DnFdOVCfdNzAgDUHQoiFQKWU8s9CiIMaAiHE9cD1AFVV6ZnE/e27dQjgiiXja6sFb9jLxsaNvHngTd5rfo8GTwNhra+HaBImylxlVLormVswt5/nTrmrfGL532ua3oMOdkGwuy8Feo+7Dq7kD7Z5i9kJjnykIw9N5BCN5RIJCqI+SdSrEfVGiHoiRHuCRLsCRLv9yIFKGTBmuTHmZoMwIGMaMhxDRiMQiSKjUWQkgoz6ITZ4aGYgBqcTU1ERpuJyHDMWYC4uxlRUjKmoCHNxkX6usBBhVjGQMkUkHMPbEcTTHsSTlM88qZSKGUMFezg6UjEEX4znyYpaApOP5sFCCAPwn8CqQ7WVUj4KPAqwePHiFAbyDo9wVON3m+tZMaOYshz7SN/+mKJJjV0du9hwYANv7n+T7S3bicooLrOLxcWLOa3iNCrcFQllX+IswWQYhSGnwn69d+1L6mEHu/TeJZAYG+71qEiU4+eGKkstScEPoexDPYOHLgZizwVHgT4EkTcZKpaAswBpySUashDxSiLdESKdASJt3UT2txJpPED0QCNafGgtGYPbrSveojIcc3qVcDzvTYUFGKypfYFJTYOEYYj2pUgENA1jXj5Gl4pkmkmklIT80X4K3tMRxJtUDnj6j5MJg8CVY2XSnPy0yJSK11DNEd57P/13MquI1/XiBuYA6+IuhCXAc0KIC4/1hPGrO5tp84b53LKx6TLaFezi7ca3eXP/m2zYv4H2YDsAM/NmsmrOKk4pP4V5hfMyu99rJADeZn34xNeapOTb+oZUko+HWEk8IpgdYMsGW46eu0qg4Diwx4/jSZrdSIMDzWBHGuxIYUOLGog0txBpbCTa2Ejkw0YiBw4QaXyfaEuL/kWRhDEvD3NpKdaaGpwnnaRPmJYUJyn4Qgz2ke14CIMBLPoQkWJkkVISi2pEQrFEioY0IqEokbCe68d95yPh3nYxwsEo3s4Qno4gkWD/rz6j2YA7z4Y730ZBpTtR7s2d2RYMaRyyPqghEEKskFK+JoS4eKjzUso/HOLem4BpQogadANwBfr6g97ru4GCpOetA27JhNfQExv3UZ5jZ/m0wmP96CMipsX4oP0DNuzfwIb9G3i/7X0kkmxrNieVncQp5adwUtlJFNgLDn2zo0HT9HFvb7OePM195YHHoZ6h72GyxXvY+XpeMK2vx+0s6Cs78vXeeMLrQySNHw8oo/+njba0Et5Xp6e6OiIHmtBCQd19Me66qIX9yFAXMvRxP/91YsP7RQizGVNpKebSUpzLlmEuK8VcVhavK8NcWjLiSn4sIzWJrzuMMIDRZMBkNmA0GRCGo5sD0DRJyB8h6I0Q9EUJ+nrLfSnkjRDwRgj5o2gxLe66H99OU4tvt6nJeB3986SyJuVBnZSGwmAQmG1GzFYjJoueZxXYKT8uV1fwScre7jZndE3NcF8EpwGvARcMcU4CwxoCKWVUCPEN4BV099FfSSk/FEJ8D9gspXzuCGUeUT5t9fLWp+2sOfc4jEf5R5lO2gJtCcX/VuNbdIe6EQjmFs7lq/O/ysnlJzM7f/bRr8aVUh8n97boydfSVx6o5H0t+gTgQCwucBXrqWQOuM4EV5F+7Czsr/gtziOeEJRSEm1tJbJvH+F9+wjX1sbzfYTr6vot2xdWq+6+6HDoC4ccdkRODsJqRVj1HrTBYk0cG6xWRPKxxYKw2fUefWkppoICvfet6IeUEk9HkI4DPjoafXp+wEdnk49oePCwm8EkMJkMGOOGwWjuMxKJstmI0WTAYBSEg9F+ij7kjx5UOQuDwOY0YXOasbnMuPNtGE0CYRAIIRAGMIjeY5LqRdy9Xy8bDIAQGAwCk8XQT7EPTMn1RtPY+fs4qCGQUt4Zz//1SG8upXwReHFA3X8cpO3pR/qco+G3G+swGQSfXVyRiccfFE1q7GzfyfqG9axvWM+H7R8CUGAv4PSK0zml/BSWlS4jx5aT4g1j0F3fX6n7WuOKfUBdxD/4emHQFbc7ruCLZuvK3V0SV/IlfcreOnIRW7VQqG9xUmMj4X21uqLft4/Ivn1o/iRZzWYslZVYJk3CefLJWKonYZmkJ1NJyYRW3FJKIqEYRqMBg0kcde9TSom3M9Sn7ON5Z6OPSKjva8qRbSGv1MmsU8rILXaAEMQiGrGonqIRTT+OaESjSeWIRiyqD6sEvJHENRa7rtjd+TZdwfcmVzwlHVtsRrVyPUVSWVBmRY82Wk3/BWXfS59Yx4ZgJMYz7zVw7uwSityZ9zv2hr283fg26xvW8/eGv9MebEcgmFc4j28e/01OLT+V4/KOG36/2WgYOvZA60fQuqsvb98NsSECWzny+3rqlSfElXkROIv6FLurSG83wrF/ZDhMpKVFH29viq8+ja9C7V2RGuvs7H+R0Yi5ohzLpEk4Fi9OKHpL9STMpaWHFS9mrBMJxwh4wgQ8kXiul/3J5R69HPRE9GEQ9A8wk8WIyWJI9GBNZkO8zojZYuh3vjc3GATdLX7a4wo/nDTObXebyStzMeOkUvJKneSVOckrdWJzKs+jsUAq/2v+BHQDW0hyHx0PvPh+I13+CJ/L0OYzUkpqe2oTin9LyxaiWhS3xc3JZSezvGI5J5efTJ5tCHexSEBX7gllH1f4HXuShmsE5FRB4QyYeqY+/u4u1ZW+q1gfe0/TNokyGiXa0jIg3EAT0aZGvdzcRKytfdBqTkNWFuaSEkylJdjnzMVcWoKppBRzaQnmkhLM5eUTwq1RSknAE6Gr2Udnk5+uZj/drYGEYg94Iv163smYrEYcbjN2twV3no2iSW7sbgs2hxlN04iGNSLhGNGwRjQUIxqOEQlrRMMxgt4w3ojWry4aiiX+mWwuM3mlTqafUNKn8Muc2F1qcnosk4ohqJBSrky7JBngyY11TC5wcuKU9LhkDUU4FmZz02bW79eHfOo9+lKLqTlTuXrW1SwvX86CogV9Lp2BLmjYDG0fx5V+XPF37etzdRQG3ZWxcAbMvEDPC4+D/Gn6Ap0RRsZiRNva4j355n7xZCJNjUSbmom2tg7yojE4nZhKSzCXlGKbOQNTcUlc0ZdgLi3FXFyMwTmxXBuj4RjdrYGEsu9q9tMZz8OBvvkXo8lAdpEdR5aFrIJsHG4L9ixd2TvcFuxuC/a48jdbR/jLTUq0mO4xY7FNnC+uiUQq/6pvCSHmSinfT7s0x5CPmnrYvK+T2z4zM+3jiFJKNhzYwNO7nubtxrcJRANYjVaWlizlC7O+wKllJ1OuSV3Z126CzU9A2yf6sbe570YGM+RPhdL5MO8yXdkXztDrTCO/0ldKSaS+nsD27QS2bSf4j3/oir6lFaL9J4mF3a735EuKdVfJZAVfUoKptBSja3zv9ialRItKolG9J907rt07Dh4ORuluCfRT+J6OYL/JTmeOlZxiB9OXFJNT7CCnxEFusQNXng1DhpwZhBAYTWJMTX4qDo9UDMEpwCohxF70oSEBSCnlvLRKlmae3FiHxWTgkkXpmySWUrKufh3/veO/+bD9QwrtBVxQejLLLUUsDWvYO/bA7kegfXX/CVpbtu7bPvVsfTinYLqecielbSgHIOb1Enz//YTiD2zfnhijFw4HtpkzcS5ZMrgnX1KCIXv8hZSORTQ6Gn201ntoq/fGPV9iCcWemOhMUvapYLIaySmyU1KTxYxlJXFl7yS7yK563Ip+aLEYkVCIaFhPVqcLm3PkO1Sp/NWdN+JPzTC+UJQ/vLeff5pbSp5z5Mc2Nanxt7q/8eiOR/mo4yPKrbncJYq48B/vYZbvxVsJyKnUFX71qf0VvrMg7TFWpKYR/vRTXenHFX9o9+7EmL1l8mRcp5+Off587AvmY506dVxPxIYDUdoaPLTWe2mr1/PORh9aTP89zFYjuaVOrHYjNpelzxfe3Jcnuz72qzMZMZoNmK0GsgrsOHOs485oTnQ0LUbYHyDk9xEO+An5fYT8/njZn6iPhkJEwiGioRDRcDipHEpS+OFEWRuwnuWs677O/LNHXiUPt6AsS0rZAxw6eMkY4/ntB/CGoiM+SRzTYvxl3194dMej7O7aTbXRxd09YT7Tvh1zVjmcdAOUztOVfd6UtIzfH1Q2r4/Als19vf0dO9C8XgAM2dnY583Dfe65uuKfNxdjdvYxk+1YIqXE3xOmtU7v5bfVe2ht8NLTGki0sWdZKKx0MWl2PgWVLgor3WQX2o968ZMi82haTFfGSco3Egr2U9CR3vOh4IC6IOFAXNn7/YQCfsJxhR8JHXqfAGEwYLbaMFutmKxWzBYrJosFk9WK3Z2FOz+p3qqf6y2brVZMFiul09Kzj/pwXbwngfPRvYUkvUs2dY461lAmefLdOo4rdrNoUu6I3C+qRXlx74v8Ysej1PbsYwpm7m9p41z/fozTz4VzV8HUs0bc/XI4pJSE99biXf8G3jfewL95C0QiYDBgPe44ss7/J+zzF2CfPx9L9aQx6WMfi+rj7uFAlHAgpufBKOFgUrn3XDBKwBOmrcHbL45LVqGdwkoXM08qpbDSTUGlC2e2iqx6pEgpCfR009nUSFfTAbqaG+mKl3vaWrE6XThzcnDm5OHKzcWRnYsrNw9nTh7O3FycObnYXO7D+mKSUhL0evB2duDr7Ejkvq5OvJ3t+Do78XV14OvqIho+fMdHg9GE2aYraIvdgcXhwOpw4s4viJcdWOxOPY+fs9j1+uSyyTJ6vwSHW1B2fjw/0lhDo5IdDV3saOjmexfNPup/lEgswvN7nucX235Gg7+Z4yIxHuzo4CxLIYYTvgULPg9ZpSMk+aHRQiH8776L9431eN94g0i97pFknTaVvC9cjevUU7HPm4fBMXoiivYudAr6IoR8UQLecDxMQJSgN5wUNkAv9yn4GLHoocfkDSaB1W7CbDNhc5iYNLeAggq9l19Q4cJiH7/DXelCSomvs4OupkY6mw/EFX08NR8gHOj7uhLCQFZRETnFpUyZVEPI78fX1Unznk/Y09k5ZE/aaDLhyNGNQq/BcObkYXdnEfR5kxS9rvT9XZ3EooNXuFsdTpw5ubjy8iibPhNHTi5WuyPR6zbbbJgsfb1tc2/Pu7fXHu+xG8fxkGgvKb2hECIXmAYkVl1JKdenS6h08uTGOuxmI/98fPkR3yMcC/PsrrX8z7af0xjpYXYoxK3dXk6vOhNx+iqYfMYx25Uosn8/3vXr8b6xHt877yCDQYTNhnPZMvKv+Vdcy5djLj/ydz1aNE3SccBH055u2hu8SYq+Lz7McArd6ugLEWB3W8gpdmCxGbHYTVhsJj23G/vKSeesdhNG89j70skkWiyGv7sLX1dnvEfdkehN+zrb6WpuoqupsV/P2mA0kl1UQk5JKeUzZ5FTXEZuSSk5JaVkFRZhNB3cwSEc0A2Dr7MTb1eH3nvv7kz06LubGzmwaycBT1+sKpvThTM3D2duHpUz5+DMy8eVk5uoc8W/LszWzC8SHSuksrL4OvQdxCqAbcAy4G3gkFtVjjZ6ghH+tO0AF84vI8t2+N43wWiQ32/5Kb/6+ClatBDzgyHuiNk5Ze5XEcd/Tl+Bm2ZkJIJ/61a8b7yBb/16Qp/o20abKyvJufRSXKctx7FkCQZbZv4T+HvCNNf20LSnm+a93bTUehILn6wOE44sCzaXmawCO0WTsvrCAgzI7S4zVocprREXxwtSSqTU9IBqWiyea2harC+PacSiEfzd3fGedCf+7l5F3xlXxh34e7qH3LLR5nLjzMklp6SUSXMXkFNSRk5JKbklpbjzCzEYj2zY02J3YLE7yC0dvrMSi0YIeDzYnC5MKrLqiJPKF8GNwBLgHSnlGUKIGcC96RUrPfxx634CkdgRhZvetPN3rHn3HtqFxuJgmHty5nLCqd9E1CxPu4dPtLUV79/fxLt+Pb4NG9A8HjCbcS5ZTPYll+BafhqWmupjPv4Yi2m0N3hp2tND895umvZ009Omf+obDIL8ChczTiyluCaLkslZZBXYR+0YaaaRmkbA04Onox1vb+psx9vREc/b8Xd3EYtGEoo+ofQPtYfCQRAGA87sHJy5ebjz8imZMk0fq8/JxZmbm+hZO7JzMWV4NbfRZMaVO/Ibsih0UjEEQSllUAiBEMIqpfxICHFc2iUbYaSUPPFOHXPLs5lXkWKgtjhtrTu5ZeP3yNLgR9UXsXjZt/TomWlCxmIEduzQFf8b6wnu1Hf3NBUVkbXyXFynnYZj2YnHfIMRX1eIpj3dNO3VFX/LPk/Cd96RbaFkcjZzlldQPDmLwio3ZsuxmxwfzYSDAbwd8THtIXgKewAAGmdJREFUZEXf0Y4nruR9nZ1osQHj3ELgzM7BlZdPdlExZdNmYDSbMRgNCIMRg0HPhcGAwWjA0FvuVx9vZzRgNJqwZ2Xr4+a5+pj7WHQSUIw8qRiCBiFEDvBH4FUhRCewL71ijTzv1XWyq9nDDy6ee1jXxf5/e3ceH1V5LnD892QhCZlsk4QkJCQhYYewibiwKmhxw+VqS9XWuqEVrLaf29bettbaem+rt7f3ttUqKm29tXX3ykdRwaUKWlQEJCwKIRJCSEL2PSSZvPePcxKGZAYCycyEzPP9fPLJzDnvzHlyMnOemfd9z3OONHHPq9fTDKxe8BC5Y3xzWkVHTQ1NGzdaff0bN+KqrYWQEKJmzCD5u9/FsWA+EePH++0TdWenoaqkkbJ9dZTuq6N0Xy2N1Va/cEiYMCIzhinz00nNiSNldCyOhME7I8JX2lqae81UaewxW6Wxppr21pZejw2PjMLhTCTG6SRj4hQczkQcCYnEOBOt285EouMTTrnLRamT0ZcrlF1p37xPRN4F4oA3fBqVD2w9UEtsZBiXTRvZ9wcZw5Mvf42PQtq5P/uqAU0CprOT1l27aXz/PZree5+W7dvBGEKdThwLFuBYMJ/oOXP8Np+/rbWD8sJ6SvfVUrqvjvIv67v79qPjhpGaG8/0RXGk5sSRlOEYcoOwnS4XrU2NtDY22D+NtDTU09rYSGuTtaylvt7uT6+msbra44yXsGER1nTIhASSs3MYPf0MawDTniLZdZCPGEQzt5QS42FgqHulSCiw0xjjm7MYTsGsWbPM5s2ndhGzhtZ2Yk5ikPjTt3/MTcWvsCR6NL+6ek2/P/G66utp+vBDa3rnhg24KitBhMi8PBzz5+NYMJ/IyZN9/nW96+IhRz/t11Fd0ogx1nCHM91BWm4cablxpObGEeOMPO0+7XfNfrH62qu7Z7+0NDS4HeyPHvSPNB/n0pgiREY7iHQ47OmMzqMH92MO8k6GRQ0/7faVCg4i8qkxZpandcf9RmCMcYnIFyKSaYw54Jvw/OdkkkDNrv/jB/tfIiM8mnuX/q1fb+62/fupeOQR6l9bCy4XIXFxOObMsT71z51LWKJvq58aY6gpa6Z4dzWlBdagblOt1c0THhFKyuhYZl2cTVpuPCmjYwf13HpjDK1NjTR1D6hWux3srcHVppoqmmprew2iioQQ4XAQ5Ygh0uFgeFw8zvRRRDocREbHEBUTQ6Sj68dx9PbwaO1LV0NaX97xCcBOEfkY6P7YZIxZ6rOoAsxU7OEnG+6hJiKcpy9cRXREzCk9T1txMZV/fJS6V15BwsNJuO5aYpcsIWrqVJ/X7eloc1Gyp5ai/EqKdlZ1z+aJcUYycmx896f9xHRHwKpaetPR1kbd4bKjZ6eWlVJbXkpdeRmN1VV0tLf1ekxkTCyOBKvrJTkr2+5zd3b3vTuciUTFxhLix7O7lTpd9OVo9FOfRzGYtNTw1Etf5f3IcH6UdzsTU2ee9FO0l5RQ+ehj1L78MhISgvP660i85RbCkpN9EPBRDdWtFOVXsn9HFSWf19DR3knYsBAyJjiZcWEWWVMSiXEOjpNs2o+02icnWQf6mrKjZ6g2VFceM5c90hFDfGoaKbljGTP7HPvA7uz+HR3v1LnlSvVDXxLBxcaYH7ovEJFfA+/5JqQAcnWQ//x1/HdEB4uSZvL1GXec1MPby8qofOwxal94EQESvvY1EpcvJzzFNyeadbo6KSusY39+FUU7qqg+ZH1hi02KZOLckWRPSWTkuHjCwgPzKbijvZ268lKqDx2kpvQQNaUl3XVnGmuqj2kbFRtHfGoaoyZN6T5ZyfoZSZTj1L6RKaX6pi+J4ALghz2WXeRh2WmvYd2/8f22Lxkx3MnPF/++z+MC7YcPU7XqcWqffRYDxP/LVSTddhvhaQNfZ6iloY2inVUU5VdxYFc1bS0dhIQIaWPjmXN1GllTEolP8d+ApenspKG6kppD1oG+uvToQb/+8OFj+umHx8WTkDaSrKkzuw/0CfZBP2J4cF2ZTKnB5HhlqL8N3AHkiMh2t1UxwAe+DszfzJa/8rMvX6QsOpo/L36YuIgTT9vsqKyk6vEnqHnmGUxHB/FXXUnibbczLGNga/vUljezb+thCrdVcrioHgwMjx1G7oxksvISGTXB6fMB3o72diqKCqkuOXqgrzl0kJoedWfCIyJJGJlOau44Js49D+fIdBLS0klIG6kHe6UGqROVoX4d+A/gHrflDcaYas8POU0Vf8zz7/0b651xfHfGd5g+Yvpxm3dUV1P15JPUPP03TFsbcUuXknTHtxmWOTDXNzDGKtS2b2sFhVsPU1VidfmMyIph9qWjybYraPqyPr4xhsriIoq2b6UofxsHd++g44h1wJeQEOJTUklISyczb7p9oE/HOTKd6ASnTp9U6jRzvDLUdUAd8HX/hRMAdSV88cL1/Dohjjkps/lW3k1em3bU1FD9pz9T/de/YlpaiL30UpLu+DYRo/tfqds68Dayb8th9m2toLa8GQTScuOYe81YcmYk+3ygt6G6kqLt2ziQv42i/G0019UCkDAygykLLyBz8lQSR2USNyI1KErzKhUsfPpuFpElwP8AocATxphf9Vh/O7ACcAGNwHJjzC5fxnSMtmaan1nGv8aEEReZwAMLHiREPM8Xb9ywkZK776azuZnYi5aQtGIFEbm5/dq86TSU76/vPvg3VLUiIUL6uHimnZ/B6OnJPr1IypHmZg7uzqdou3Xgry6xrl8QFRtHVt50svKmk5k3ndgk3852UkoFls8SgX1W8sNYg80HgU9EZE2PA/3fjDGP2u2XAv8FLPFVTMcwBl5ZwQPtJRRFOnhiwX+SGOX5xK6OmhoO/ehHhI9MY+R//obI8eNOebOdnYbSglq726eCptojhIQKGROczLo4m9HTkohy+GYqpKujg7KCPRTZn/jLCr6g0+UibFgEGRMnk3feBWTmTSc5M1tPoFIqiPjyG8FsoMAYUwggIs8AlwPdicC+JnKXaKxLYPrHht/wStGbrElO5NvTbmd22myvTcsf+HdctbVkPr7qlJNAVUkj+f84SOG2Cloa2gkNCyFzspPcK3LInppExPCBL/NrjKG65CBF+ds4sGMbxTu3W1ePEiE1ZwyzLruKrLwZjBw/MeBlhpVSgePLRJAOFLvdPwic1bORiKwAvgcMw8vFbkRkObAcIHMgBmQ/f43CDf/BAxkZzEqZyW1Tb/PatOGtt6h/9VWSVqwgcuLEk95UbXkzH7/6JXs3lxMWHkLWlCRyZyaTNSWRYZEDv/ubamusA7/9qb+xugqA+JQ0JsxZQNbUGYyaPFXn5iulugV8xM8Y8zDwsIhcC/wEuMFDm1XAKrCKzvVrg+W7aH1pOd8fOYrIiBh+Ne9XhHopO9BRU0PpfT8nYsIEkm5bflKbqa9qYfPa/Xz+zzJCw4SZF2Yx48JMIqMH9pN3W2sLB3fvsA7827dRWWxVCI90xJA5ZRpZU62+/rgRqQO6XaXU0OHLRFACjHK7n2Ev8+YZ4I8+jAeaq+Hvy3jIGceeEBePzP13UqJTvDZ37xKSPpYwaKo7wqevF7FzQwkI5C1MZ+ZXsgZs0LfT5aJs316K8rdyIP8zDu35nE5XB6Hh4aRPmMy8eeeRlTedEdk52s+vlOoTXyaCT4CxIjIaKwEsA651byAiY40xe+27lwB78RVXOzz3Td7sqOG5qHhunHwj8zLmeW3e3SW0cmWfuoRaG9vZ8mYR+f84iMtlmHhuGrMuzh6QKZ/GGPZ/toXtb71O8c58q2SyCCOyczjjksutfv4JEwkf5rsZRkqpoctnicAY0yEiK4E3saaPrjbG7BSR+4HNxpg1wEoRWQy0AzV46BYaMO8/RPHBD7kvK4epzvHcOfNOr027u4QmTjxhl9CRlg62vXWAz94upv2Ii3GzUzjzktHEj+j/hUe6EsA/n/8bpQVf4EhwMu6cuWTlTWfU5KkMj/XPRWuUUkObT8cIjDFrgbU9lt3rdvsuX27fXfuZN/P9ineQjmYeXPAg4SHe++q7u4SeeBzxMpum/YiL7e8Ws3XdAY40d5A7I5nZl+XgHNn/Mgo9E0BMUjIX3LqSyQsXERqms3uUUgMr4IPF/vJ4wYvsbCnntwt/S7rDey2g7i6hO1cSOaH3hdk62l3sfP8Qn76xn5aGdrKmJHLW0hySM/s/C0cTgFIqEIImESybsIzk4ckszlrstc0xXULLj+0S6uw07P7gEJvX7qex5gjp4+I567Yc0sbE9zs2TQBKqUAKmkTgjHRyzbhrjtum/JcPeO0S+mhNIVveKCJldCzn3zCRjPEJ/S6upglAKTUYBE0iOJH69eupf+01j11CtYeb2fbWAcadlcLib03SBKCUGlI0EWB1CZXd93MiJvXuEgL44IUCQkNDOPeqMf1KApoAlFKDkSYC7C6h+noyVz/Zq0vowM4q9m+v5Jwrc/t1UljZvr28s/pRTQBKqUEn6BNBd5fQd+4kcvz4Y9a5XJ1sfH4vcclRTDt/lJdnOD7T2cnmV19m4zNPMTw2ThOAUmrQCepEcEyX0K239lqf/+5BasqaueSOqYSGn3y5hsaaat545LcUbd/K2LPO5cLl3yHS4RiI0JVSasAEdSIo/8UvvXYJNde38cmrX5I52UlWnufrFBxP4dZPeOOR/6a9tZULbl1J3qKv6CUclVKDUtAmgvp166hfu9ZjlxDAplf20dHWydxrxp7UAbyjvZ0NT/+JLa+vISkzm0vv+gGJGQNzLWOllPKFoEwEHTU1lP38fiInTfLYJXS4qJ7dH5YybdEoElL7XjKiqqSY1373EBX7C5mx5DLmX3cjYX2sWqqUUoESlIngaJfQ6l5dQsYYNjy7lyhHOGde0reL0htj2PHuet7582OEDYvgih/8lNwzel2DRymlBqWgSwRdXULJd33H42Un93xcTllhHed9YwIRUSfePa1Njaxf9Qf2bNpI5pRpXLTiezicJz+moJRSgRJUicC9Syjxllt6rW9r7eCfLxUwIiuGieeknfD5Sj7fxWu/f4immmrmXfstzrzsKr0YjFLqtBNUiaD8F7/w2iUEsOWNIprq2lhyWx4S4n2AuLPTxUcvPcc/X/g7sSNGsOz+B0kb03vAWSmlTgdBkwjq31xH/drXvXYJ1VW0sO2tYsadlUJqjvcLvtRXVvD6H37Dwd07mDh3IYtuvoOI4f2/CI1SSgVK0CSCkKhIHAsWeOwSAvjghb1IqHDulWO8Psfejz5k3WO/w+VycdGK7zFp/vm+ClcppfwmaBKBY/58HPPne1xXvKuaLz+r5OwrcoiO91xPaPtbb7D+8T+QkjOWS+76PgmpI30ZrlJK+U3QJAJvXK5ONjy3h9jkKKYt8lxPqL6ygn/875Nk5k3nqnt+pnWClFJDStBPcdnxjxJqypqZe/UYwsJDe603xvD26j9iTCcXLl+pSUApNeQEdSJoaWjj41e/ZNQkJ9lTkzy22bPpAwo//Zg511xH3IhUP0eolFK+F9SJYNOaQjqOuLzWE2ptbOSdPz1KSs4YZl58eQAiVEop3wvaRFBxoIFdGw+RtzADZ5rnekLvP72aloZ6Llh+JyGhvbuNlFJqKAjKRGCMYcNze6x6Qpdme2xTvCuf/HfWccYlV5AyOte/ASqllB/5NBGIyBIR+UJECkTkHg/rvyciu0Rku4i8LSJZvoynS8Hmw5QW1HHW0hwihvce/O1oa2P9qj8QNyKFc6+51h8hKaVUwPgsEYhIKPAwcBEwCfi6iEzq0WwrMMsYMxV4AXjQV/F0aT/i4sOXCkjOjGHiHM/nAmx66VlqSktYfOtKwiMifR2SUkoFlC+/EcwGCowxhcaYNuAZ4JgRV2PMu8aYZvvuJiDDh/EAsOXNIhprjjDvq2MJ8VBPqPLAfj5Z8wKT5p1H9tQZvg5HKaUCzpeJIB0odrt/0F7mzc3A655WiMhyEdksIpsrKipOOaD6yha2rjvA2DNTSBsT32t9Z6eLdat+T8TwaBZ803MpCqWUGmoGxWCxiFwPzAIe8rTeGLPKGDPLGDMrOTn5lLfzwYsFSAice5Xnwd/P1q2ldO8XLLzhVobHei88p5RSQ4kvS0yUAO41GzLsZccQkcXAj4EFxpgjvgrm4OfVFG6t4KylOTgSevf711dWsOHvT5E9bSYT5y70VRhKKTXo+PIbwSfAWBEZLSLDgGXAGvcGIjIDeAxYaow57MNYaKo9QmKGg+kX9K4n5F5GYvEtd5zUxeqVUup057NvBMaYDhFZCbwJhAKrjTE7ReR+YLMxZg1WV5ADeN4++B4wxiz1RTzjz05j3OxUjxec6SojseD6m7SMhFIq6Pi0+qgxZi2wtseye91uL/bl9nvylAS0jIRSKtgNisHiQNIyEkqpYBfUiUDLSCilVBAngu4yEimpWkZCKRXUgjYRdJeRuGWFlpFQSgW1oEwEFV1lJOafr2UklFJBL+gSQWeni/WP2WUkvnFzoMNRSqmAC7pEsO3NtZQWaBkJpZTqElSJoL6ygo3PaBkJpZRyFzSJwBjD208+omUklFKqh6BJBHs2baRwyyfMueY6LSOhlFJugiYRREQNJ3fW2VpGQimlevBpraHBJHv6GWRPPyPQYSil1KATNN8IlFJKeaaJQCmlgpwmAqWUCnKaCJRSKshpIlBKqSCniUAppYKcJgKllApymgiUUirIiTEm0DGcFBGpAIpO8eFJQOUAhjPQNL7+0fj6b7DHqPGduixjTLKnFaddIugPEdlsjJkV6Di80fj6R+Prv8Eeo8bnG9o1pJRSQU4TgVJKBblgSwSrAh3ACWh8/aPx9d9gj1Hj84GgGiNQSinVW7B9I1BKKdWDJgKllApyQzIRiMgSEflCRApE5B4P6yNE5Fl7/Uciku3H2EaJyLsisktEdorIXR7aLBSROhHZZv/c66/47O3vF5F8e9ubPawXEfmdvf+2i8hMP8Y23m2/bBORehG5u0cbv+8/EVktIodFZIfbMqeIrBeRvfbvBC+PvcFus1dEbvBTbA+JyOf2/+9lEYn38tjjvhZ8HON9IlLi9n+82Mtjj/t+92F8z7rFtl9Etnl5rF/2Yb8YY4bUDxAK7ANygGHAZ8CkHm3uAB61by8DnvVjfGnATPt2DLDHQ3wLgVcDuA/3A0nHWX8x8DogwNnARwH8X5dhnSgT0P0HzAdmAjvclj0I3GPfvgf4tYfHOYFC+3eCfTvBD7FdCITZt3/tKba+vBZ8HON9wL/24TVw3Pe7r+Lrsf43wL2B3If9+RmK3whmAwXGmEJjTBvwDNDzQsWXA3+xb78ALBIR8UdwxphSY8wW+3YDsBtI98e2B9DlwFPGsgmIF5G0AMSxCNhnjDnVM80HjDHmfaC6x2L319lfgCs8PPQrwHpjTLUxpgZYDyzxdWzGmHXGmA777iYgYyC3ebK87L++6Mv7vd+OF5997Pgq8PeB3q6/DMVEkA4Uu90/SO8DbXcb+81QByT6JTo3dpfUDOAjD6vPEZHPROR1EZns18DAAOtE5FMRWe5hfV/2sT8sw/ubL5D7r0uKMabUvl0GpHhoMxj25U1Y3/A8OdFrwddW2t1Xq710rQ2G/TcPKDfG7PWyPtD78ISGYiI4LYiIA3gRuNsYU99j9Ras7o5pwO+B//NzeHONMTOBi4AVIjLfz9s/IREZBiwFnvewOtD7rxdj9REMurnaIvJjoAN42kuTQL4W/gjkAtOBUqzul8Ho6xz/28Cgfz8NxURQAoxyu59hL/PYRkTCgDigyi/RWdsMx0oCTxtjXuq53hhTb4xptG+vBcJFJMlf8RljSuzfh4GXsb5+u+vLPva1i4AtxpjynisCvf/clHd1mdm/D3toE7B9KSLfAi4FrrMTVS99eC34jDGm3BjjMsZ0Ao972XZAX4v28eMq4FlvbQK5D/tqKCaCT4CxIjLa/tS4DFjTo80aoGt2xtXAO97eCAPN7k98EthtjPkvL21Su8YsRGQ21v/JL4lKRKJFJKbrNtag4o4ezdYA37RnD50N1Ll1gfiL109hgdx/Pbi/zm4AXvHQ5k3gQhFJsLs+LrSX+ZSILAF+ACw1xjR7adOX14IvY3Qfd7rSy7b78n73pcXA58aYg55WBnof9lmgR6t98YM1q2UP1myCH9vL7sd60QNEYnUpFAAfAzl+jG0uVhfBdmCb/XMxcDtwu91mJbATawbEJuBcP8aXY2/3MzuGrv3nHp8AD9v7Nx+Y5ef/bzTWgT3ObVlA9x9WUioF2rH6qW/GGnd6G9gLvAU47bazgCfcHnuT/VosAG70U2wFWH3rXa/Brll0I4G1x3st+HH//a/9+tqOdXBP6xmjfb/X+90f8dnL/9z1unNrG5B92J8fLTGhlFJBbih2DSmllDoJmgiUUirIaSJQSqkgp4lAKaWCnCYCpZQKcpoIlPIjuzLqq4GOQyl3mgiUUirIaSJQygMRuV5EPrZryD8mIqEi0igivxXrOhJvi0iy3Xa6iGxyq+2fYC8fIyJv2cXvtohIrv30DhF5wb4ewNP+qnyrlDeaCJTqQUQmAl8D5hhjpgMu4DqsM5o3G2MmA+8BP7Mf8hTwQ2PMVKwzYbuWPw08bKzid+dinZkKVsXZu4FJWGeezvH5H6XUcYQFOgClBqFFwBnAJ/aH9SisgnGdHC0u9lfgJRGJA+KNMe/Zy/8CPG/Xl0k3xrwMYIxpBbCf72Nj16axr2qVDWz0/Z+llGeaCJTqTYC/GGN+dMxCkZ/2aHeq9VmOuN12oe9DFWDaNaRUb28DV4vICOi+9nAW1vvlarvNtcBGY0wdUCMi8+zl3wDeM9bV5w6KyBX2c0SIyHC//hVK9ZF+ElGqB2PMLhH5CdZVpUKwKk6uAJqA2fa6w1jjCGCVmH7UPtAXAjfay78BPCYi99vPcY0f/wyl+kyrjyrVRyLSaIxxBDoOpQaadg0ppVSQ028ESikV5PQbgVJKBTlNBEopFeQ0ESilVJDTRKCUUkFOE4FSSgW5/wcTGw2wzr6CxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7444 - accuracy: 0.7482\n",
      "CNN Test accuracy: 0.748199999332428\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7481 - accuracy: 0.3940\n",
      "0 Dense NN Test accuracy: 0.39399999380111694\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4693 - accuracy: 0.4854\n",
      "1 Dense NN Test accuracy: 0.48539999127388\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5370 - accuracy: 0.4550\n",
      "2 Dense NN Test accuracy: 0.45500001311302185\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6564 - accuracy: 0.4309\n",
      "3 Dense NN Test accuracy: 0.4309000074863434\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8226 - accuracy: 0.3897\n",
      "4 Dense NN Test accuracy: 0.3896999955177307\n"
     ]
    }
   ],
   "source": [
    "legendName = ['Conv']\n",
    "for i in range(5):\n",
    "  legendName.append(str(i)+\" DNN\")    \n",
    "# Plot training accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "for i in dense_nn:\n",
    "  plt.plot(i.history['accuracy'])\n",
    "plt.title('training accuracy')\n",
    "plt.ylabel('training accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(legendName, loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "for i in dense_nn:\n",
    "  plt.plot(i.history['val_accuracy'])\n",
    "plt.title('validation accuracy')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(legendName, loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the best model saved (i.e., model with best validation accuracy) on the test set\n",
    "saved_model = load_model('best_model_3_DO_noDA_rmsopt_relu')\n",
    "scores = saved_model.evaluate(x_test, y_test, verbose=1)\n",
    "print('CNN Test accuracy:', scores[1])\n",
    "\n",
    "for i in range(5):\n",
    "  scores = load_model('best_model_'+str(i)).evaluate(x_test, y_test, verbose=1)\n",
    "  print(str(i)+' Dense NN Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1F1ghueG9UGo"
   },
   "source": [
    "### Explanation:\n",
    "\n",
    "In the graph, one can see that CNN has the best accuracy for both training and the validation set and outperforms any of the dense neural networks. This is because when using dense neural network, information in the 2d dimension is lost and flattened into 1d, while the CNN uses convolutions and max pooling to capture information in 2d. \n",
    "\n",
    "For Dense neural network, ignoring the 0 hidden layer for now, the accuracy is ranked descendingly with 1 hidden layer, 2 hidden layers, 3 hidden layers, and 4 hidden layers. So with more hidden layers, the accuracy decreases. This could be due to needing more epochs and data to optimize more complex models. It may also be due to the fact that we are using drop out rate of 0.5, which makes training more as the number of layers increase.\n",
    "\n",
    "The neural network with 0 hidden layer performed worse than DNNs with 1 or 2 hidden layers, this could mean the data is not linearly separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV9GmEx0zIoU"
   },
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ExigdvhONMnQ",
    "outputId": "b503b25e-5a32-426d-ec4d-a7be5c2d7122"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Not using data augmentation.\n",
      "Epoch 1/20\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 2.3341 - accuracy: 0.1012\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.09800, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.3339 - accuracy: 0.1012 - val_loss: 2.3082 - val_accuracy: 0.0980\n",
      "Epoch 2/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 2.3078 - accuracy: 0.1009\n",
      "Epoch 00002: val_accuracy improved from 0.09800 to 0.10160, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.3078 - accuracy: 0.1010 - val_loss: 2.3042 - val_accuracy: 0.1016\n",
      "Epoch 3/20\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 2.3063 - accuracy: 0.0998\n",
      "Epoch 00003: val_accuracy did not improve from 0.10160\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3063 - accuracy: 0.0998 - val_loss: 2.3035 - val_accuracy: 0.0977\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.3049 - accuracy: 0.1004\n",
      "Epoch 00004: val_accuracy did not improve from 0.10160\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3049 - accuracy: 0.1004 - val_loss: 2.3032 - val_accuracy: 0.0997\n",
      "Epoch 5/20\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 2.3046 - accuracy: 0.1012\n",
      "Epoch 00005: val_accuracy did not improve from 0.10160\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3046 - accuracy: 0.1011 - val_loss: 2.3041 - val_accuracy: 0.1014\n",
      "Epoch 6/20\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 2.3038 - accuracy: 0.0985\n",
      "Epoch 00006: val_accuracy did not improve from 0.10160\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3038 - accuracy: 0.0985 - val_loss: 2.3032 - val_accuracy: 0.0952\n",
      "Epoch 7/20\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 2.3036 - accuracy: 0.0995\n",
      "Epoch 00007: val_accuracy did not improve from 0.10160\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.3036 - accuracy: 0.0996 - val_loss: 2.3028 - val_accuracy: 0.1014\n",
      "Epoch 8/20\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 2.2678 - accuracy: 0.1309\n",
      "Epoch 00008: val_accuracy improved from 0.10160 to 0.23300, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 2.2670 - accuracy: 0.1314 - val_loss: 2.1296 - val_accuracy: 0.2330\n",
      "Epoch 9/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 2.0776 - accuracy: 0.2427\n",
      "Epoch 00009: val_accuracy improved from 0.23300 to 0.28820, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 2.0776 - accuracy: 0.2428 - val_loss: 1.9875 - val_accuracy: 0.2882\n",
      "Epoch 10/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.9753 - accuracy: 0.2880\n",
      "Epoch 00010: val_accuracy improved from 0.28820 to 0.32900, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.9752 - accuracy: 0.2880 - val_loss: 1.8929 - val_accuracy: 0.3290\n",
      "Epoch 11/20\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.9032 - accuracy: 0.3156\n",
      "Epoch 00011: val_accuracy improved from 0.32900 to 0.34480, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.9027 - accuracy: 0.3158 - val_loss: 1.8337 - val_accuracy: 0.3448\n",
      "Epoch 12/20\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.8538 - accuracy: 0.3339\n",
      "Epoch 00012: val_accuracy improved from 0.34480 to 0.35880, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.8537 - accuracy: 0.3338 - val_loss: 1.7943 - val_accuracy: 0.3588\n",
      "Epoch 13/20\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.8256 - accuracy: 0.3451\n",
      "Epoch 00013: val_accuracy improved from 0.35880 to 0.36050, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.8254 - accuracy: 0.3453 - val_loss: 1.7741 - val_accuracy: 0.3605\n",
      "Epoch 14/20\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.7984 - accuracy: 0.3546\n",
      "Epoch 00014: val_accuracy improved from 0.36050 to 0.37550, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.7987 - accuracy: 0.3544 - val_loss: 1.7396 - val_accuracy: 0.3755\n",
      "Epoch 15/20\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.7685 - accuracy: 0.3642\n",
      "Epoch 00015: val_accuracy improved from 0.37550 to 0.38620, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.7683 - accuracy: 0.3643 - val_loss: 1.7203 - val_accuracy: 0.3862\n",
      "Epoch 16/20\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.7461 - accuracy: 0.3758\n",
      "Epoch 00016: val_accuracy improved from 0.38620 to 0.39360, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.7465 - accuracy: 0.3757 - val_loss: 1.6969 - val_accuracy: 0.3936\n",
      "Epoch 17/20\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.7220 - accuracy: 0.3838\n",
      "Epoch 00017: val_accuracy improved from 0.39360 to 0.40170, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.7210 - accuracy: 0.3841 - val_loss: 1.6647 - val_accuracy: 0.4017\n",
      "Epoch 18/20\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.7000 - accuracy: 0.3926\n",
      "Epoch 00018: val_accuracy improved from 0.40170 to 0.41150, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6995 - accuracy: 0.3927 - val_loss: 1.6567 - val_accuracy: 0.4115\n",
      "Epoch 19/20\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.6727 - accuracy: 0.4020\n",
      "Epoch 00019: val_accuracy improved from 0.41150 to 0.41930, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6725 - accuracy: 0.4020 - val_loss: 1.6212 - val_accuracy: 0.4193\n",
      "Epoch 20/20\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.6536 - accuracy: 0.4068\n",
      "Epoch 00020: val_accuracy improved from 0.41930 to 0.42500, saving model to best_model_3_DO_noDA_rmsopt_sigmoid\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_sigmoid/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.6537 - accuracy: 0.4069 - val_loss: 1.6045 - val_accuracy: 0.4250\n"
     ]
    }
   ],
   "source": [
    "history_sigmoid = create_model(activation=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "OCgW5lxh2Hap",
    "outputId": "5f488ad3-37e0-451c-902e-d11f0e6d596d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5dn48e+dHZKQhRCWBEiQTZA9gAoVWzdsVVwrWCu4oVXbqrWtXV6l1t9btVbtglrcq/bFpS64IHWtxRYkICC7EAIkrEkgJIHs9++PcxKGmIQBMjmZmftzXXPNWZ6Zc2cy89znPOec5xFVxRhjTPiK8DoAY4wx3rJEYIwxYc4SgTHGhDlLBMYYE+YsERhjTJizRGCMMWHOEoEJeiLyuIj8T1uXNSZciN1HYLwkIvnAdar6gdexGBOu7IjAdGgiEuV1DMHAPidzPCwRGM+IyPNAH+AtESkXkZ+JSJaIqIhcKyJbgY/csq+IyE4RKRWRT0VkqM/7PCsi97rTp4tIgYj8RER2i8gOEbn6GMt2FZG3RGS/iCwRkXtFZGErf09rMXYSkT+IyBZ3/UIR6eSumygi/xGRfSKyTURmuMs/EZHrfN5jhu/23c/pZhH5CvjKXfZH9z32i8hSEfmGT/lIEfmliGwSkTJ3fW8RmS0if2jyt8wTkdv8/FeaIGeJwHhGVb8PbAXOV9UEVX3AZ/Uk4ETgHHd+PjAASAeWAS+28tY9gCQgA7gWmC0iKcdQdjZQ4ZaZ7j5a01qMDwJjgFOBVOBnQL2I9HVf92egGzASWH6E7fi6EBgPDHHnl7jvkQr8HXhFROLcdbcD04BvA12Aa4ADwHPANBGJABCRNOBM9/UmHKiqPezh2QPIB870mc8CFOjXymuS3TJJ7vyzwL3u9OnAQSDKp/xu4OSjKQtEAjXAIJ919wIL/fy7GmPE2eE6CIxoptwvgNdbeI9PcM6fNMzP8N2++/7fOkIcexu2C6wHprRQbi1wljt9C/Cu198Ne7Tfw44ITEe1rWHCbdK4z23S2I+TPADSWnhtsarW+swfABKOsmw3IMo3jibThzlCjGlAHLCpmZf2bmG5vw6LSUTuEJG1bvPTPpxE1PA5tbat54Ar3ekrgeePIyYTZCwRGK+1dNma7/IrgCk4zRVJOEcNABK4sNgD1AKZPst6t1K+tRiLgErghGZet62F5eA0S3X2me/RTJnGz8k9H/Az4LtAiqomA6Uc+pxa29YLwBQRGYHTJPdGC+VMCLJEYLy2C+h3hDKJQBVQjFMx/m+gg1LVOuA1YJaIdBaRwcBVxxKjqtYDTwMPiUgv9+jhFBGJxTmPcKaIfFdEotwT1CPdly4HLna33x/nHEZrEnGS1x4gSkTuwjkX0OBJ4LciMkAcw0WkqxtjAc75heeBf6jqwSN+SCZkWCIwXvsd8Gv3ipk7WijzN2ALUAisARa1U2y34Ozd78SpIP8Pp7JvzpFivAP4EqeyLQHuByJUdSvOydufuMuXAyPc1zwMVOMky+do/QQ5wALgPWCDG0slhzcdPQS8DPwT2A88BXTyWf8cMAxrFgo7dkOZMX4SkfuBHqp6pKuHgpKInIbTRNRXrWIIK3ZEYEwLRGSw23wiIjIOp2nmda/jCgQRiQZ+DDxpSSD8WCIwpmWJOOcJKoCXgD8Ab3oaUQCIyInAPqAn8IjH4RgPWNOQMcaEOTsiMMaYMBd0HVWlpaVpVlaW12EYY0xQWbp0aZGqdmtuXdAlgqysLHJzc70OwxhjgoqIbGlpnTUNGWNMmLNEYIwxYc4SgTHGhLmgO0fQnJqaGgoKCqisrPQ6FNOCuLg4MjMziY6O9joUY0wTIZEICgoKSExMJCsrC5FAdkhpjoWqUlxcTEFBAdnZ2V6HY4xpIiSahiorK+nataslgQ5KROjatasdsRnTQYVEIgAsCXRw9v8xpuMKiaYhY4wJFapKWVUtRWVVFFdUU1RWRZH7fMaJ6QzPTG7zbVoiMMaYAFNVSiqq2V1WRVF5FcXl1RSVV1HkPhe708XlTqVfXVvf7Pt0S4y1RNDR7dy5k1tvvZUlS5aQnJxM9+7deeSRRxg4cKDXoTXekZ2W1tIwv8aY47W/sob8ogo2F1WQt8d5zi+uYPOeCsqqar9WPjpS6BofS1piDF3jYxnYPZG0hBjSEmLp6vPcLSGWlPgYoiMD05pviaCNqCoXXXQR06dPZ+7cuQCsWLGCXbt2tVsiqKurIzIysl22ZUy4qqypY0vxATYXlZNXVNFY8W8uqqCovLqxnAhkJHciOy2ei0ZnkNU1nh5JcXSNjyEtMZa0+Fi6dIrqEOfPQi4R/Oat1azZvr9N33NIry7cff7QVst8/PHHREdHc+ONNzYuGzFiBKrKT3/6U+bPn4+I8Otf/5rLL7+cTz75hFmzZpGWlsaqVasYM2YML7zwAgsWLOCpp57ilVdeAeCTTz7hwQcf5O233252uwkJCdxwww188MEHzJ49m/z8fP70pz9RXV3N+PHjefTRRw9LDvn5+Zx33nmsWrUKgAcffJDy8nJmzZp1nJ+SMcGhvl45UFNHRVUtZZW1VFTVUt7wqKylorr55fsra9hWcpDtpQfx7b2/W2Is2WnxnDG4O9nd4slOi6dfWjy9UzsTFx0cO2Yhlwi80lCZN/Xaa6+xfPlyVqxYQVFREWPHjuW0004D4IsvvmD16tX06tWLCRMm8Nlnn3HmmWcyc+ZMKioqiI+P56WXXmLq1KktbreiooLx48fzhz/8gbVr13L//ffz2WefER0dzU033cSLL77IVVe1Nua6MaFDVdl7oIYtxRVsLTnA1uIDbCk5wNaSAxTuPUjpwRoqqmvxZxiWqAghIS6K+JgoEuOiSIiNYlx2Klld48nu5lT2fbt2JjEu+G+SDLlEcKQ99/a2cOFCpk2bRmRkJN27d2fSpEksWbKELl26MG7cODIzMwEYOXIk+fn5TJw4kcmTJ/PWW29x6aWX8s477/DAAw+0+P6RkZFccsklAHz44YcsXbqUsWPHAnDw4EHS09MD/0ca045q6+rZUVrJluIDbCnxqfCLD7Ct5MDX2uK7d4mlb2o84/ulktwphoS4KBJiI0mIjSY+NpJEt7JPcCv7+FjnOTYqokM027SHkEsEXhk6dCivvvrqUb0mNja2cToyMpLaWucLPHXqVP7yl7+QmppKTk4OiYmJLb5HXFxcY9OPqjJ9+nR+97vftVg+KiqK+vpDVyTYTV6mI6mpq6eovIpd+6vYtb+S3fsr2bm/snG+Yc++tv7QLn1MZASZqZ3om9qZcdmp9E7tTN/UzvTt2pnMlM50igmO5hkvWSJoI9/61rf45S9/yZw5c5g5cyYAK1euJDk5mZdeeonp06dTUlLCp59+yu9//3vWrVvX4ntNmjSJa665hieeeKLVZqGmzjjjDKZMmcJtt91Geno6JSUllJWV0bdv38Yy3bt3Z/fu3RQXF5OQkMDbb7/N5MmTj/0PN8YPqkpRebVTuZc5FfvO0kPTu9zKvrii6mvNNpERQnpiLOld4hiWkcR5w3vSJ7UzfVKdppkeXeKIiAiPPfdAsUTQRkSE119/nVtvvZX777+fuLg4srKyeOSRRygvL2fEiBGICA888AA9evRoNRFERkZy3nnn8eyzz/Lcc8/5HcOQIUO49957Ofvss6mvryc6OprZs2cflgiio6O56667GDduHBkZGQwePPi4/m5jwGmu2VVWReHegxTuO0BByUEK97mPvc5zVTPXxqclxNC9Sxzdu8QxPDOJ9MQ4dz62cXlqfAyRVtEHVNANXp+Tk6NNRyhbu3YtJ554okcRGX/Z/yl41dUrBXsPULD3IAV7neaZAp9KfkdpJXX1h9claQkxZCR3IiOlk/Oc3IkeSZ0aK/luibEBuy7efJ2ILFXVnObW2RGBMeYwe8qqWL+zjHU797N+Zxnrd5WxYVcZlTWH9ugjBLp3iSMjuRM5fVPcyr7zYZW+tc0HD0sEQWL8+PFUVVUdtuz5559n2LBhHkVkgt2B6lo27Cpn/c79rNtZ5lT6O8sorjh0U1RaQgyDeiRyxbi+DOqRQJ/UeDJTOtEjKc725kOIJYIgsXjxYq9DMEGovl7ZU17Fdre9fsPOMqfS31XG1pIDjSdmO0VHMrB7AmecmM6gHl0Y3CORQT0SSUuIbX0DJiQENBGIyGTgj0Ak8KSq3tdk/cPAN93ZzkC6qrZ9j0rGhKCGm6e27zvIdredfnvpQXbsq2RH6UG276tk1/7Kwy61jBDISotnaK8uXDwqk0E9EhncI5E+qZ3typswFrBEICKRwGzgLKAAWCIi81R1TUMZVb3Np/wPgVGBiseYYFVRVUvulr0s27KXgr0H2VHqVvrNXIkTHSn0SIqjZ1Inxmal0DO5E73c+V7JnejXLT5ouj0w7SeQRwTjgI2qmgcgInOBKcCaFspPA+4OYDzGBIWGin9RXjGL8opZWVBKXb0SIZCeGEfP5DiG9OzCGYPT6ZnciYxkp6LvmRxHWnys7dmboxbIRJABbPOZLwDGN1dQRPoC2cBHAYzHmA6pvKqW3PwSFuWVsCivmC8LnYo/KkIY0TuZGyf14+R+XRnTN4XOMXZaz7S9jvKtmgq8qqp1za0UkZnATIA+ffq0Z1xHpaOMR3DXXXdx2mmnceaZZwZsG9dddx233347Q4YMOWz5s88+S25uLn/5y18Ctu1gZxW/6WgC+S0rBHr7zGe6y5ozFbi5pTdS1TnAHHBuKGurANtSRxiPoME999wT8G08+eSTAd9GKFBVdu6vZMW2fXyxbR+L80oOq/hH9k7mB5NO4OR+XRndN9kqfuOJQH7rlgADRCQbJwFMBa5oWkhEBgMpwH/bZKvz74SdX7bJWzXqMQzOva/VIl6MR1BXV8e1115Lbm4uIsI111zDbbfdxowZMzjvvPO49NJLeffdd7n99tuJj49nwoQJ5OXl8fbbbzNr1iw2b95MXl4eW7du5eGHH2bRokXMnz+fjIwM3nrrLaKjo/nwww+54447qK2tZezYsTz22GPExsZy+umn8+CDD5KTk8MzzzzD7373O5KTkxkxYsRhnemFm70V1awsLGXltn2sKNjHioJS9pQ5939YxW86qoB9C1W1VkRuARbgXD76tKquFpF7gFxVnecWnQrM1WDr66IJL8YjWL58OYWFhY2DzOzbt++w9ZWVldxwww18+umnZGdnM23atMPWb9q0iY8//pg1a9Zwyimn8I9//IMHHniAiy66iHfeeYfJkyczY8YMPvzwQwYOHMhVV13FY489xq233tr4Hjt27ODuu+9m6dKlJCUl8c1vfpNRo8Lj4q8D1bWsKtzPSrfCX7FtH1tLDjSu79ctnon90xiRmcTw3skM6dnFrtgxHVJAd0dU9V3g3SbL7moyP6tNN3qEPff2FsjxCPr160deXh4//OEP+c53vsPZZ5992Pp169bRr18/srOzAZg2bRpz5sxpXH/uuecSHR3NsGHDqKura+yFdNiwYeTn57N+/Xqys7Mbm7amT5/O7NmzD0sEixcv5vTTT6dbt24AXH755WzYsKGNPr2Oo7aunnU7y1i+bR8rC/axsqCUDbvKaLhEv1dSHMMzk5k2rg8jMpM4KTOJLiEwYIkJD3Zc2ka8GI8gJSWFFStWsGDBAh5//HFefvllnn766aPefkREBNHR0Y2DcERERDTGEq4OVtfxxda9LMnfy5L8EpZt3cuBaudahpTO0QzPTObsId0Z0TuZ4ZnJdEsM3+YwE/wsEbQRL8YjKCoqIiYmhksuuYRBgwZx5ZVXHrZ+0KBB5OXlkZ+fT1ZWFi+99NJR/U2DBg0iPz+fjRs30r9/f55//nkmTZp0WJnx48fz4x//mOLiYrp06cIrr7zCiBEjjmo7HUFJRTW5+SUsyS9hSf5eVhWWUluviMDgHl24dEwmY/qmMLpPCpkpncJm5CoTHiwRtBEvxiMoLCzk6quvbhxxrOnIZJ06deLRRx9l8uTJxMfHNw5h6a+4uDieeeYZLrvsssaTxb4nwwF69uzJrFmzOOWUU0hOTmbkyJFHtQ0vqCoFew+6lb5T8W/cXQ44o12N6J3EzNP6MTYrldF9U0jqZE08JrTZeAQhrry8nISEBFSVm2++mQEDBnDbbbcd+YUB4NX/qb5eWb+rrLHSX7K5hJ37nSE6E+OiyOmbwtjsVMZmpTIsI8lO6JqQZOMRhLEnnniC5557jurqakaNGsUNN9zgdUgBV1Vbx8qCUqfi31xC7pa9lFU65zx6dIljbHYq47JSyMlKZVD3ROuSwYQ9SwRB4ljHI7jttts8OwJoL6UHa1i2ZW9jU8+KglKq3c7YBqQncN7wXozLTiGnb6q17xvTjJBJBKoa0j/wYB+PoC2bIHeWVjZW+p9vLmH9rjJUnRu2TspIYsapWeT0dfb4U+Nj2my7xoSqkEgEcXFxFBcX07Vr15BOBsFKVSkuLiYuLu6YXl9dW88n63fz3uqdLMkvYVvJQQA6x0Qypm8K557Uk7HZKYzsbXfqGnMsQuJXk5mZSUFBAXv27PE6FNOCuLi4xpvn/KGqLN2yl9e/KOSdL3ew70ANKZ2jGZ/dlRmnZjMuK5UTeyYSZcMlGnPcQiIRREdHN949a4Lbxt3lvPFFIW8sL6Rg70HioiM4Z2gPLhyVwcT+aTZOrjEBEBKJwAS33WWVvLViB298UciXhaVECEwc0I2fnD2Qs4f0ID7WvqbGBJL9wownKqpqWbB6J69/UchnG4uoVxiWkcT/nDeE80f0JD3x2M4nGGOOniUC025q6upZ+FURr39RyPtrdnGwpo7MlE7c/M3+TBmZQf/0BK9DNCYsWSIwAbd6eymvLi1g3vLtFFdUk9w5motHZ3DRqAzG9E2xK72M8ZglAhMQReVVvLl8O68uLWDtjv3EREZw5pB0LhqVyaSB3YiJspO+xnQUlghMm6murefj9bt5dWkBH6/bTW29MiIzid9OGcr5I3qR3Nlu7jKmI7JEYI5bQ9PPm8u3U1JRTbfEWK6dmM0lYzIZ2L35sRSMMR2HJQJzTIrKq3jji0JeXVrAup1lxERGcNbQ7lw6JpNv9E+zG72MCSKWCIzfqmvr+Wid0/TzyXq36ad3Mr+98CTOH97Tmn6MCVKWCMwRlVRU8+xnm3l+0Rb2HqghPTGWa7+RzaWjMxlgTT/GBD1LBKZFO0oP8sSnm/m/z7dysKaOs4d054rxfZhoTT/GhBRLBOZrNhdV8Pgnm3jtiwLqFS4cmcEPTu9H/3Tb+zcmFAU0EYjIZOCPQCTwpKre10yZ7wKzAAVWqOoVgYzJtGz19lIe/WQT87/cQXRkBFeM68P1p/UjM6Wz16EZYwIoYIlARCKB2cBZQAGwRETmqeoanzIDgF8AE1R1r4ikByoe07Il+SXM/ngjn6zfQ2JsFDdMOoFrJmTTLTHW69CMMe0gkEcE44CNqpoHICJzgSnAGp8y1wOzVXUvgKruDmA8xoeq8smGPTz28SY+zy8hNT6Gn54ziCtP7ktSp2ivwzPGtKNAJoIMYJvPfAEwvkmZgQAi8hlO89EsVX2v6RuJyExgJkCfPn0CEmy4qKtX5q/awaMfb2LNjv30Sopj1vlDuHxsHzrFRHodnjHGA16fLI4CBgCnA5nApyIyTFX3+RZS1TnAHICcnJy2G/w2jNTU1fP6skIe+9cmNhdV0K9bPA9cOpwLR2ZYvz/GhLlAJoJCoLfPfKa7zFcBsFhVa4DNIrIBJzEsCWBcYUVVmb9qJw+8t4784gOclNGFR783mnOG9iAywnr9NMYENhEsAQaISDZOApgKNL0i6A1gGvCMiKThNBXlBTCmsLI4r5jfzV/H8m37GNg9gaem5/CtwenW7bMx5jABSwSqWisitwALcNr/n1bV1SJyD5CrqvPcdWeLyBqgDvipqhYHKqZw8dWuMu5/bx0frN1Njy5xPHDJcC4Zk2lHAMaYZolqcDW55+TkaG5urtdhdEi79lfy8PsbeDl3G/ExUdx4unMZqJ0ENsaIyFJVzWlundcni00bKKus4a//yuPJhXnU1SvTT83ih98aQGq8dQJnjDkySwRBrLq2nr8v3sKfPtpISUU1F4zoxR1nD6JPV7sT2BjjP0sEQUhVeefLHfx+wXq2FB/glH5d+cW3BzM8M9nr0IwxQcgSQZD576Zi7pu/lhUFpQzukcgzV4/l9IHd7EogY8wxs0QQJAr2HuCuN1fz0brd9EyK4/eXDufi0XYlkDHm+B0xEYjIUuBp4O8NfQKZ9rUor5ibXlxGdW09P588mKsnZBEXbVcCGWPahj99C1wO9MLpPXSuiJwj1g7Rbl5YtIUrn1xMcudo5t0ygR+cfoIlAWNMmzpiIlDVjar6K5y7fv+Oc3SwRUR+IyKpgQ4wXNXU1fPrN77k12+sYuKANN64eQL9uiV4HZYxJgT5dY5ARIYDVwPfBv4BvAhMBD4CRgYsujBVXF7FTS8uY/HmEm6Y1I+fnTPYzgUYYwLG33ME+4CngDtVtcpdtVhEJgQyuHC0dsd+rnsulz3lVTx8+QguGpXpdUjGmBDnzxHBZQ2DyzSlqhe3cTxh7b1VO7j95RUkxkXxyg2nMKK33RdgjAk8f04WXycijTWSiKSIyL0BjCns1NcrD7+/gRtfWMbA7om8dctESwLGmHbjTyI413egGPcS0m8HLqTwUlFVy00vLuOPH37FJaMzmTvzZNK7xHkdljEmjPjTNBQpIrEN5wZEpBNgo5q3gW0lB7j+b7ls2FXGr79zItdOzLY7hI0x7c6fRPAi8KGIPOPOXw08F7iQwkPDTWK1dfU8c/U4Jg3s5nVIxpgwdcREoKr3i8hK4Ax30W9VdUFgwwptLyzawqx5q+nTtTNPXpVj9wcYYzzl130EqjofmB/gWEJeTV09v3lrNS8s2so3B3Xjj9NG0SUu2uuwjDFhzp/7CE4G/gycCMTgDDtZoapdAhxbSNlbUc2NLyxl8eYSbpx0Aj89Z5DdJGaM6RD8OSL4C87A868AOcBVON1NGD8dqK5lxrNLWLtjP49cPpILR2V4HZIxxjTy5/JRVHUjEKmqdar6DDA5sGGFjpq6en7wwjK+LNjH7CtGWxIwxnQ4/hwRHBCRGGC5iDwA7MDPBBLu6uuVn726kn9t2MP9lwzjrCHdvQ7JGGO+xp8K/ftuuVuACqA3cIk/by4ik0VkvYhsFJE7m1k/Q0T2iMhy93Hd0QTf0d333jpe/6KQn54ziMvH9vE6HGOMaVarRwQiEgn8r6p+D6gEfuPvG7uvnQ2cBRTgjGcwT1XXNCn6kqrecnRhd3xzPt3EnE/zmHFqFjedfoLX4RhjTItaPSJQ1Tqgr9s0dLTGARtVNU9Vq4G5wJRjeJ+g89qyAv733XV8Z3hP7jpviN0tbIzp0Pw5R5AHfCYi83CahgBQ1YeO8LoMYJvPfAEwvplyl4jIacAG4DZV3da0gIjMBGYC9OnTsZtYPl6/m5+9upIJ/bvy0HdHEGGXiBpjOjh/zhFsAt52yyb6PNrCW0CWqg4H3qeFritUdY6q5qhqTrduHbcrhi+27uWmF5YxuGcij185htgoG1LSGNPx+dPFhN/nBZooxDmx3CDTXeb73sU+s08CDxzjtjy3cXcZVz+7hPQusTwzYxyJdsewMSZI+HNn8ceANl2uqt86wkuXAANEJBsnAUwFrmjy3j1VdYc7ewGw1p+gO5odpQe56qnPiYqI4G/XjKNbonXOaowJHv6cI7jDZzoO59LR2iO9SFVrReQWYAFOtxRPq+pqEbkHyFXVecCPROQC9/1KgBlHGb/nSg/UMP3pz9lfWcvcmSfTt2u81yEZY8xREdWv7ewf+UUin6vquADEc0Q5OTmam5vrxaa/prKmjiufXMzKglKevXosp/ZP8zokY4xplogsVdWc5tb50zSU6jMbAYwBktootqBVW1fPLX//gqVb9/KXaaMtCRhjgpY/TUNLcc4RCE4Tzmbg2kAG1dGpKr96fRUfrN3Fb6cM5TvDe3odkjHGHDN/rhrKbo9Agskf/rmBl3K38aNv9ef7p2R5HY4xxhyXI95HICI3i0iyz3yKiNwU2LA6rmc/28xfPt7ItHF9uO0s643bGBP8/Lmh7HpV3dcwo6p7gesDF1LHNW/Fdn7z9hrOGdqdey88ybqOMMaEBH8SQaT41HhuZ3LH0vdQUFu6ZS8/eXk5Y7NS+ePUUTa6mDEmZPhzsvg94CUR+as7f4O7LKw88sEGUjrH8MRVOcRFW9cRxpjQ4U8i+DlOh28/cOffx+kOImys31nGv78q4qfnDCKpk3UdYYwJLf4kgk7AE6r6ODQ2DcUCBwIZWEfy9MLNxEVHcMW4jt3zqTHGHAt/zhF8iJMMGnQCPghMOB1PcXkVry8v5OLRmaTEh92pEWNMGPAnEcSpannDjDvdOXAhdSwvLt5KdW0910yw2ymMMaHJn0RQISKjG2ZEZAxwMHAhdRxVtXX87b9bOH1QN/qnJ3gdjjHGBIQ/5whuBV4Rke043Uz0AC4PaFQdxFsrdlBUXsW1E+1owBgTuvzpYmKJiAwGBrmL1qtqTWDD8p6q8tTCzQzsnsBE61DOGBPC/DkiACcJDMEZj2C0iKCqfwtcWN77b14xa3fs576Lh9kdxMaYkOZPN9R3A6fjJIJ3gXOBhUBIJ4KnF+aTGh/DhaMyvA7FGGMCyp+TxZcCZwA7VfVqYAQhPh5BflEFH67bxZXj+9hdxMaYkOdPIjioqvVArYh0AXZz+KD0IeeZzzYTHRHBlaf09ToUY4wJOH/OEeS63VA/gTNITTnw34BG5aHSgzW8srSA80f0Ij0xzutwjDEm4Py5aqhh7IHHReQ9oIuqrgxsWN6Z+/lWDlTXcc3ELK9DMcaYduHvVUMAqGp+gOLoEGrr6nnuP/mc3C+Vob1C+jSIMcY0OqpEcLREZDLwRyASeFJV72uh3CXAq8BYVc0NZEyteW/1TraXVvKbKSd5FYIxJlzVVELFbijfDeW73Mfuw58n3Aonntfmmw5YInB7KZ0NnAUUAEtEZJ6qrmlSLhH4MbA4ULH466mFm8nq2pkzBqd7HYoxJlSoOpX47vDNCTMAABhRSURBVLVQtqP5Cr58F1SWNv/6zl0hoTskpENkYLrB9+c+gtRmFpf5cXfxOGCjqua57zMXmAKsaVLut8D9wE+PHG7gLNu6ly+27uM3FwwlwkYfM8Yci8pS2L0Odq+GXWucyn/3aji49/ByMYlOxZ7QHdKHQL9vQkI3t8LvfmhdfLeAVf6+/DkiWIZzuehenL6GkoGdIrILZzzjpS28LgPY5jNfAIz3LeB2ZtdbVd8RkRYTgYjMxBkchz59AjMmwFMLN9MlLopLx2QG5P2NMSGktgqKNjgV/a7VboW/Bkp9qryYREg/EYZMgfShznRSplPJx8R7F3sz/EkE7wOvquoCABE5G7gEeAZ4lCaVu79EJAJ4CJhxpLKqOgeYA5CTk6PHsr3WFO47yHurdnLdxGziYwN62sQYE0zqaqAkD/asgz0bnL373Wuh6CvQOqdMRDSkDYQ+J0P6Nc4efvchkNQbgqR7Gn9qvZNV9fqGGVX9p4g8qKo3iEhsK68r5PAbzzLdZQ0SgZOAT9y+fHoA80TkgvY+Yfy3/+QDcNWpWe25WWNMR1F9AIq/gj3rnUeR+1ySB/W1h8ol94XuQ2Hwd9wKfyh07d8uzTeB5E8i2CEiPwfmuvOXA7vck8H1rbxuCTBARLJxEsBU4IqGlapaCjR26ykinwB3tHcSqKiq5e+fb2XyST3ISO505BcYY4LXwX1Ok86edW6F707v2wa4jQ0SCan9oNsgGHwedBsM3QZC1wEQG5rjkviTCK4A7gbecOc/c5dFAt9t6UWqWisitwAL3LJPq+pqEbkHyFXVeccVeRt5dWkBZZW1NuaAMaFCFfZvdyr5hkdDpV++61C5yFinSSdzLIy80qn4uw2C1BMgKryGpfXnzuIi4IctrN54hNe+i9Njqe+yu1ooe/qRYmlr9fXKM59tZlSfZEb3SWnvzRtjjkddDZRsdppxijY4bfhF6532++ryQ+Vik5w9+v5nOhV/wx5+cl+IsE4lwb/LRwcCdwBZvuVV9VuBC6t9fLhuN/nFB7jjnEFHLmyM8UZ9PZRsgsJlTjNOw15+0/b7LhmQNgBGfs+p6NMGQtog5yqdIDlp6xV/moZeAR4HngTqAhtO+3pqYR69kuKYPLSH16EYYxpUFEFBLhTmOs/blx262Soiymm6SRsIJ57vVvYDnQQQm+ht3EHMn0RQq6qPBTySdrZ6eymL8kr4xbmDiYr0pzduY0ybq6mEnSsPr/j3bXHWSaRzZc7QiyAjBzLGOBV+kF+h0xH5kwjeEpGbgNeBqoaFqloSsKjawdML8+kcE8nUcYG5Qc0Y00RDE09BLhQudSr+naug3u2koEsmZI6BsddBZg70HNHhbrwKVf4kgunus++dvwr0a/tw2sfuskreWrGdaeN6k9TJ9i6MaXO11U57/s4vYdcq53nnykNNPDEJ0GsUnHqLs7efmQOJ1kTrFX+uGgq56ypf+O8WaurruXpCyP1pxrS/AyVNKvwvncs1G/b0ozs7N14Nvdhp3skY41ymaVfsdBgtJgIR+ZaqfiQiFze3XlVfC1xYgVNZU8cLi7dyxuDuZKXZYacxfquvh72bD6/wd66C/QWHyiT0gB7DYMDZznOPYc7NWVbpd2itHRFMAj4Czm9mnQJBmQjeXF5ISUW13UBmTEtUne6Rd6851Jna7rVOU0/D9fkS6Vyt0/dU6HGSU+F3H+b0oGmCTouJQFXvdp+vbr9wAktVeWrhZk7s2YWT+zXXu7YxYebgXrfb5IZK3634D/pcC9K5q3P1zsgrDu3ldzsRom1M71Dhzw1lsTi9jWZx+A1l9wQurMBYuLGIDbvKefCyEYjdYGLCSW21Tx/5PpV+2fZDZRq6TT7xfKfiTz/Reba9/JDnz1VDbwKlwFJ8Lh8NRk8t3ExaQiznj+jpdSjGBI6q05ZfsPTQtfk7V0JdtbM+MtY5WZt92qHKvqGvfNtBCkv+JIJMVZ0c8EgCbOPuMj5Zv4fbzxpIbJSduDIh5OBe57r8hoq/cCkcKHbWRXeGniNh/A3O1Trdh0Fqtp28NYfxJxH8R0SGqeqXAY8mgN5asYOYqAi+N95uIDNBrK7GuWqnIPfQ3bjFDX0/irOnP/Bc58asjBxnbz/SBlsyrfPnGzIRmCEim3GahgRQVR0e0Mja2K1nDuD8ET3pmtDaWDrGdED7tsLq12Hdu7BjOdRWOsvj050bsUZMc557jYK4JG9jNUHJn0RwbsCjaAciQv9065TKBInSQljzJqx+DQqWOMt6jnS6X8gY41T8QTQUounYWruhrIuq7gfK2jEeY8JX2a5Dlf/W/zrLegyDM+52Ol5LtXtfTGC0dkTwd+A8nKuFFKdJqEFQ9zVkTIdRUQRr58Gq12DLZ6D1Trv+N3/ldMmQ1t/rCE0YaO2GsvPcZ9sNMaYtHSiBdW87lf/mT0HrnPFwT/ups+effqLXEZow49flBCKSAgwAGm8lVNVPAxWUMSGntso54bvqH7DpI2dkrZQsmPBjOOli6H6Stfcbz/hzZ/F1wI+BTGA5cDLwXyDoh6o0JuDqamHlXPjkPijd5pzgPfkmZ8+/1yir/E2H4M8RwY+BscAiVf2miAwG/jewYRkT5OrrYe2b8NH/g+KvnEr//EfghDOs8jcdjj9jNFaqaiU4/Q6p6jrAr9HeRWSyiKwXkY0icmcz628UkS9FZLmILBSRIUcXvjEdjCp89T7MmQSvzHDu4L38Bbj+Y+h/piUB0yH5c0RQICLJwBvA+yKyF9hypBeJSCQwGzgLKACWiMg8VV3jU+zvqvq4W/4C4CEg6LuzMGFqy3/gw3ucSz+T+8JFf4Vhl1l3DqbD82eEsovcyVki8jGQBLznx3uPAzaqah6AiMwFpgCNicC9T6FBPM5lqcYEl+1fwEf3wsYPnIFZvvMQjPo+RMV4HZkxfmk1Ebh79atVdTCAqv7rKN47A9jmM18AjG9mGzcDtwMxtHACWkRmAjMB+vSxvoJMB7FnvZMA1s6DTilw1m+dO39jOnsdmTFHpdVEoKp1bht/H1XdGogAVHU2MFtErgB+DUxvpswcYA5ATk6OHTUYb+3d4lwFtHKu07vnpDvhlJshrovXkRlzTPw5R5ACrBaRz4GKhoWqesERXlcI9PaZz3SXtWQu8Jgf8RjjjbKd8OmDsPRZp93/5Jtg4u0Q39XryIw5Lv4kgv85xvdeAgwQkWycBDAVuMK3gIgMUNWv3NnvAF9hTEe08mWY9yOor4HRVzl3AXfp5XVUxrQJfxLBt1X1574LROR+oNXzBapaKyK3AAuASOBpVV0tIvcAuao6D7hFRM4EaoC9NNMsZIynVJ1moH/dB1nfgAv+BKnWzZYJLaLaepO7iCxT1dFNlq30ajyCnJwczc3N9WLTJtzUVMKbN8OqV2HklXDew3YlkAlaIrJUVXOaW9daN9Q/AG4C+onISp9VicBnbRuiMR1MRRHMvQK2LXa6gZ54m90MZkLWkbqhng/8DvC9K7hMVUsCGpUxXtqzHl68DMp3wWXPwdALvY7ImIBqrRvqUqAUmNZ+4RjjsU0fw8vTISoWZrzrjP1rTIjzp68hY8LD0mfhhUsgKROu/9CSgAkbfo1HYExIq6+DD+6G//wZ+p8Flz5tN4eZsGKJwIS36gp4baYzYtjY62HyfRBpPwsTXuwbb8LX/h3wf5fDzi/h3Adg/A1eR2SMJywRmPC0YyX8/XKo2g/T5sLAc7yOyBjPWCIw4Wf9e/DqNdApGa55D3oM8zoiYzxlVw2Z8KEKix6DudMgbQBc/5ElAWOwIwITLurrYP7PYMmTMPg8uHgOxMR7HZUxHYIdEZjwsPRZJwmc+iP47vOWBIzxYUcEJvTV1cBnj0DmODjrHuszyJgm7IjAhL5V/4B9W+EbP7EkYEwzLBGY0FZfD/9+CLqfZJeIGtMCSwQmtK17G4rWWzfSxrTCEoEJXarw7z84I4oNvcjraIzpsCwRmNC16SPYsRwm3OoMNm+MaZYlAhO6/v0QJPaCEVO9jsSYDs0SgQlNWxfBloUw4UfOIDPGmBZZIjCh6d8PQeeuMPoqryMxpsMLaCIQkckisl5ENorInc2sv11E1ojIShH5UET6BjIeEyZ2rISvFsDJP7A7iI3xQ8ASgYhEArOBc4EhwDQRGdKk2BdAjqoOB14FHghUPCaMLHwIYhKdgWaMMUcUyCOCccBGVc1T1WpgLjDFt4CqfqyqB9zZRUBmAOMx4aBoI6x+A8Zd53QzbYw5okAmggxgm898gbusJdcC85tbISIzRSRXRHL37NnThiGakPPZw87J4ZNv8joSY4JGhzhZLCJXAjnA75tbr6pzVDVHVXO6devWvsGZ4LFvG6yY65wgTkj3OhpjgkYgex8tBHr7zGe6yw4jImcCvwImqWpVAOMxoe6/f3GeT/2Rt3EYE2QCeUSwBBggItkiEgNMBeb5FhCRUcBfgQtUdXcAYzGhrnwPLH0Ohk+F5N5HLm+MaRSwRKCqtcAtwAJgLfCyqq4WkXtE5AK32O+BBOAVEVkuIvNaeDtjWrfoUaithIm3eh2JMUEnoAPTqOq7wLtNlt3lM31mILdvwsTBfc7oY0OmOGMRG2OOSoc4WWzMcVnyJFTth2/c7nUkxgQlSwQmuFUfcJqF+p8FPUd4HY0xQckSgQluy/4GB4rhtDu8jsSYoGWJwASv2mr4z5+g7wToc7LX0RgTtCwRmOC18iXYX2jnBow5TpYITHCqr4OFDzvnBU44w+tojAlqlghMcFrzBpRsgm/8xAalN+Y4WSIwwUfVGXgmbSAMPt/raIwJepYITPD56p+waxVMvA0i7CtszPGyX5EJLqrw6YOQ1AeGXeZ1NMaEBEsEJrhs+QwKPncGpY+M9joaY0KCJQITXD59EOLTYdSVXkdiTMiwRGCCR+FSyPsYTrkZojt5HY0xIcMSgQke/34I4pIg5xqvIzEmpFgiMMFh7Vuw7m0YdwPEdfE6GmNCSkDHIzDmuJXkwfw74asFkD4ETv6B1xEZE3IsEZiOqfqA04XEZ390rg46+14Yf6NdKWRMAFgiMB2LKqx/F967E/Ztde4VOOu30KWn15EZE7IsEZiOo3gTzP85bHzfaQaa8Q5kTfQ6KmNCniUC473qA7DwIbcZKBbO+R2Mu96agYxpJ5YIjHdUnSuB3vsllG6F4ZfDWfdAYg+vIzMmrAT08lERmSwi60Vko4jc2cz600RkmYjUisilgYzFdDDFm+CFS+ClKyE2Ea6eDxfPsSRgjAcCdkQgIpHAbOAsoABYIiLzVHWNT7GtwAzABpwNF9UV8O8/wH/+DFFxMPk+GHs9RNrBqTFeCeSvbxywUVXzAERkLjAFaEwEqprvrqsPYByO9e/BqlcBcQcyae6Z1tdHREJkjNN2fdhzC9MR0Ycvj4gCrQetc0bYOuy5voV19YfmtR7qa32Wu9P1tYfeo3G6YXn9oWmAmM4QkwAx8e5zw3T8oelYn/VH205fXwd1NVBf4z7XHprf/gUs+DXsL4AR0+DM30Bi9zb7Fxtjjk0gE0EGsM1nvgAYfyxvJCIzgZkAffr0ObZoyndCQS6gTts0CkqT+SM8N1SoddXOo6OSSCfpRLjPEuFMg3Nitvag/+8VGXMoKUR3cv/+Wp+KvubweedDbVn3YXDpUzbYvDEdSFAcj6vqHGAOQE5OzhFqmhaMmeE82i6ow5NCXc2Rp+vrnEq5oWKWyCbPLa2LcJ4lopkKPsqnXJR/A7XU1zlNNI2PcvdR4fPsTlf5zNcedLcR7TTlNBzxRES5zw3TLazrlAIDzrZmIGM6mED+IguB3j7zme6y0CDiNvtEA/FeR3N0IiKd/nqszx5jDIG9amgJMEBEskUkBpgKzAvg9owxxhyDgCUCVa0FbgEWAGuBl1V1tYjcIyIXAIjIWBEpAC4D/ioiqwMVjzHGmOYFtLFWVd8F3m2y7C6f6SU4TUbGGGM8YuMRGGNMmLNEYIwxYc4SgTHGhDlLBMYYE+YsERhjTJgT1WO7UdcrIrIH2HKML08DitownLZm8R0fi+/4dfQYLb5j11dVuzW3IugSwfEQkVxVzfE6jpZYfMfH4jt+HT1Giy8wrGnIGGPCnCUCY4wJc+GWCOZ4HcARWHzHx+I7fh09RosvAMLqHIExxpivC7cjAmOMMU1YIjDGmDAXkolARCaLyHoR2SgidzazPlZEXnLXLxaRrHaMrbeIfCwia0RktYj8uJkyp4tIqYgsdx93NfdeAYwxX0S+dLed28x6EZE/uZ/fShEZ3Y6xDfL5XJaLyH4RubVJmXb//ETkaRHZLSKrfJalisj7IvKV+5zSwmunu2W+EpHp7RTb70Vknfv/e11Eklt4bavfhQDHOEtECn3+j99u4bWt/t4DGN9LPrHli8jyFl7bLp/hcVHVkHoAkcAmoB8QA6wAhjQpcxPwuDs9FXipHePrCYx2pxOBDc3EdzrwtoefYT6Q1sr6bwPzAQFOBhZ7+L/eiXOjjKefH3AaMBpY5bPsAeBOd/pO4P5mXpcK5LnPKe50SjvEdjYQ5U7f31xs/nwXAhzjLOAOP74Drf7eAxVfk/V/AO7y8jM8nkcoHhGMAzaqap6qVgNzgSlNykwBnnOnXwXOEBFpj+BUdYeqLnOny3AG7cloj223oSnA39SxCEgWkZ4exHEGsElVj/VO8zajqp8CJU0W+37PngMubOal5wDvq2qJqu4F3gcmBzo2Vf2nOoNHASzC43FBWvj8/OHP7/24tRafW3d8F/i/tt5uewnFRJABbPOZL+DrFW1jGffHUAp0bZfofLhNUqOAxc2sPkVEVojIfBEZ2q6BgQL/FJGlIjKzmfX+fMbtYSot//i8/PwadFfVHe70TqB7M2U6wmd5Dc4RXnOO9F0ItFvc5qunW2ha6wif3zeAXar6VQvrvf4MjygUE0FQEJEE4B/Araq6v8nqZTjNHSOAPwNvtHN4E1V1NHAucLOInNbO2z8idxzsC4BXmlnt9ef3Neq0EXS4a7VF5FdALfBiC0W8/C48BpwAjAR24DS/dETTaP1ooMP/nkIxERQCvX3mM91lzZYRkSggCShul+icbUbjJIEXVfW1putVdb+qlrvT7wLRIpLWXvGpaqH7vBt4Hefw25c/n3GgnQssU9VdTVd4/fn52NXQZOY+726mjGefpYjMAM4Dvucmqq/x47sQMKq6S1XrVLUeeKKFbXv6XXTrj4uBl1oq4+Vn6K9QTARLgAEiku3uNU4F5jUpMw9ouDrjUuCjln4Ibc1tT3wKWKuqD7VQpkfDOQsRGYfzf2qXRCUi8SKS2DCNc1JxVZNi84Cr3KuHTgZKfZpA2kuLe2Fefn5N+H7PpgNvNlNmAXC2iKS4TR9nu8sCSkQmAz8DLlDVAy2U8ee7EMgYfc87XdTCtv35vQfSmcA6VS1obqXXn6HfvD5bHYgHzlUtG3CuJviVu+wenC89QBxOk8JG4HOgXzvGNhGniWAlsNx9fBu4EbjRLXMLsBrnCohFwKntGF8/d7sr3BgaPj/f+ASY7X6+XwI57fz/jcep2JN8lnn6+eEkpR1ADU479bU4550+BL4CPgBS3bI5wJM+r73G/S5uBK5up9g24rStN3wHG66i6wW829p3oR0/v+fd79dKnMq9Z9MY3fmv/d7bIz53+bMN3zufsp58hsfzsC4mjDEmzIVi05AxxpijYInAGGPCnCUCY4wJc5YIjDEmzFkiMMaYMGeJwJh25PaM+rbXcRjjyxKBMcaEOUsExjRDRK4Ukc/dPuT/KiKRIlIuIg+LM47EhyLSzS07UkQW+fTtn+Iu7y8iH7id3y0TkRPct08QkVfd8QBebK+eb41piSUCY5oQkROBy4EJqjoSqAO+h3NHc66qDgX+BdztvuRvwM9VdTjOnbANy18EZqvT+d2pOHemgtPj7K3AEJw7TycE/I8yphVRXgdgTAd0BjAGWOLurHfC6TCunkOdi70AvCYiSUCyqv7LXf4c8Irbv0yGqr4OoKqVAO77fa5u3zTuqFZZwMLA/1nGNM8SgTFfJ8BzqvqLwxaK/E+TcsfaP0uVz3Qd9js0HrOmIWO+7kPgUhFJh8axh/vi/F4udctcASxU1VJgr4h8w13+feBf6ow+VyAiF7rvESsindv1rzDGT7YnYkwTqrpGRH6NM6pUBE6PkzcDFcA4d91unPMI4HQx/bhb0ecBV7vLvw/8VUTucd/jsnb8M4zxm/U+aoyfRKRcVRO8jsOYtmZNQ8YYE+bsiMAYY8KcHREYY0yYs0RgjDFhzhKBMcaEOUsExhgT5iwRGGNMmPv/kiPYb+X5IXAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7444 - accuracy: 0.7482\n",
      "CNN with relu Test accuracy: 0.748199999332428\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5795 - accuracy: 0.4374\n",
      "CNN with sigmoid Test accuracy: 0.4374000132083893\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "# Plot training accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history_sigmoid.history['accuracy'])\n",
    "plt.title('training accuracy')\n",
    "plt.ylabel('training accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Conv_relu', 'Conv_sigmoid'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history_sigmoid.history['val_accuracy'])\n",
    "plt.title('validation accuracy')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Conv_relu', 'Conv_sigmoid'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the best model saved (i.e., model with best validation accuracy) on the test set\n",
    "saved_model = load_model('best_model_3_DO_noDA_rmsopt_relu')\n",
    "scores = saved_model.evaluate(x_test, y_test, verbose=1)\n",
    "print('CNN with relu Test accuracy:', scores[1])\n",
    "scores = load_model('best_model_3_DO_noDA_rmsopt_sigmoid').evaluate(x_test, y_test, verbose=1)\n",
    "print('CNN with sigmoid Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwFOXSy1BefM"
   },
   "source": [
    "### Explanation\n",
    "\n",
    "The CNN with sigmoid units has lower accuracy than rectified linear units. This is because sigmoid units suffer from the vanishing gradient problem, so each step of gradient descent will make only very small change to the weights, leading to slow convergence shown in the graph. Rectified linear units are more computationally efficient, and reduces the likelihood of vanishing gradient, and converges more quickly shown in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U1hR6jSzUOZ"
   },
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "diScJqsTNSXX",
    "outputId": "801d3818-822d-41e5-e6a0-451bd9119678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.7171 - accuracy: 0.3817\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.47090, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.7171 - accuracy: 0.3817 - val_loss: 1.4525 - val_accuracy: 0.4709\n",
      "Epoch 2/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.4278 - accuracy: 0.4874\n",
      "Epoch 00002: val_accuracy improved from 0.47090 to 0.54320, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 1.4277 - accuracy: 0.4875 - val_loss: 1.2874 - val_accuracy: 0.5432\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.3042 - accuracy: 0.5331\n",
      "Epoch 00003: val_accuracy improved from 0.54320 to 0.55590, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.3042 - accuracy: 0.5331 - val_loss: 1.2322 - val_accuracy: 0.5559\n",
      "Epoch 4/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.2094 - accuracy: 0.5728\n",
      "Epoch 00004: val_accuracy improved from 0.55590 to 0.61230, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 1.2100 - accuracy: 0.5725 - val_loss: 1.1088 - val_accuracy: 0.6123\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.1315 - accuracy: 0.6018\n",
      "Epoch 00005: val_accuracy improved from 0.61230 to 0.64150, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 1.1315 - accuracy: 0.6018 - val_loss: 1.0292 - val_accuracy: 0.6415\n",
      "Epoch 6/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.0735 - accuracy: 0.6228\n",
      "Epoch 00006: val_accuracy improved from 0.64150 to 0.64970, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.0735 - accuracy: 0.6229 - val_loss: 1.0075 - val_accuracy: 0.6497\n",
      "Epoch 7/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.0202 - accuracy: 0.6434\n",
      "Epoch 00007: val_accuracy improved from 0.64970 to 0.66430, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 1.0202 - accuracy: 0.6434 - val_loss: 0.9782 - val_accuracy: 0.6643\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.9837 - accuracy: 0.6552\n",
      "Epoch 00008: val_accuracy improved from 0.66430 to 0.66580, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.9837 - accuracy: 0.6552 - val_loss: 0.9562 - val_accuracy: 0.6658\n",
      "Epoch 9/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.9460 - accuracy: 0.6646\n",
      "Epoch 00009: val_accuracy improved from 0.66580 to 0.69400, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.9460 - accuracy: 0.6646 - val_loss: 0.8799 - val_accuracy: 0.6940\n",
      "Epoch 10/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.9110 - accuracy: 0.6817\n",
      "Epoch 00010: val_accuracy did not improve from 0.69400\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.9110 - accuracy: 0.6818 - val_loss: 0.9460 - val_accuracy: 0.6766\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8805 - accuracy: 0.6928\n",
      "Epoch 00011: val_accuracy improved from 0.69400 to 0.70880, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.8805 - accuracy: 0.6928 - val_loss: 0.8490 - val_accuracy: 0.7088\n",
      "Epoch 12/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.8503 - accuracy: 0.7021\n",
      "Epoch 00012: val_accuracy did not improve from 0.70880\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.8506 - accuracy: 0.7020 - val_loss: 0.8377 - val_accuracy: 0.7080\n",
      "Epoch 13/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.8251 - accuracy: 0.7116\n",
      "Epoch 00013: val_accuracy improved from 0.70880 to 0.73110, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.8252 - accuracy: 0.7115 - val_loss: 0.7853 - val_accuracy: 0.7311\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7993 - accuracy: 0.7216\n",
      "Epoch 00014: val_accuracy improved from 0.73110 to 0.73220, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.7993 - accuracy: 0.7216 - val_loss: 0.7937 - val_accuracy: 0.7322\n",
      "Epoch 15/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7763 - accuracy: 0.7297\n",
      "Epoch 00015: val_accuracy did not improve from 0.73220\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.7763 - accuracy: 0.7298 - val_loss: 0.8168 - val_accuracy: 0.7231\n",
      "Epoch 16/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7562 - accuracy: 0.7360\n",
      "Epoch 00016: val_accuracy improved from 0.73220 to 0.73310, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.7559 - accuracy: 0.7361 - val_loss: 0.8024 - val_accuracy: 0.7331\n",
      "Epoch 17/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7323 - accuracy: 0.7474\n",
      "Epoch 00017: val_accuracy improved from 0.73310 to 0.74160, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.7323 - accuracy: 0.7475 - val_loss: 0.7790 - val_accuracy: 0.7416\n",
      "Epoch 18/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7164 - accuracy: 0.7517\n",
      "Epoch 00018: val_accuracy improved from 0.74160 to 0.75690, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.7168 - accuracy: 0.7516 - val_loss: 0.7353 - val_accuracy: 0.7569\n",
      "Epoch 19/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6952 - accuracy: 0.7592\n",
      "Epoch 00019: val_accuracy improved from 0.75690 to 0.76060, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.6951 - accuracy: 0.7592 - val_loss: 0.7110 - val_accuracy: 0.7606\n",
      "Epoch 20/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6817 - accuracy: 0.7643\n",
      "Epoch 00020: val_accuracy did not improve from 0.76060\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.6818 - accuracy: 0.7642 - val_loss: 0.7490 - val_accuracy: 0.7512\n",
      "Epoch 21/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6619 - accuracy: 0.7721\n",
      "Epoch 00021: val_accuracy did not improve from 0.76060\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.6620 - accuracy: 0.7720 - val_loss: 0.7477 - val_accuracy: 0.7540\n",
      "Epoch 22/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6498 - accuracy: 0.7746\n",
      "Epoch 00022: val_accuracy did not improve from 0.76060\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.6497 - accuracy: 0.7746 - val_loss: 0.7638 - val_accuracy: 0.7477\n",
      "Epoch 23/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6372 - accuracy: 0.7795\n",
      "Epoch 00023: val_accuracy improved from 0.76060 to 0.77330, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.6374 - accuracy: 0.7793 - val_loss: 0.6799 - val_accuracy: 0.7733\n",
      "Epoch 24/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6271 - accuracy: 0.7822\n",
      "Epoch 00024: val_accuracy improved from 0.77330 to 0.78100, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.6270 - accuracy: 0.7822 - val_loss: 0.6635 - val_accuracy: 0.7810\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6105 - accuracy: 0.7893\n",
      "Epoch 00025: val_accuracy improved from 0.78100 to 0.78460, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.6105 - accuracy: 0.7893 - val_loss: 0.6446 - val_accuracy: 0.7846\n",
      "Epoch 26/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6003 - accuracy: 0.7919\n",
      "Epoch 00026: val_accuracy did not improve from 0.78460\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.6004 - accuracy: 0.7918 - val_loss: 0.6795 - val_accuracy: 0.7784\n",
      "Epoch 27/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.5909 - accuracy: 0.7965\n",
      "Epoch 00027: val_accuracy did not improve from 0.78460\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.5909 - accuracy: 0.7965 - val_loss: 0.6732 - val_accuracy: 0.7737\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.7986\n",
      "Epoch 00028: val_accuracy did not improve from 0.78460\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.5843 - accuracy: 0.7986 - val_loss: 0.7095 - val_accuracy: 0.7636\n",
      "Epoch 29/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.5744 - accuracy: 0.8007\n",
      "Epoch 00029: val_accuracy did not improve from 0.78460\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.5741 - accuracy: 0.8008 - val_loss: 0.6634 - val_accuracy: 0.7826\n",
      "Epoch 30/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.5625 - accuracy: 0.8071\n",
      "Epoch 00030: val_accuracy did not improve from 0.78460\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.5622 - accuracy: 0.8072 - val_loss: 0.7011 - val_accuracy: 0.7757\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.5536 - accuracy: 0.8107\n",
      "Epoch 00031: val_accuracy improved from 0.78460 to 0.78620, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5536 - accuracy: 0.8107 - val_loss: 0.6707 - val_accuracy: 0.7862\n",
      "Epoch 32/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.5428 - accuracy: 0.8139\n",
      "Epoch 00032: val_accuracy improved from 0.78620 to 0.79170, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.5428 - accuracy: 0.8140 - val_loss: 0.6417 - val_accuracy: 0.7917\n",
      "Epoch 33/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.5390 - accuracy: 0.8146\n",
      "Epoch 00033: val_accuracy did not improve from 0.79170\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.5389 - accuracy: 0.8146 - val_loss: 0.6577 - val_accuracy: 0.7875\n",
      "Epoch 34/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.5274 - accuracy: 0.8186\n",
      "Epoch 00034: val_accuracy improved from 0.79170 to 0.79390, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.5276 - accuracy: 0.8185 - val_loss: 0.6454 - val_accuracy: 0.7939\n",
      "Epoch 35/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.5233 - accuracy: 0.8210\n",
      "Epoch 00035: val_accuracy did not improve from 0.79390\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.5236 - accuracy: 0.8209 - val_loss: 0.6732 - val_accuracy: 0.7800\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.8219\n",
      "Epoch 00036: val_accuracy did not improve from 0.79390\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.5170 - accuracy: 0.8219 - val_loss: 0.6573 - val_accuracy: 0.7828\n",
      "Epoch 37/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.5052 - accuracy: 0.8255\n",
      "Epoch 00037: val_accuracy improved from 0.79390 to 0.79760, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.5053 - accuracy: 0.8254 - val_loss: 0.6408 - val_accuracy: 0.7976\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.5064 - accuracy: 0.8263\n",
      "Epoch 00038: val_accuracy did not improve from 0.79760\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.5064 - accuracy: 0.8263 - val_loss: 0.6722 - val_accuracy: 0.7875\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.5013 - accuracy: 0.8277\n",
      "Epoch 00039: val_accuracy improved from 0.79760 to 0.80160, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.5013 - accuracy: 0.8277 - val_loss: 0.6065 - val_accuracy: 0.8016\n",
      "Epoch 40/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4923 - accuracy: 0.8312\n",
      "Epoch 00040: val_accuracy did not improve from 0.80160\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4921 - accuracy: 0.8312 - val_loss: 0.6309 - val_accuracy: 0.8007\n",
      "Epoch 41/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4876 - accuracy: 0.8306\n",
      "Epoch 00041: val_accuracy did not improve from 0.80160\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4876 - accuracy: 0.8307 - val_loss: 0.6822 - val_accuracy: 0.7902\n",
      "Epoch 42/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4772 - accuracy: 0.8360\n",
      "Epoch 00042: val_accuracy improved from 0.80160 to 0.80400, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4774 - accuracy: 0.8360 - val_loss: 0.6283 - val_accuracy: 0.8040\n",
      "Epoch 43/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4753 - accuracy: 0.8365\n",
      "Epoch 00043: val_accuracy did not improve from 0.80400\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4754 - accuracy: 0.8364 - val_loss: 0.6558 - val_accuracy: 0.7962\n",
      "Epoch 44/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4729 - accuracy: 0.8374\n",
      "Epoch 00044: val_accuracy improved from 0.80400 to 0.80510, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4728 - accuracy: 0.8374 - val_loss: 0.6362 - val_accuracy: 0.8051\n",
      "Epoch 45/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4703 - accuracy: 0.8383\n",
      "Epoch 00045: val_accuracy did not improve from 0.80510\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4707 - accuracy: 0.8382 - val_loss: 0.6285 - val_accuracy: 0.7989\n",
      "Epoch 46/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4675 - accuracy: 0.8400\n",
      "Epoch 00046: val_accuracy did not improve from 0.80510\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4675 - accuracy: 0.8400 - val_loss: 0.6290 - val_accuracy: 0.8046\n",
      "Epoch 47/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4582 - accuracy: 0.8423\n",
      "Epoch 00047: val_accuracy improved from 0.80510 to 0.80960, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4580 - accuracy: 0.8424 - val_loss: 0.6210 - val_accuracy: 0.8096\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.8416\n",
      "Epoch 00048: val_accuracy improved from 0.80960 to 0.81410, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4572 - accuracy: 0.8416 - val_loss: 0.6091 - val_accuracy: 0.8141\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4555 - accuracy: 0.8438\n",
      "Epoch 00049: val_accuracy improved from 0.81410 to 0.81510, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4555 - accuracy: 0.8438 - val_loss: 0.6210 - val_accuracy: 0.8151\n",
      "Epoch 50/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8454\n",
      "Epoch 00050: val_accuracy did not improve from 0.81510\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4505 - accuracy: 0.8455 - val_loss: 0.6809 - val_accuracy: 0.8070\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.8461\n",
      "Epoch 00051: val_accuracy did not improve from 0.81510\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4513 - accuracy: 0.8461 - val_loss: 0.6426 - val_accuracy: 0.7968\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.8486\n",
      "Epoch 00052: val_accuracy did not improve from 0.81510\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4416 - accuracy: 0.8486 - val_loss: 0.6909 - val_accuracy: 0.7891\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4393 - accuracy: 0.8494\n",
      "Epoch 00053: val_accuracy did not improve from 0.81510\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4393 - accuracy: 0.8494 - val_loss: 0.6416 - val_accuracy: 0.8082\n",
      "Epoch 54/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4375 - accuracy: 0.8496\n",
      "Epoch 00054: val_accuracy did not improve from 0.81510\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4376 - accuracy: 0.8495 - val_loss: 0.6258 - val_accuracy: 0.8064\n",
      "Epoch 55/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.4418 - accuracy: 0.8492\n",
      "Epoch 00055: val_accuracy did not improve from 0.81510\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4419 - accuracy: 0.8493 - val_loss: 0.6220 - val_accuracy: 0.8088\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.8515\n",
      "Epoch 00056: val_accuracy did not improve from 0.81510\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4357 - accuracy: 0.8515 - val_loss: 0.6137 - val_accuracy: 0.8065\n",
      "Epoch 57/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.8520\n",
      "Epoch 00057: val_accuracy improved from 0.81510 to 0.81710, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4301 - accuracy: 0.8522 - val_loss: 0.6373 - val_accuracy: 0.8171\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4339 - accuracy: 0.8517\n",
      "Epoch 00058: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4339 - accuracy: 0.8517 - val_loss: 0.6080 - val_accuracy: 0.8106\n",
      "Epoch 59/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4288 - accuracy: 0.8535\n",
      "Epoch 00059: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.4288 - accuracy: 0.8535 - val_loss: 0.6419 - val_accuracy: 0.8021\n",
      "Epoch 60/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4273 - accuracy: 0.8542\n",
      "Epoch 00060: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.4273 - accuracy: 0.8542 - val_loss: 0.7320 - val_accuracy: 0.7843\n",
      "Epoch 61/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4311 - accuracy: 0.8544\n",
      "Epoch 00061: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4312 - accuracy: 0.8543 - val_loss: 0.6516 - val_accuracy: 0.8033\n",
      "Epoch 62/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.4239 - accuracy: 0.8556\n",
      "Epoch 00062: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4240 - accuracy: 0.8555 - val_loss: 0.6069 - val_accuracy: 0.8120\n",
      "Epoch 63/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4244 - accuracy: 0.8550\n",
      "Epoch 00063: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4244 - accuracy: 0.8550 - val_loss: 0.6628 - val_accuracy: 0.8093\n",
      "Epoch 64/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4245 - accuracy: 0.8538\n",
      "Epoch 00064: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4243 - accuracy: 0.8537 - val_loss: 0.6976 - val_accuracy: 0.8114\n",
      "Epoch 65/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4265 - accuracy: 0.8528\n",
      "Epoch 00065: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4268 - accuracy: 0.8528 - val_loss: 0.6234 - val_accuracy: 0.8069\n",
      "Epoch 66/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4213 - accuracy: 0.8552\n",
      "Epoch 00066: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4214 - accuracy: 0.8551 - val_loss: 0.6522 - val_accuracy: 0.8040\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4197 - accuracy: 0.8571\n",
      "Epoch 00067: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4197 - accuracy: 0.8571 - val_loss: 0.6492 - val_accuracy: 0.8123\n",
      "Epoch 68/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4220 - accuracy: 0.8556\n",
      "Epoch 00068: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4220 - accuracy: 0.8556 - val_loss: 0.6944 - val_accuracy: 0.7910\n",
      "Epoch 69/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4181 - accuracy: 0.8588\n",
      "Epoch 00069: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.4184 - accuracy: 0.8587 - val_loss: 0.6680 - val_accuracy: 0.7818\n",
      "Epoch 70/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4192 - accuracy: 0.8581\n",
      "Epoch 00070: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4194 - accuracy: 0.8581 - val_loss: 0.7007 - val_accuracy: 0.8015\n",
      "Epoch 71/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.4181 - accuracy: 0.8586\n",
      "Epoch 00071: val_accuracy did not improve from 0.81710\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4181 - accuracy: 0.8587 - val_loss: 0.6740 - val_accuracy: 0.8105\n",
      "Epoch 72/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4244 - accuracy: 0.8569\n",
      "Epoch 00072: val_accuracy improved from 0.81710 to 0.81780, saving model to best_model_3_noDO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4244 - accuracy: 0.8569 - val_loss: 0.6291 - val_accuracy: 0.8178\n",
      "Epoch 73/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4229 - accuracy: 0.8579\n",
      "Epoch 00073: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.4230 - accuracy: 0.8578 - val_loss: 0.6255 - val_accuracy: 0.8007\n",
      "Epoch 74/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4207 - accuracy: 0.8568\n",
      "Epoch 00074: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.4205 - accuracy: 0.8568 - val_loss: 0.6508 - val_accuracy: 0.8092\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.8578\n",
      "Epoch 00075: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4214 - accuracy: 0.8578 - val_loss: 0.6674 - val_accuracy: 0.8053\n",
      "Epoch 76/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4203 - accuracy: 0.8562\n",
      "Epoch 00076: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4203 - accuracy: 0.8562 - val_loss: 0.7536 - val_accuracy: 0.7877\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4248 - accuracy: 0.8551\n",
      "Epoch 00077: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4248 - accuracy: 0.8551 - val_loss: 0.6729 - val_accuracy: 0.7857\n",
      "Epoch 78/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4185 - accuracy: 0.8569\n",
      "Epoch 00078: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4184 - accuracy: 0.8569 - val_loss: 0.7086 - val_accuracy: 0.8024\n",
      "Epoch 79/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.4263 - accuracy: 0.8561\n",
      "Epoch 00079: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4268 - accuracy: 0.8560 - val_loss: 0.6758 - val_accuracy: 0.7985\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.8565\n",
      "Epoch 00080: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4210 - accuracy: 0.8565 - val_loss: 0.6454 - val_accuracy: 0.8034\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4250 - accuracy: 0.8522\n",
      "Epoch 00081: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4250 - accuracy: 0.8522 - val_loss: 0.7722 - val_accuracy: 0.7922\n",
      "Epoch 82/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4288 - accuracy: 0.8554\n",
      "Epoch 00082: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.4287 - accuracy: 0.8554 - val_loss: 0.6860 - val_accuracy: 0.8106\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4317 - accuracy: 0.8524\n",
      "Epoch 00083: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4317 - accuracy: 0.8524 - val_loss: 0.6895 - val_accuracy: 0.8113\n",
      "Epoch 84/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4325 - accuracy: 0.8526\n",
      "Epoch 00084: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4326 - accuracy: 0.8526 - val_loss: 0.6931 - val_accuracy: 0.8021\n",
      "Epoch 85/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4290 - accuracy: 0.8530\n",
      "Epoch 00085: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4291 - accuracy: 0.8529 - val_loss: 0.6549 - val_accuracy: 0.8049\n",
      "Epoch 86/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4332 - accuracy: 0.8531\n",
      "Epoch 00086: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4334 - accuracy: 0.8530 - val_loss: 0.6483 - val_accuracy: 0.8098\n",
      "Epoch 87/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4319 - accuracy: 0.8522\n",
      "Epoch 00087: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4319 - accuracy: 0.8522 - val_loss: 0.7312 - val_accuracy: 0.8030\n",
      "Epoch 88/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4330 - accuracy: 0.8534\n",
      "Epoch 00088: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4329 - accuracy: 0.8534 - val_loss: 0.8042 - val_accuracy: 0.7703\n",
      "Epoch 89/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4284 - accuracy: 0.8543\n",
      "Epoch 00089: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4288 - accuracy: 0.8543 - val_loss: 0.6443 - val_accuracy: 0.7985\n",
      "Epoch 90/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4347 - accuracy: 0.8529\n",
      "Epoch 00090: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4346 - accuracy: 0.8529 - val_loss: 0.7251 - val_accuracy: 0.8055\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.8515\n",
      "Epoch 00091: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4360 - accuracy: 0.8515 - val_loss: 0.7459 - val_accuracy: 0.7969\n",
      "Epoch 92/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4378 - accuracy: 0.8496\n",
      "Epoch 00092: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4378 - accuracy: 0.8495 - val_loss: 0.6840 - val_accuracy: 0.8060\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.8525\n",
      "Epoch 00093: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4365 - accuracy: 0.8525 - val_loss: 0.6522 - val_accuracy: 0.8105\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.8521\n",
      "Epoch 00094: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4373 - accuracy: 0.8521 - val_loss: 0.7636 - val_accuracy: 0.7961\n",
      "Epoch 95/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4358 - accuracy: 0.8528\n",
      "Epoch 00095: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4362 - accuracy: 0.8528 - val_loss: 0.6453 - val_accuracy: 0.8123\n",
      "Epoch 96/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4411 - accuracy: 0.8509\n",
      "Epoch 00096: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4410 - accuracy: 0.8509 - val_loss: 0.7257 - val_accuracy: 0.8078\n",
      "Epoch 97/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4402 - accuracy: 0.8494\n",
      "Epoch 00097: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4410 - accuracy: 0.8493 - val_loss: 0.6213 - val_accuracy: 0.8040\n",
      "Epoch 98/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4464 - accuracy: 0.8485\n",
      "Epoch 00098: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.4464 - accuracy: 0.8485 - val_loss: 0.6377 - val_accuracy: 0.7968\n",
      "Epoch 99/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4393 - accuracy: 0.8512\n",
      "Epoch 00099: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4393 - accuracy: 0.8513 - val_loss: 0.6806 - val_accuracy: 0.8092\n",
      "Epoch 100/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.4505 - accuracy: 0.8466\n",
      "Epoch 00100: val_accuracy did not improve from 0.81780\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4507 - accuracy: 0.8466 - val_loss: 0.8800 - val_accuracy: 0.7803\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Not using data augmentation.\n",
      "Epoch 1/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.6508 - accuracy: 0.4098\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.48520, saving model to best_model_3_noDO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6504 - accuracy: 0.4099 - val_loss: 1.4320 - val_accuracy: 0.4852\n",
      "Epoch 2/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.3105 - accuracy: 0.5344\n",
      "Epoch 00002: val_accuracy improved from 0.48520 to 0.57280, saving model to best_model_3_noDO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.3099 - accuracy: 0.5350 - val_loss: 1.2058 - val_accuracy: 0.5728\n",
      "Epoch 3/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.1472 - accuracy: 0.5956\n",
      "Epoch 00003: val_accuracy improved from 0.57280 to 0.60880, saving model to best_model_3_noDO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.1476 - accuracy: 0.5956 - val_loss: 1.1084 - val_accuracy: 0.6088\n",
      "Epoch 4/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.0330 - accuracy: 0.6374\n",
      "Epoch 00004: val_accuracy improved from 0.60880 to 0.64410, saving model to best_model_3_noDO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.0327 - accuracy: 0.6375 - val_loss: 1.0222 - val_accuracy: 0.6441\n",
      "Epoch 5/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.9463 - accuracy: 0.6697\n",
      "Epoch 00005: val_accuracy improved from 0.64410 to 0.65080, saving model to best_model_3_noDO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.9458 - accuracy: 0.6699 - val_loss: 0.9926 - val_accuracy: 0.6508\n",
      "Epoch 6/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8728 - accuracy: 0.6979\n",
      "Epoch 00006: val_accuracy improved from 0.65080 to 0.68040, saving model to best_model_3_noDO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8728 - accuracy: 0.6980 - val_loss: 0.9259 - val_accuracy: 0.6804\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8085 - accuracy: 0.7193\n",
      "Epoch 00007: val_accuracy improved from 0.68040 to 0.68670, saving model to best_model_3_noDO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.8085 - accuracy: 0.7193 - val_loss: 0.9084 - val_accuracy: 0.6867\n",
      "Epoch 8/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.7486 - accuracy: 0.7405\n",
      "Epoch 00008: val_accuracy improved from 0.68670 to 0.69890, saving model to best_model_3_noDO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7488 - accuracy: 0.7405 - val_loss: 0.8770 - val_accuracy: 0.6989\n",
      "Epoch 9/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6898 - accuracy: 0.7635\n",
      "Epoch 00009: val_accuracy improved from 0.69890 to 0.70150, saving model to best_model_3_noDO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6901 - accuracy: 0.7633 - val_loss: 0.8704 - val_accuracy: 0.7015\n",
      "Epoch 10/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6321 - accuracy: 0.7839\n",
      "Epoch 00010: val_accuracy did not improve from 0.70150\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6318 - accuracy: 0.7841 - val_loss: 0.9249 - val_accuracy: 0.6917\n",
      "Epoch 11/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.5769 - accuracy: 0.8036\n",
      "Epoch 00011: val_accuracy improved from 0.70150 to 0.71000, saving model to best_model_3_noDO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5767 - accuracy: 0.8036 - val_loss: 0.8932 - val_accuracy: 0.7100\n",
      "Epoch 12/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.5210 - accuracy: 0.8231\n",
      "Epoch 00012: val_accuracy improved from 0.71000 to 0.71680, saving model to best_model_3_noDO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5211 - accuracy: 0.8231 - val_loss: 0.8531 - val_accuracy: 0.7168\n",
      "Epoch 13/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.4651 - accuracy: 0.8434\n",
      "Epoch 00013: val_accuracy improved from 0.71680 to 0.72710, saving model to best_model_3_noDO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.4653 - accuracy: 0.8433 - val_loss: 0.8598 - val_accuracy: 0.7271\n",
      "Epoch 14/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4104 - accuracy: 0.8639\n",
      "Epoch 00014: val_accuracy did not improve from 0.72710\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4105 - accuracy: 0.8638 - val_loss: 0.8864 - val_accuracy: 0.7228\n",
      "Epoch 15/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.3573 - accuracy: 0.8818\n",
      "Epoch 00015: val_accuracy improved from 0.72710 to 0.73290, saving model to best_model_3_noDO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_noDO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.3570 - accuracy: 0.8819 - val_loss: 0.8806 - val_accuracy: 0.7329\n",
      "Epoch 16/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.3044 - accuracy: 0.8990\n",
      "Epoch 00016: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3046 - accuracy: 0.8989 - val_loss: 0.9393 - val_accuracy: 0.7305\n",
      "Epoch 17/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.2557 - accuracy: 0.9176\n",
      "Epoch 00017: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2558 - accuracy: 0.9176 - val_loss: 1.0513 - val_accuracy: 0.7157\n",
      "Epoch 18/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.2117 - accuracy: 0.9327\n",
      "Epoch 00018: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.2121 - accuracy: 0.9326 - val_loss: 1.0765 - val_accuracy: 0.7172\n",
      "Epoch 19/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.1723 - accuracy: 0.9460\n",
      "Epoch 00019: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1724 - accuracy: 0.9460 - val_loss: 1.0979 - val_accuracy: 0.7232\n",
      "Epoch 20/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.1380 - accuracy: 0.9557\n",
      "Epoch 00020: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1380 - accuracy: 0.9556 - val_loss: 1.2592 - val_accuracy: 0.7170\n",
      "Epoch 21/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.1096 - accuracy: 0.9661\n",
      "Epoch 00021: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.1100 - accuracy: 0.9660 - val_loss: 1.2967 - val_accuracy: 0.7175\n",
      "Epoch 22/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 0.9735\n",
      "Epoch 00022: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0875 - accuracy: 0.9734 - val_loss: 1.4465 - val_accuracy: 0.7098\n",
      "Epoch 23/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9790\n",
      "Epoch 00023: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0692 - accuracy: 0.9790 - val_loss: 1.4569 - val_accuracy: 0.7239\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9835\n",
      "Epoch 00024: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0555 - accuracy: 0.9835 - val_loss: 1.6391 - val_accuracy: 0.7155\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9862\n",
      "Epoch 00025: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0454 - accuracy: 0.9862 - val_loss: 1.6997 - val_accuracy: 0.7177\n",
      "Epoch 26/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9886\n",
      "Epoch 00026: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0389 - accuracy: 0.9886 - val_loss: 1.7713 - val_accuracy: 0.7155\n",
      "Epoch 27/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.0309 - accuracy: 0.9912\n",
      "Epoch 00027: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 1.8318 - val_accuracy: 0.7220\n",
      "Epoch 28/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9919\n",
      "Epoch 00028: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0279 - accuracy: 0.9919 - val_loss: 1.9024 - val_accuracy: 0.7231\n",
      "Epoch 29/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9925\n",
      "Epoch 00029: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 1.9912 - val_accuracy: 0.7261\n",
      "Epoch 30/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9939\n",
      "Epoch 00030: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 1.9647 - val_accuracy: 0.7233\n",
      "Epoch 31/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9939\n",
      "Epoch 00031: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 2.0741 - val_accuracy: 0.7206\n",
      "Epoch 32/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9945\n",
      "Epoch 00032: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 2.1891 - val_accuracy: 0.7209\n",
      "Epoch 33/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9953\n",
      "Epoch 00033: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 2.2956 - val_accuracy: 0.7159\n",
      "Epoch 34/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9954\n",
      "Epoch 00034: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 2.3207 - val_accuracy: 0.7222\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9954\n",
      "Epoch 00035: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 2.3273 - val_accuracy: 0.7218\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9956\n",
      "Epoch 00036: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 2.5772 - val_accuracy: 0.7107\n",
      "Epoch 37/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9963\n",
      "Epoch 00037: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 2.4326 - val_accuracy: 0.7232\n",
      "Epoch 38/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9955\n",
      "Epoch 00038: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 2.5467 - val_accuracy: 0.7199\n",
      "Epoch 39/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9959\n",
      "Epoch 00039: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 2.5875 - val_accuracy: 0.7072\n",
      "Epoch 40/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9964\n",
      "Epoch 00040: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 2.6002 - val_accuracy: 0.7227\n",
      "Epoch 41/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9971\n",
      "Epoch 00041: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 2.7201 - val_accuracy: 0.7161\n",
      "Epoch 42/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9968\n",
      "Epoch 00042: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 2.7350 - val_accuracy: 0.7232\n",
      "Epoch 43/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9970\n",
      "Epoch 00043: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 2.7535 - val_accuracy: 0.7253\n",
      "Epoch 44/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9972\n",
      "Epoch 00044: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 2.8055 - val_accuracy: 0.7231\n",
      "Epoch 45/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 00045: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 2.9104 - val_accuracy: 0.7152\n",
      "Epoch 46/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9973\n",
      "Epoch 00046: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 2.8096 - val_accuracy: 0.7246\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9971\n",
      "Epoch 00047: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 2.9516 - val_accuracy: 0.7198\n",
      "Epoch 48/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9967\n",
      "Epoch 00048: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 2.9865 - val_accuracy: 0.7173\n",
      "Epoch 49/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9973\n",
      "Epoch 00049: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 2.9225 - val_accuracy: 0.7244\n",
      "Epoch 50/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 00050: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 3.1129 - val_accuracy: 0.7227\n",
      "Epoch 51/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9975\n",
      "Epoch 00051: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 3.0407 - val_accuracy: 0.7179\n",
      "Epoch 52/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9976\n",
      "Epoch 00052: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 3.3370 - val_accuracy: 0.7146\n",
      "Epoch 53/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9981\n",
      "Epoch 00053: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 3.1773 - val_accuracy: 0.7275\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9975\n",
      "Epoch 00054: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 3.2533 - val_accuracy: 0.7255\n",
      "Epoch 55/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 00055: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 3.1679 - val_accuracy: 0.7208\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9980\n",
      "Epoch 00056: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 3.4336 - val_accuracy: 0.7137\n",
      "Epoch 57/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9980\n",
      "Epoch 00057: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 3.3882 - val_accuracy: 0.7231\n",
      "Epoch 58/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 00058: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 3.4773 - val_accuracy: 0.7190\n",
      "Epoch 59/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 00059: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 3.4292 - val_accuracy: 0.7217\n",
      "Epoch 60/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9980\n",
      "Epoch 00060: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 3.4416 - val_accuracy: 0.7175\n",
      "Epoch 61/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9979\n",
      "Epoch 00061: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 3.7694 - val_accuracy: 0.7134\n",
      "Epoch 62/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9978\n",
      "Epoch 00062: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 3.7145 - val_accuracy: 0.7225\n",
      "Epoch 63/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9983\n",
      "Epoch 00063: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 3.8169 - val_accuracy: 0.7152\n",
      "Epoch 64/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9983\n",
      "Epoch 00064: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 3.6181 - val_accuracy: 0.7175\n",
      "Epoch 65/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9983\n",
      "Epoch 00065: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 4.0073 - val_accuracy: 0.7103\n",
      "Epoch 66/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 00066: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 3.7805 - val_accuracy: 0.7178\n",
      "Epoch 67/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9983\n",
      "Epoch 00067: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 3.9656 - val_accuracy: 0.7135\n",
      "Epoch 68/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984\n",
      "Epoch 00068: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 3.9848 - val_accuracy: 0.7137\n",
      "Epoch 69/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch 00069: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 3.7484 - val_accuracy: 0.7214\n",
      "Epoch 70/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 00070: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 3.8005 - val_accuracy: 0.7190\n",
      "Epoch 71/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 00071: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 4.0615 - val_accuracy: 0.7235\n",
      "Epoch 72/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 00072: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 3.8465 - val_accuracy: 0.7220\n",
      "Epoch 73/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 00073: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 4.0299 - val_accuracy: 0.7183\n",
      "Epoch 74/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 00074: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 4.1513 - val_accuracy: 0.7199\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 00075: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 3.8756 - val_accuracy: 0.7197\n",
      "Epoch 76/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 00076: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 4.0391 - val_accuracy: 0.7224\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9983\n",
      "Epoch 00077: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 4.4601 - val_accuracy: 0.7113\n",
      "Epoch 78/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9990\n",
      "Epoch 00078: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 4.2307 - val_accuracy: 0.7234\n",
      "Epoch 79/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 00079: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 4.4007 - val_accuracy: 0.7182\n",
      "Epoch 80/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9980\n",
      "Epoch 00080: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 4.3605 - val_accuracy: 0.7242\n",
      "Epoch 81/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 00081: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 4.3370 - val_accuracy: 0.7214\n",
      "Epoch 82/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 00082: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 4.3570 - val_accuracy: 0.7110\n",
      "Epoch 83/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch 00083: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 4.3614 - val_accuracy: 0.7165\n",
      "Epoch 84/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9985\n",
      "Epoch 00084: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 4.1602 - val_accuracy: 0.7260\n",
      "Epoch 85/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9987\n",
      "Epoch 00085: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 4.3638 - val_accuracy: 0.7224\n",
      "Epoch 86/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 00086: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 4.3051 - val_accuracy: 0.7142\n",
      "Epoch 87/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 00087: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 4.4903 - val_accuracy: 0.7271\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9989\n",
      "Epoch 00088: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 4.2362 - val_accuracy: 0.7193\n",
      "Epoch 89/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989\n",
      "Epoch 00089: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 4.6425 - val_accuracy: 0.7188\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00090: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 4.6558 - val_accuracy: 0.7220\n",
      "Epoch 91/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 00091: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 4.4832 - val_accuracy: 0.7254\n",
      "Epoch 92/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9990\n",
      "Epoch 00092: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 4.5165 - val_accuracy: 0.7203\n",
      "Epoch 93/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 00093: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 4.6434 - val_accuracy: 0.7245\n",
      "Epoch 94/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 00094: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 4.6931 - val_accuracy: 0.7184\n",
      "Epoch 95/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 00095: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 4.8459 - val_accuracy: 0.7219\n",
      "Epoch 96/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 00096: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 4.7837 - val_accuracy: 0.7234\n",
      "Epoch 97/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 00097: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 4.9632 - val_accuracy: 0.7184\n",
      "Epoch 98/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 00098: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 4.7478 - val_accuracy: 0.7277\n",
      "Epoch 99/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 00099: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 4.9377 - val_accuracy: 0.7269\n",
      "Epoch 100/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 00100: val_accuracy did not improve from 0.73290\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 5.0077 - val_accuracy: 0.7217\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.8934 - accuracy: 0.3114\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.41910, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.8932 - accuracy: 0.3115 - val_loss: 1.6203 - val_accuracy: 0.4191\n",
      "Epoch 2/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.6045 - accuracy: 0.4180\n",
      "Epoch 00002: val_accuracy improved from 0.41910 to 0.47460, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 26s 20ms/step - loss: 1.6044 - accuracy: 0.4181 - val_loss: 1.4537 - val_accuracy: 0.4746\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.4787 - accuracy: 0.4663\n",
      "Epoch 00003: val_accuracy improved from 0.47460 to 0.50990, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 1.4787 - accuracy: 0.4663 - val_loss: 1.3624 - val_accuracy: 0.5099\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.3930 - accuracy: 0.4989\n",
      "Epoch 00004: val_accuracy improved from 0.50990 to 0.54130, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.3930 - accuracy: 0.4989 - val_loss: 1.2769 - val_accuracy: 0.5413\n",
      "Epoch 5/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.3227 - accuracy: 0.5260\n",
      "Epoch 00005: val_accuracy did not improve from 0.54130\n",
      "1250/1250 [==============================] - 24s 20ms/step - loss: 1.3223 - accuracy: 0.5262 - val_loss: 1.3460 - val_accuracy: 0.5311\n",
      "Epoch 6/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.2639 - accuracy: 0.5478\n",
      "Epoch 00006: val_accuracy improved from 0.54130 to 0.57610, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.2640 - accuracy: 0.5478 - val_loss: 1.2172 - val_accuracy: 0.5761\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.2152 - accuracy: 0.5676\n",
      "Epoch 00007: val_accuracy improved from 0.57610 to 0.59130, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.2152 - accuracy: 0.5676 - val_loss: 1.1465 - val_accuracy: 0.5913\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.1712 - accuracy: 0.5843\n",
      "Epoch 00008: val_accuracy improved from 0.59130 to 0.63920, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.1712 - accuracy: 0.5843 - val_loss: 1.0271 - val_accuracy: 0.6392\n",
      "Epoch 9/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.1359 - accuracy: 0.5976\n",
      "Epoch 00009: val_accuracy did not improve from 0.63920\n",
      "1250/1250 [==============================] - 24s 20ms/step - loss: 1.1358 - accuracy: 0.5978 - val_loss: 1.0530 - val_accuracy: 0.6256\n",
      "Epoch 10/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.0968 - accuracy: 0.6117\n",
      "Epoch 00010: val_accuracy improved from 0.63920 to 0.66090, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 26s 20ms/step - loss: 1.0967 - accuracy: 0.6118 - val_loss: 0.9722 - val_accuracy: 0.6609\n",
      "Epoch 11/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.0667 - accuracy: 0.6237\n",
      "Epoch 00011: val_accuracy improved from 0.66090 to 0.67060, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0667 - accuracy: 0.6237 - val_loss: 0.9267 - val_accuracy: 0.6706\n",
      "Epoch 12/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.0427 - accuracy: 0.6350\n",
      "Epoch 00012: val_accuracy did not improve from 0.67060\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 1.0426 - accuracy: 0.6350 - val_loss: 1.0047 - val_accuracy: 0.6540\n",
      "Epoch 13/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.0203 - accuracy: 0.6395\n",
      "Epoch 00013: val_accuracy improved from 0.67060 to 0.68790, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 26s 21ms/step - loss: 1.0205 - accuracy: 0.6396 - val_loss: 0.8816 - val_accuracy: 0.6879\n",
      "Epoch 14/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.0011 - accuracy: 0.6493\n",
      "Epoch 00014: val_accuracy improved from 0.68790 to 0.69680, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 26s 20ms/step - loss: 1.0011 - accuracy: 0.6494 - val_loss: 0.8593 - val_accuracy: 0.6968\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.9852 - accuracy: 0.6531\n",
      "Epoch 00015: val_accuracy did not improve from 0.69680\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.9852 - accuracy: 0.6531 - val_loss: 0.9147 - val_accuracy: 0.6853\n",
      "Epoch 16/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.9672 - accuracy: 0.6625\n",
      "Epoch 00016: val_accuracy did not improve from 0.69680\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.9672 - accuracy: 0.6625 - val_loss: 0.9468 - val_accuracy: 0.6855\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.9524 - accuracy: 0.6659\n",
      "Epoch 00017: val_accuracy improved from 0.69680 to 0.70760, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.9524 - accuracy: 0.6659 - val_loss: 0.8509 - val_accuracy: 0.7076\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.9404 - accuracy: 0.6728\n",
      "Epoch 00018: val_accuracy improved from 0.70760 to 0.71520, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.9404 - accuracy: 0.6728 - val_loss: 0.8235 - val_accuracy: 0.7152\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.9296 - accuracy: 0.6755\n",
      "Epoch 00019: val_accuracy did not improve from 0.71520\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.9296 - accuracy: 0.6755 - val_loss: 0.8482 - val_accuracy: 0.7082\n",
      "Epoch 20/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.9232 - accuracy: 0.6811\n",
      "Epoch 00020: val_accuracy improved from 0.71520 to 0.72460, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.9230 - accuracy: 0.6811 - val_loss: 0.7972 - val_accuracy: 0.7246\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.9048 - accuracy: 0.6869\n",
      "Epoch 00021: val_accuracy improved from 0.72460 to 0.72900, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.9048 - accuracy: 0.6869 - val_loss: 0.7796 - val_accuracy: 0.7290\n",
      "Epoch 22/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9016 - accuracy: 0.6876\n",
      "Epoch 00022: val_accuracy improved from 0.72900 to 0.73230, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.9017 - accuracy: 0.6876 - val_loss: 0.7717 - val_accuracy: 0.7323\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8887 - accuracy: 0.6894\n",
      "Epoch 00023: val_accuracy improved from 0.73230 to 0.73780, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.8887 - accuracy: 0.6894 - val_loss: 0.7674 - val_accuracy: 0.7378\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8871 - accuracy: 0.6941\n",
      "Epoch 00024: val_accuracy improved from 0.73780 to 0.74060, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.8871 - accuracy: 0.6941 - val_loss: 0.7648 - val_accuracy: 0.7406\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8790 - accuracy: 0.6959\n",
      "Epoch 00025: val_accuracy improved from 0.74060 to 0.74280, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.8790 - accuracy: 0.6959 - val_loss: 0.7553 - val_accuracy: 0.7428\n",
      "Epoch 26/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.8777 - accuracy: 0.6986\n",
      "Epoch 00026: val_accuracy did not improve from 0.74280\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.8777 - accuracy: 0.6986 - val_loss: 0.7568 - val_accuracy: 0.7410\n",
      "Epoch 27/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.8707 - accuracy: 0.7024\n",
      "Epoch 00027: val_accuracy did not improve from 0.74280\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.8711 - accuracy: 0.7023 - val_loss: 0.7907 - val_accuracy: 0.7346\n",
      "Epoch 28/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8568 - accuracy: 0.7023\n",
      "Epoch 00028: val_accuracy improved from 0.74280 to 0.74650, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.8568 - accuracy: 0.7023 - val_loss: 0.7385 - val_accuracy: 0.7465\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8589 - accuracy: 0.7034\n",
      "Epoch 00029: val_accuracy did not improve from 0.74650\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.8589 - accuracy: 0.7034 - val_loss: 0.7714 - val_accuracy: 0.7410\n",
      "Epoch 30/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8556 - accuracy: 0.7059\n",
      "Epoch 00030: val_accuracy did not improve from 0.74650\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.8555 - accuracy: 0.7059 - val_loss: 0.8106 - val_accuracy: 0.7312\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8501 - accuracy: 0.7079\n",
      "Epoch 00031: val_accuracy did not improve from 0.74650\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.8501 - accuracy: 0.7079 - val_loss: 0.7578 - val_accuracy: 0.7432\n",
      "Epoch 32/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8387 - accuracy: 0.7110\n",
      "Epoch 00032: val_accuracy improved from 0.74650 to 0.75000, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.8386 - accuracy: 0.7110 - val_loss: 0.7373 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8400 - accuracy: 0.7130\n",
      "Epoch 00033: val_accuracy improved from 0.75000 to 0.75520, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.8400 - accuracy: 0.7130 - val_loss: 0.7625 - val_accuracy: 0.7552\n",
      "Epoch 34/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.8350 - accuracy: 0.7153\n",
      "Epoch 00034: val_accuracy did not improve from 0.75520\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.8347 - accuracy: 0.7155 - val_loss: 0.7295 - val_accuracy: 0.7543\n",
      "Epoch 35/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8355 - accuracy: 0.7133\n",
      "Epoch 00035: val_accuracy did not improve from 0.75520\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.8361 - accuracy: 0.7130 - val_loss: 0.7788 - val_accuracy: 0.7430\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8309 - accuracy: 0.7189\n",
      "Epoch 00036: val_accuracy did not improve from 0.75520\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.8309 - accuracy: 0.7189 - val_loss: 0.7846 - val_accuracy: 0.7472\n",
      "Epoch 37/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.8185 - accuracy: 0.7195\n",
      "Epoch 00037: val_accuracy improved from 0.75520 to 0.75580, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.8190 - accuracy: 0.7194 - val_loss: 0.7244 - val_accuracy: 0.7558\n",
      "Epoch 38/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8213 - accuracy: 0.7192\n",
      "Epoch 00038: val_accuracy improved from 0.75580 to 0.76980, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.8212 - accuracy: 0.7192 - val_loss: 0.6845 - val_accuracy: 0.7698\n",
      "Epoch 39/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.8135 - accuracy: 0.7249\n",
      "Epoch 00039: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.8136 - accuracy: 0.7248 - val_loss: 0.6893 - val_accuracy: 0.7675\n",
      "Epoch 40/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.8134 - accuracy: 0.7228\n",
      "Epoch 00040: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.8136 - accuracy: 0.7228 - val_loss: 0.7529 - val_accuracy: 0.7554\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8163 - accuracy: 0.7221\n",
      "Epoch 00041: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.8163 - accuracy: 0.7221 - val_loss: 0.7340 - val_accuracy: 0.7563\n",
      "Epoch 42/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8063 - accuracy: 0.7241\n",
      "Epoch 00042: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.8062 - accuracy: 0.7242 - val_loss: 0.7265 - val_accuracy: 0.7567\n",
      "Epoch 43/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.8025 - accuracy: 0.7243\n",
      "Epoch 00043: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.8025 - accuracy: 0.7242 - val_loss: 0.7368 - val_accuracy: 0.7558\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8063 - accuracy: 0.7267\n",
      "Epoch 00044: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.8063 - accuracy: 0.7267 - val_loss: 0.7174 - val_accuracy: 0.7604\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8020 - accuracy: 0.7276\n",
      "Epoch 00045: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.8020 - accuracy: 0.7276 - val_loss: 0.6834 - val_accuracy: 0.7686\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7986 - accuracy: 0.7288\n",
      "Epoch 00046: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7986 - accuracy: 0.7288 - val_loss: 0.7555 - val_accuracy: 0.7642\n",
      "Epoch 47/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7977 - accuracy: 0.7290\n",
      "Epoch 00047: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7978 - accuracy: 0.7289 - val_loss: 0.7058 - val_accuracy: 0.7678\n",
      "Epoch 48/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7975 - accuracy: 0.7279\n",
      "Epoch 00048: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7977 - accuracy: 0.7279 - val_loss: 0.7221 - val_accuracy: 0.7588\n",
      "Epoch 49/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7974 - accuracy: 0.7303\n",
      "Epoch 00049: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7981 - accuracy: 0.7301 - val_loss: 0.7361 - val_accuracy: 0.7666\n",
      "Epoch 50/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7946 - accuracy: 0.7305\n",
      "Epoch 00050: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7945 - accuracy: 0.7306 - val_loss: 0.7114 - val_accuracy: 0.7634\n",
      "Epoch 51/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7949 - accuracy: 0.7315\n",
      "Epoch 00051: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7948 - accuracy: 0.7315 - val_loss: 0.7152 - val_accuracy: 0.7657\n",
      "Epoch 52/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7911 - accuracy: 0.7325\n",
      "Epoch 00052: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.7913 - accuracy: 0.7326 - val_loss: 0.7866 - val_accuracy: 0.7545\n",
      "Epoch 53/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7913 - accuracy: 0.7303\n",
      "Epoch 00053: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.7910 - accuracy: 0.7304 - val_loss: 0.7117 - val_accuracy: 0.7653\n",
      "Epoch 54/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7862 - accuracy: 0.7355\n",
      "Epoch 00054: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7862 - accuracy: 0.7355 - val_loss: 0.8135 - val_accuracy: 0.7464\n",
      "Epoch 55/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7869 - accuracy: 0.7350\n",
      "Epoch 00055: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 0.7868 - accuracy: 0.7351 - val_loss: 0.6907 - val_accuracy: 0.7678\n",
      "Epoch 56/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7884 - accuracy: 0.7369\n",
      "Epoch 00056: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 0.7883 - accuracy: 0.7369 - val_loss: 0.6855 - val_accuracy: 0.7656\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7808 - accuracy: 0.7356\n",
      "Epoch 00057: val_accuracy did not improve from 0.76980\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 0.7808 - accuracy: 0.7356 - val_loss: 0.7271 - val_accuracy: 0.7602\n",
      "Epoch 58/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7881 - accuracy: 0.7362\n",
      "Epoch 00058: val_accuracy improved from 0.76980 to 0.77330, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.7882 - accuracy: 0.7362 - val_loss: 0.6849 - val_accuracy: 0.7733\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7904 - accuracy: 0.7359\n",
      "Epoch 00059: val_accuracy did not improve from 0.77330\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 0.7904 - accuracy: 0.7359 - val_loss: 0.7152 - val_accuracy: 0.7649\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7850 - accuracy: 0.7380\n",
      "Epoch 00060: val_accuracy did not improve from 0.77330\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7850 - accuracy: 0.7380 - val_loss: 0.7239 - val_accuracy: 0.7682\n",
      "Epoch 61/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7850 - accuracy: 0.7364\n",
      "Epoch 00061: val_accuracy did not improve from 0.77330\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7845 - accuracy: 0.7366 - val_loss: 0.6901 - val_accuracy: 0.7715\n",
      "Epoch 62/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7848 - accuracy: 0.7394\n",
      "Epoch 00062: val_accuracy improved from 0.77330 to 0.78420, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.7846 - accuracy: 0.7393 - val_loss: 0.6498 - val_accuracy: 0.7842\n",
      "Epoch 63/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7871 - accuracy: 0.7344\n",
      "Epoch 00063: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7873 - accuracy: 0.7344 - val_loss: 0.6531 - val_accuracy: 0.7821\n",
      "Epoch 64/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7846 - accuracy: 0.7367\n",
      "Epoch 00064: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7843 - accuracy: 0.7368 - val_loss: 0.7189 - val_accuracy: 0.7675\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7823 - accuracy: 0.7385\n",
      "Epoch 00065: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7823 - accuracy: 0.7385 - val_loss: 0.6951 - val_accuracy: 0.7696\n",
      "Epoch 66/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7804 - accuracy: 0.7379\n",
      "Epoch 00066: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7806 - accuracy: 0.7379 - val_loss: 0.6674 - val_accuracy: 0.7761\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7770 - accuracy: 0.7397\n",
      "Epoch 00067: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.7770 - accuracy: 0.7397 - val_loss: 0.6746 - val_accuracy: 0.7791\n",
      "Epoch 68/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7817 - accuracy: 0.7382\n",
      "Epoch 00068: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.7821 - accuracy: 0.7382 - val_loss: 0.7321 - val_accuracy: 0.7527\n",
      "Epoch 69/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7787 - accuracy: 0.7394\n",
      "Epoch 00069: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7790 - accuracy: 0.7393 - val_loss: 0.6722 - val_accuracy: 0.7794\n",
      "Epoch 70/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7815 - accuracy: 0.7394\n",
      "Epoch 00070: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7816 - accuracy: 0.7394 - val_loss: 0.7071 - val_accuracy: 0.7645\n",
      "Epoch 71/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7825 - accuracy: 0.7371\n",
      "Epoch 00071: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7828 - accuracy: 0.7371 - val_loss: 0.7373 - val_accuracy: 0.7593\n",
      "Epoch 72/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7790 - accuracy: 0.7363\n",
      "Epoch 00072: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.7791 - accuracy: 0.7363 - val_loss: 0.7206 - val_accuracy: 0.7630\n",
      "Epoch 73/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7779 - accuracy: 0.7407\n",
      "Epoch 00073: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7774 - accuracy: 0.7407 - val_loss: 0.6913 - val_accuracy: 0.7770\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7802 - accuracy: 0.7386\n",
      "Epoch 00074: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7802 - accuracy: 0.7386 - val_loss: 0.6880 - val_accuracy: 0.7730\n",
      "Epoch 75/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7759 - accuracy: 0.7407\n",
      "Epoch 00075: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.7756 - accuracy: 0.7407 - val_loss: 0.7128 - val_accuracy: 0.7658\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7800 - accuracy: 0.7382\n",
      "Epoch 00076: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7800 - accuracy: 0.7382 - val_loss: 0.7478 - val_accuracy: 0.7491\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7782 - accuracy: 0.7412\n",
      "Epoch 00077: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7782 - accuracy: 0.7412 - val_loss: 0.7205 - val_accuracy: 0.7644\n",
      "Epoch 78/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7826 - accuracy: 0.7393\n",
      "Epoch 00078: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7826 - accuracy: 0.7394 - val_loss: 0.6945 - val_accuracy: 0.7733\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7801 - accuracy: 0.7381\n",
      "Epoch 00079: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.7801 - accuracy: 0.7381 - val_loss: 0.6781 - val_accuracy: 0.7793\n",
      "Epoch 80/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7764 - accuracy: 0.7396\n",
      "Epoch 00080: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.7762 - accuracy: 0.7396 - val_loss: 0.6690 - val_accuracy: 0.7806\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7781 - accuracy: 0.7399\n",
      "Epoch 00081: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7781 - accuracy: 0.7399 - val_loss: 0.7021 - val_accuracy: 0.7730\n",
      "Epoch 82/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7755 - accuracy: 0.7393\n",
      "Epoch 00082: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.7758 - accuracy: 0.7393 - val_loss: 0.7222 - val_accuracy: 0.7663\n",
      "Epoch 83/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7792 - accuracy: 0.7402\n",
      "Epoch 00083: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7793 - accuracy: 0.7402 - val_loss: 0.6732 - val_accuracy: 0.7738\n",
      "Epoch 84/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7793 - accuracy: 0.7381\n",
      "Epoch 00084: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7790 - accuracy: 0.7383 - val_loss: 0.6874 - val_accuracy: 0.7658\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7780 - accuracy: 0.7395\n",
      "Epoch 00085: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7780 - accuracy: 0.7395 - val_loss: 0.7319 - val_accuracy: 0.7663\n",
      "Epoch 86/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7756 - accuracy: 0.7413\n",
      "Epoch 00086: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7759 - accuracy: 0.7412 - val_loss: 0.6967 - val_accuracy: 0.7685\n",
      "Epoch 87/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7838 - accuracy: 0.7406\n",
      "Epoch 00087: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 0.7836 - accuracy: 0.7406 - val_loss: 0.6868 - val_accuracy: 0.7719\n",
      "Epoch 88/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7829 - accuracy: 0.7411\n",
      "Epoch 00088: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7830 - accuracy: 0.7411 - val_loss: 0.7005 - val_accuracy: 0.7632\n",
      "Epoch 89/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7840 - accuracy: 0.7397\n",
      "Epoch 00089: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7843 - accuracy: 0.7397 - val_loss: 0.7851 - val_accuracy: 0.7464\n",
      "Epoch 90/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7834 - accuracy: 0.7386\n",
      "Epoch 00090: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7836 - accuracy: 0.7385 - val_loss: 0.7130 - val_accuracy: 0.7629\n",
      "Epoch 91/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7876 - accuracy: 0.7370\n",
      "Epoch 00091: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 0.7877 - accuracy: 0.7370 - val_loss: 0.6581 - val_accuracy: 0.7813\n",
      "Epoch 92/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7816 - accuracy: 0.7405\n",
      "Epoch 00092: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7814 - accuracy: 0.7406 - val_loss: 0.6601 - val_accuracy: 0.7768\n",
      "Epoch 93/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7813 - accuracy: 0.7381\n",
      "Epoch 00093: val_accuracy did not improve from 0.78420\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7814 - accuracy: 0.7380 - val_loss: 0.7312 - val_accuracy: 0.7576\n",
      "Epoch 94/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7768 - accuracy: 0.7433\n",
      "Epoch 00094: val_accuracy improved from 0.78420 to 0.78560, saving model to best_model_3_DO_DA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_DA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.7765 - accuracy: 0.7434 - val_loss: 0.6510 - val_accuracy: 0.7856\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7787 - accuracy: 0.7403\n",
      "Epoch 00095: val_accuracy did not improve from 0.78560\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7787 - accuracy: 0.7403 - val_loss: 0.7714 - val_accuracy: 0.7489\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7794 - accuracy: 0.7393\n",
      "Epoch 00096: val_accuracy did not improve from 0.78560\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7794 - accuracy: 0.7393 - val_loss: 0.7131 - val_accuracy: 0.7628\n",
      "Epoch 97/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7883 - accuracy: 0.7373\n",
      "Epoch 00097: val_accuracy did not improve from 0.78560\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.7882 - accuracy: 0.7373 - val_loss: 0.6856 - val_accuracy: 0.7732\n",
      "Epoch 98/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7806 - accuracy: 0.7389\n",
      "Epoch 00098: val_accuracy did not improve from 0.78560\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 0.7809 - accuracy: 0.7388 - val_loss: 0.6781 - val_accuracy: 0.7758\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7883 - accuracy: 0.7391\n",
      "Epoch 00099: val_accuracy did not improve from 0.78560\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7883 - accuracy: 0.7391 - val_loss: 0.6967 - val_accuracy: 0.7701\n",
      "Epoch 100/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7809 - accuracy: 0.7404\n",
      "Epoch 00100: val_accuracy did not improve from 0.78560\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 0.7812 - accuracy: 0.7403 - val_loss: 0.7453 - val_accuracy: 0.7592\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Not using data augmentation.\n",
      "Epoch 1/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.8239 - accuracy: 0.3360\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.43720, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.8227 - accuracy: 0.3362 - val_loss: 1.5625 - val_accuracy: 0.4372\n",
      "Epoch 2/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.5224 - accuracy: 0.4500\n",
      "Epoch 00002: val_accuracy improved from 0.43720 to 0.49030, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.5218 - accuracy: 0.4501 - val_loss: 1.3994 - val_accuracy: 0.4903\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.3860 - accuracy: 0.5010\n",
      "Epoch 00003: val_accuracy improved from 0.49030 to 0.54920, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.3860 - accuracy: 0.5010 - val_loss: 1.2725 - val_accuracy: 0.5492\n",
      "Epoch 4/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.2823 - accuracy: 0.5393\n",
      "Epoch 00004: val_accuracy improved from 0.54920 to 0.58400, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.2821 - accuracy: 0.5394 - val_loss: 1.1915 - val_accuracy: 0.5840\n",
      "Epoch 5/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.1965 - accuracy: 0.5730\n",
      "Epoch 00005: val_accuracy improved from 0.58400 to 0.59810, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.1969 - accuracy: 0.5730 - val_loss: 1.1559 - val_accuracy: 0.5981\n",
      "Epoch 6/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.1292 - accuracy: 0.6008\n",
      "Epoch 00006: val_accuracy improved from 0.59810 to 0.62620, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.1292 - accuracy: 0.6009 - val_loss: 1.0749 - val_accuracy: 0.6262\n",
      "Epoch 7/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.0706 - accuracy: 0.6222\n",
      "Epoch 00007: val_accuracy improved from 0.62620 to 0.63860, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.0709 - accuracy: 0.6221 - val_loss: 1.0300 - val_accuracy: 0.6386\n",
      "Epoch 8/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.0211 - accuracy: 0.6424\n",
      "Epoch 00008: val_accuracy improved from 0.63860 to 0.65930, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.0208 - accuracy: 0.6425 - val_loss: 0.9662 - val_accuracy: 0.6593\n",
      "Epoch 9/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.9796 - accuracy: 0.6567\n",
      "Epoch 00009: val_accuracy improved from 0.65930 to 0.67830, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.9795 - accuracy: 0.6566 - val_loss: 0.9231 - val_accuracy: 0.6783\n",
      "Epoch 10/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.9371 - accuracy: 0.6738\n",
      "Epoch 00010: val_accuracy improved from 0.67830 to 0.68210, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.9373 - accuracy: 0.6737 - val_loss: 0.9118 - val_accuracy: 0.6821\n",
      "Epoch 11/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.9026 - accuracy: 0.6862\n",
      "Epoch 00011: val_accuracy improved from 0.68210 to 0.68820, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.9023 - accuracy: 0.6862 - val_loss: 0.8904 - val_accuracy: 0.6882\n",
      "Epoch 12/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.8795 - accuracy: 0.6925\n",
      "Epoch 00012: val_accuracy improved from 0.68820 to 0.69620, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8800 - accuracy: 0.6923 - val_loss: 0.8709 - val_accuracy: 0.6962\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8508 - accuracy: 0.7040\n",
      "Epoch 00013: val_accuracy improved from 0.69620 to 0.69660, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8508 - accuracy: 0.7040 - val_loss: 0.8691 - val_accuracy: 0.6966\n",
      "Epoch 14/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.8280 - accuracy: 0.7097\n",
      "Epoch 00014: val_accuracy improved from 0.69660 to 0.71310, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8287 - accuracy: 0.7096 - val_loss: 0.8196 - val_accuracy: 0.7131\n",
      "Epoch 15/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8080 - accuracy: 0.7214\n",
      "Epoch 00015: val_accuracy improved from 0.71310 to 0.72200, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8082 - accuracy: 0.7213 - val_loss: 0.8033 - val_accuracy: 0.7220\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7893 - accuracy: 0.7260\n",
      "Epoch 00016: val_accuracy improved from 0.72200 to 0.72440, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.7893 - accuracy: 0.7260 - val_loss: 0.7981 - val_accuracy: 0.7244\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7754 - accuracy: 0.7325\n",
      "Epoch 00017: val_accuracy did not improve from 0.72440\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7754 - accuracy: 0.7325 - val_loss: 0.8109 - val_accuracy: 0.7214\n",
      "Epoch 18/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.7625 - accuracy: 0.7371\n",
      "Epoch 00018: val_accuracy improved from 0.72440 to 0.73030, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.7617 - accuracy: 0.7374 - val_loss: 0.7842 - val_accuracy: 0.7303\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7494 - accuracy: 0.7426\n",
      "Epoch 00019: val_accuracy improved from 0.73030 to 0.74620, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7494 - accuracy: 0.7426 - val_loss: 0.7593 - val_accuracy: 0.7462\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7347 - accuracy: 0.7476\n",
      "Epoch 00020: val_accuracy did not improve from 0.74620\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7347 - accuracy: 0.7476 - val_loss: 0.7815 - val_accuracy: 0.7290\n",
      "Epoch 21/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.7255 - accuracy: 0.7505\n",
      "Epoch 00021: val_accuracy did not improve from 0.74620\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7248 - accuracy: 0.7505 - val_loss: 0.7374 - val_accuracy: 0.7452\n",
      "Epoch 22/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.7168 - accuracy: 0.7545\n",
      "Epoch 00022: val_accuracy improved from 0.74620 to 0.74730, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7167 - accuracy: 0.7544 - val_loss: 0.7437 - val_accuracy: 0.7473\n",
      "Epoch 23/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.7087 - accuracy: 0.7581\n",
      "Epoch 00023: val_accuracy did not improve from 0.74730\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7080 - accuracy: 0.7582 - val_loss: 0.7739 - val_accuracy: 0.7431\n",
      "Epoch 24/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7013 - accuracy: 0.7595\n",
      "Epoch 00024: val_accuracy improved from 0.74730 to 0.75800, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7015 - accuracy: 0.7594 - val_loss: 0.7184 - val_accuracy: 0.7580\n",
      "Epoch 25/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6896 - accuracy: 0.7647\n",
      "Epoch 00025: val_accuracy improved from 0.75800 to 0.75960, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6901 - accuracy: 0.7646 - val_loss: 0.7176 - val_accuracy: 0.7596\n",
      "Epoch 26/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6911 - accuracy: 0.7649\n",
      "Epoch 00026: val_accuracy improved from 0.75960 to 0.76440, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6909 - accuracy: 0.7650 - val_loss: 0.7069 - val_accuracy: 0.7644\n",
      "Epoch 27/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6827 - accuracy: 0.7683\n",
      "Epoch 00027: val_accuracy did not improve from 0.76440\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6826 - accuracy: 0.7683 - val_loss: 0.7439 - val_accuracy: 0.7518\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6834 - accuracy: 0.7702\n",
      "Epoch 00028: val_accuracy improved from 0.76440 to 0.76470, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6834 - accuracy: 0.7702 - val_loss: 0.6999 - val_accuracy: 0.7647\n",
      "Epoch 29/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6730 - accuracy: 0.7693\n",
      "Epoch 00029: val_accuracy improved from 0.76470 to 0.76570, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.6733 - accuracy: 0.7693 - val_loss: 0.7064 - val_accuracy: 0.7657\n",
      "Epoch 30/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.7741\n",
      "Epoch 00030: val_accuracy improved from 0.76570 to 0.76690, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6733 - accuracy: 0.7739 - val_loss: 0.6953 - val_accuracy: 0.7669\n",
      "Epoch 31/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6694 - accuracy: 0.7727\n",
      "Epoch 00031: val_accuracy did not improve from 0.76690\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6693 - accuracy: 0.7727 - val_loss: 0.7150 - val_accuracy: 0.7603\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6639 - accuracy: 0.7742\n",
      "Epoch 00032: val_accuracy improved from 0.76690 to 0.77500, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6639 - accuracy: 0.7742 - val_loss: 0.6809 - val_accuracy: 0.7750\n",
      "Epoch 33/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6555 - accuracy: 0.7773\n",
      "Epoch 00033: val_accuracy did not improve from 0.77500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6555 - accuracy: 0.7774 - val_loss: 0.7057 - val_accuracy: 0.7683\n",
      "Epoch 34/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6589 - accuracy: 0.7797\n",
      "Epoch 00034: val_accuracy did not improve from 0.77500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6587 - accuracy: 0.7796 - val_loss: 0.6913 - val_accuracy: 0.7663\n",
      "Epoch 35/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6498 - accuracy: 0.7830\n",
      "Epoch 00035: val_accuracy did not improve from 0.77500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6500 - accuracy: 0.7830 - val_loss: 0.7028 - val_accuracy: 0.7703\n",
      "Epoch 36/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6510 - accuracy: 0.7814\n",
      "Epoch 00036: val_accuracy did not improve from 0.77500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6522 - accuracy: 0.7811 - val_loss: 0.6843 - val_accuracy: 0.7710\n",
      "Epoch 37/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6451 - accuracy: 0.7835\n",
      "Epoch 00037: val_accuracy did not improve from 0.77500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6448 - accuracy: 0.7838 - val_loss: 0.6857 - val_accuracy: 0.7721\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6491 - accuracy: 0.7829\n",
      "Epoch 00038: val_accuracy did not improve from 0.77500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6491 - accuracy: 0.7829 - val_loss: 0.6747 - val_accuracy: 0.7750\n",
      "Epoch 39/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6444 - accuracy: 0.7831\n",
      "Epoch 00039: val_accuracy improved from 0.77500 to 0.77840, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6445 - accuracy: 0.7831 - val_loss: 0.6777 - val_accuracy: 0.7784\n",
      "Epoch 40/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6406 - accuracy: 0.7832\n",
      "Epoch 00040: val_accuracy did not improve from 0.77840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6403 - accuracy: 0.7833 - val_loss: 0.6808 - val_accuracy: 0.7747\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6385 - accuracy: 0.7866\n",
      "Epoch 00041: val_accuracy did not improve from 0.77840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6385 - accuracy: 0.7866 - val_loss: 0.6828 - val_accuracy: 0.7778\n",
      "Epoch 42/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6411 - accuracy: 0.7845\n",
      "Epoch 00042: val_accuracy did not improve from 0.77840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6413 - accuracy: 0.7844 - val_loss: 0.6692 - val_accuracy: 0.7781\n",
      "Epoch 43/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6315 - accuracy: 0.7885\n",
      "Epoch 00043: val_accuracy did not improve from 0.77840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6313 - accuracy: 0.7886 - val_loss: 0.7042 - val_accuracy: 0.7719\n",
      "Epoch 44/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6300 - accuracy: 0.7899\n",
      "Epoch 00044: val_accuracy did not improve from 0.77840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6301 - accuracy: 0.7898 - val_loss: 0.6870 - val_accuracy: 0.7757\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6263 - accuracy: 0.7897\n",
      "Epoch 00045: val_accuracy improved from 0.77840 to 0.78000, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6263 - accuracy: 0.7897 - val_loss: 0.6571 - val_accuracy: 0.7800\n",
      "Epoch 46/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6261 - accuracy: 0.7912\n",
      "Epoch 00046: val_accuracy improved from 0.78000 to 0.78470, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6258 - accuracy: 0.7913 - val_loss: 0.6587 - val_accuracy: 0.7847\n",
      "Epoch 47/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6247 - accuracy: 0.7917\n",
      "Epoch 00047: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6247 - accuracy: 0.7917 - val_loss: 0.6609 - val_accuracy: 0.7815\n",
      "Epoch 48/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6178 - accuracy: 0.7915\n",
      "Epoch 00048: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6179 - accuracy: 0.7917 - val_loss: 0.6749 - val_accuracy: 0.7790\n",
      "Epoch 49/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6204 - accuracy: 0.7938\n",
      "Epoch 00049: val_accuracy improved from 0.78470 to 0.78650, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6203 - accuracy: 0.7938 - val_loss: 0.6573 - val_accuracy: 0.7865\n",
      "Epoch 50/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.7945\n",
      "Epoch 00050: val_accuracy did not improve from 0.78650\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6190 - accuracy: 0.7941 - val_loss: 0.7149 - val_accuracy: 0.7735\n",
      "Epoch 51/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6177 - accuracy: 0.7956\n",
      "Epoch 00051: val_accuracy did not improve from 0.78650\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6180 - accuracy: 0.7955 - val_loss: 0.7149 - val_accuracy: 0.7731\n",
      "Epoch 52/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6120 - accuracy: 0.7958\n",
      "Epoch 00052: val_accuracy did not improve from 0.78650\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6120 - accuracy: 0.7959 - val_loss: 0.6770 - val_accuracy: 0.7791\n",
      "Epoch 53/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6109 - accuracy: 0.7972\n",
      "Epoch 00053: val_accuracy did not improve from 0.78650\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6110 - accuracy: 0.7972 - val_loss: 0.6647 - val_accuracy: 0.7771\n",
      "Epoch 54/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6131 - accuracy: 0.7950\n",
      "Epoch 00054: val_accuracy did not improve from 0.78650\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6128 - accuracy: 0.7951 - val_loss: 0.6582 - val_accuracy: 0.7844\n",
      "Epoch 55/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6105 - accuracy: 0.7957\n",
      "Epoch 00055: val_accuracy did not improve from 0.78650\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6106 - accuracy: 0.7957 - val_loss: 0.6967 - val_accuracy: 0.7758\n",
      "Epoch 56/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6072 - accuracy: 0.7989\n",
      "Epoch 00056: val_accuracy did not improve from 0.78650\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6071 - accuracy: 0.7989 - val_loss: 0.6782 - val_accuracy: 0.7802\n",
      "Epoch 57/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6068 - accuracy: 0.7988\n",
      "Epoch 00057: val_accuracy did not improve from 0.78650\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6066 - accuracy: 0.7988 - val_loss: 0.6753 - val_accuracy: 0.7783\n",
      "Epoch 58/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6055 - accuracy: 0.7972\n",
      "Epoch 00058: val_accuracy did not improve from 0.78650\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6059 - accuracy: 0.7972 - val_loss: 0.7080 - val_accuracy: 0.7728\n",
      "Epoch 59/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6127 - accuracy: 0.7992\n",
      "Epoch 00059: val_accuracy did not improve from 0.78650\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6122 - accuracy: 0.7992 - val_loss: 0.6595 - val_accuracy: 0.7860\n",
      "Epoch 60/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6071 - accuracy: 0.7989\n",
      "Epoch 00060: val_accuracy did not improve from 0.78650\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6073 - accuracy: 0.7989 - val_loss: 0.6679 - val_accuracy: 0.7820\n",
      "Epoch 61/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6050 - accuracy: 0.7990\n",
      "Epoch 00061: val_accuracy improved from 0.78650 to 0.78900, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6050 - accuracy: 0.7991 - val_loss: 0.6726 - val_accuracy: 0.7890\n",
      "Epoch 62/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6067 - accuracy: 0.7993\n",
      "Epoch 00062: val_accuracy did not improve from 0.78900\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6064 - accuracy: 0.7995 - val_loss: 0.6997 - val_accuracy: 0.7799\n",
      "Epoch 63/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6030 - accuracy: 0.7995\n",
      "Epoch 00063: val_accuracy did not improve from 0.78900\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6039 - accuracy: 0.7994 - val_loss: 0.8207 - val_accuracy: 0.7814\n",
      "Epoch 64/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6052 - accuracy: 0.8001\n",
      "Epoch 00064: val_accuracy did not improve from 0.78900\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6050 - accuracy: 0.8002 - val_loss: 0.6700 - val_accuracy: 0.7831\n",
      "Epoch 65/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6072 - accuracy: 0.7988\n",
      "Epoch 00065: val_accuracy did not improve from 0.78900\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6066 - accuracy: 0.7990 - val_loss: 0.6715 - val_accuracy: 0.7873\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6010 - accuracy: 0.7988\n",
      "Epoch 00066: val_accuracy did not improve from 0.78900\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6010 - accuracy: 0.7988 - val_loss: 0.6603 - val_accuracy: 0.7883\n",
      "Epoch 67/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.5987 - accuracy: 0.8023\n",
      "Epoch 00067: val_accuracy did not improve from 0.78900\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5992 - accuracy: 0.8022 - val_loss: 0.7011 - val_accuracy: 0.7876\n",
      "Epoch 68/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6025 - accuracy: 0.8025\n",
      "Epoch 00068: val_accuracy improved from 0.78900 to 0.79120, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.6028 - accuracy: 0.8024 - val_loss: 0.7011 - val_accuracy: 0.7912\n",
      "Epoch 69/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6011 - accuracy: 0.8028\n",
      "Epoch 00069: val_accuracy did not improve from 0.79120\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6020 - accuracy: 0.8026 - val_loss: 0.6786 - val_accuracy: 0.7868\n",
      "Epoch 70/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.5961 - accuracy: 0.8023\n",
      "Epoch 00070: val_accuracy did not improve from 0.79120\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5960 - accuracy: 0.8023 - val_loss: 0.7201 - val_accuracy: 0.7885\n",
      "Epoch 71/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.5987 - accuracy: 0.8000\n",
      "Epoch 00071: val_accuracy did not improve from 0.79120\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.5987 - accuracy: 0.7998 - val_loss: 0.7064 - val_accuracy: 0.7761\n",
      "Epoch 72/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6022 - accuracy: 0.8016\n",
      "Epoch 00072: val_accuracy did not improve from 0.79120\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6022 - accuracy: 0.8016 - val_loss: 0.6624 - val_accuracy: 0.7881\n",
      "Epoch 73/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.5963 - accuracy: 0.8032\n",
      "Epoch 00073: val_accuracy improved from 0.79120 to 0.79230, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5961 - accuracy: 0.8034 - val_loss: 0.6588 - val_accuracy: 0.7923\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.8048\n",
      "Epoch 00074: val_accuracy did not improve from 0.79230\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5956 - accuracy: 0.8048 - val_loss: 0.6714 - val_accuracy: 0.7893\n",
      "Epoch 75/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.5982 - accuracy: 0.8017\n",
      "Epoch 00075: val_accuracy did not improve from 0.79230\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5986 - accuracy: 0.8016 - val_loss: 0.6835 - val_accuracy: 0.7807\n",
      "Epoch 76/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.5967 - accuracy: 0.8029\n",
      "Epoch 00076: val_accuracy did not improve from 0.79230\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5964 - accuracy: 0.8030 - val_loss: 0.7016 - val_accuracy: 0.7836\n",
      "Epoch 77/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.5979 - accuracy: 0.8022\n",
      "Epoch 00077: val_accuracy did not improve from 0.79230\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5977 - accuracy: 0.8023 - val_loss: 0.6745 - val_accuracy: 0.7917\n",
      "Epoch 78/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.5911 - accuracy: 0.8057\n",
      "Epoch 00078: val_accuracy did not improve from 0.79230\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5917 - accuracy: 0.8055 - val_loss: 0.6885 - val_accuracy: 0.7781\n",
      "Epoch 79/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.5954 - accuracy: 0.8044\n",
      "Epoch 00079: val_accuracy did not improve from 0.79230\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5954 - accuracy: 0.8044 - val_loss: 0.7086 - val_accuracy: 0.7789\n",
      "Epoch 80/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.5977 - accuracy: 0.8039\n",
      "Epoch 00080: val_accuracy did not improve from 0.79230\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5975 - accuracy: 0.8039 - val_loss: 0.6855 - val_accuracy: 0.7837\n",
      "Epoch 81/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.5899 - accuracy: 0.8061\n",
      "Epoch 00081: val_accuracy did not improve from 0.79230\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5899 - accuracy: 0.8061 - val_loss: 0.6792 - val_accuracy: 0.7891\n",
      "Epoch 82/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.5979 - accuracy: 0.8065\n",
      "Epoch 00082: val_accuracy did not improve from 0.79230\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5980 - accuracy: 0.8065 - val_loss: 0.6788 - val_accuracy: 0.7847\n",
      "Epoch 83/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.5951 - accuracy: 0.8044\n",
      "Epoch 00083: val_accuracy did not improve from 0.79230\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5953 - accuracy: 0.8044 - val_loss: 0.6926 - val_accuracy: 0.7872\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.5962 - accuracy: 0.8043\n",
      "Epoch 00084: val_accuracy improved from 0.79230 to 0.79630, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.5962 - accuracy: 0.8043 - val_loss: 0.6565 - val_accuracy: 0.7963\n",
      "Epoch 85/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.5921 - accuracy: 0.8068\n",
      "Epoch 00085: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5919 - accuracy: 0.8069 - val_loss: 0.6671 - val_accuracy: 0.7838\n",
      "Epoch 86/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.5964 - accuracy: 0.8034\n",
      "Epoch 00086: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5969 - accuracy: 0.8035 - val_loss: 0.6772 - val_accuracy: 0.7875\n",
      "Epoch 87/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.5922 - accuracy: 0.8046\n",
      "Epoch 00087: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5923 - accuracy: 0.8045 - val_loss: 0.6813 - val_accuracy: 0.7949\n",
      "Epoch 88/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.5901 - accuracy: 0.8044\n",
      "Epoch 00088: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5903 - accuracy: 0.8043 - val_loss: 0.7404 - val_accuracy: 0.7742\n",
      "Epoch 89/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.5896 - accuracy: 0.8068\n",
      "Epoch 00089: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5896 - accuracy: 0.8067 - val_loss: 0.6762 - val_accuracy: 0.7875\n",
      "Epoch 90/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.5922 - accuracy: 0.8059\n",
      "Epoch 00090: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5923 - accuracy: 0.8059 - val_loss: 0.7190 - val_accuracy: 0.7837\n",
      "Epoch 91/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.5850 - accuracy: 0.8089\n",
      "Epoch 00091: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5849 - accuracy: 0.8089 - val_loss: 0.6494 - val_accuracy: 0.7959\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.5918 - accuracy: 0.8051\n",
      "Epoch 00092: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5918 - accuracy: 0.8051 - val_loss: 0.6797 - val_accuracy: 0.7894\n",
      "Epoch 93/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.5957 - accuracy: 0.8052\n",
      "Epoch 00093: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5952 - accuracy: 0.8054 - val_loss: 0.6754 - val_accuracy: 0.7815\n",
      "Epoch 94/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.5897 - accuracy: 0.8066\n",
      "Epoch 00094: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5899 - accuracy: 0.8066 - val_loss: 0.8039 - val_accuracy: 0.7739\n",
      "Epoch 95/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.5894 - accuracy: 0.8066\n",
      "Epoch 00095: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5906 - accuracy: 0.8061 - val_loss: 0.7009 - val_accuracy: 0.7733\n",
      "Epoch 96/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.5911 - accuracy: 0.8076\n",
      "Epoch 00096: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5914 - accuracy: 0.8076 - val_loss: 0.6673 - val_accuracy: 0.7912\n",
      "Epoch 97/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.5896 - accuracy: 0.8073\n",
      "Epoch 00097: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5890 - accuracy: 0.8075 - val_loss: 0.6762 - val_accuracy: 0.7834\n",
      "Epoch 98/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.5890 - accuracy: 0.8091\n",
      "Epoch 00098: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5887 - accuracy: 0.8092 - val_loss: 0.6833 - val_accuracy: 0.7846\n",
      "Epoch 99/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.5868 - accuracy: 0.8074\n",
      "Epoch 00099: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5866 - accuracy: 0.8074 - val_loss: 0.7390 - val_accuracy: 0.7683\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 0.8084\n",
      "Epoch 00100: val_accuracy did not improve from 0.79630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5859 - accuracy: 0.8084 - val_loss: 0.7098 - val_accuracy: 0.7772\n"
     ]
    }
   ],
   "source": [
    "noDO_DA = create_model(dropOut=False, data_augmentation=True, epochs= 100)\n",
    "noDO_noDA = create_model(dropOut=False, data_augmentation=False, epochs=100)\n",
    "DO_DA = create_model(dropOut=True, data_augmentation=True, epochs=100)\n",
    "DO_noDA = create_model(dropOut=True, data_augmentation=False, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1-1hAtp22K62",
    "outputId": "031a2346-6519-4ae7-b0a2-4436c7fd4e54"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6693 - accuracy: 0.7808\n",
      "CNN with Drop Out and with Data Augmentation Test accuracy: 0.7807999849319458\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6404 - accuracy: 0.8120\n",
      "CNN without Drop Out and with Data Augmentation Test accuracy: 0.8119999766349792\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6794 - accuracy: 0.7842\n",
      "CNN with Drop Out and without Data Augmentation Test accuracy: 0.7842000126838684\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8963 - accuracy: 0.7242\n",
      "CNN without Drop Out and without Data Augmentation Test accuracy: 0.7242000102996826\n"
     ]
    }
   ],
   "source": [
    "# Plot training accuracy\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(DO_DA.history['accuracy'])\n",
    "plt.plot(DO_noDA.history['accuracy'])\n",
    "plt.plot(noDO_DA.history['accuracy'])\n",
    "plt.plot(noDO_noDA.history['accuracy'])\n",
    "plt.title('training accuracy')\n",
    "plt.ylabel('training accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Drop Out+Data Augment','Drop Out+No Data Augment','No Drop Out+Data Augment', 'No Drop Out+No Data Augment'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(DO_DA.history['val_accuracy'])\n",
    "plt.plot(DO_noDA.history['val_accuracy'])\n",
    "plt.plot(noDO_DA.history['val_accuracy'])\n",
    "plt.plot(noDO_noDA.history['val_accuracy'])\n",
    "plt.title('validation accuracy')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Drop Out+Data Augment','Drop Out+No Data Augment','No Drop Out+Data Augment', 'No Drop Out+No Data Augment'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the best model saved (i.e., model with best validation accuracy) on the test set\n",
    "\n",
    "scores = load_model('best_model_3_DO_DA_rmsopt_relu').evaluate(x_test, y_test, verbose=1)\n",
    "print('CNN with Drop Out and with Data Augmentation Test accuracy:', scores[1])\n",
    "\n",
    "scores = load_model('best_model_3_noDO_DA_rmsopt_relu').evaluate(x_test, y_test, verbose=1)\n",
    "print('CNN without Drop Out and with Data Augmentation Test accuracy:', scores[1])\n",
    "\n",
    "scores = load_model('best_model_3_DO_noDA_rmsopt_relu').evaluate(x_test, y_test, verbose=1)\n",
    "print('CNN with Drop Out and without Data Augmentation Test accuracy:', scores[1])\n",
    "\n",
    "scores = load_model('best_model_3_noDO_noDA_rmsopt_relu').evaluate(x_test, y_test, verbose=1)\n",
    "print('CNN without Drop Out and without Data Augmentation Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vHMT9_hBefT"
   },
   "source": [
    "### Explanation\n",
    "\n",
    "In training, one sees that without dropout and without data augment the accuracy is the highest. However, in the validation and test set, this combination has the least accuracy in the long run, due to overfitting. \n",
    "\n",
    "In training,using only data augmentation leads to the second highest accuracy, and in the validation and test set, this also has the highest accuracy in the long run. This shows that using data augmentation helps generalize the model well and trains the neural network well.\n",
    "\n",
    "Using only drop out also leads to a good accuracy as shown in the validation graph and test accuracy, as it is a good way to approximate ensemble learning where during each training iteration, a different subnetwork is trained. \n",
    "\n",
    "Next is data augmentation and drop out combination. Since both methods are dealing with overfitting, using both could overly generalize the model, underfit the data and lead to a lesser accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_EefCAdH1Or"
   },
   "source": [
    "# Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "W57BLkKcH3iH",
    "outputId": "8ff5a1ea-b4df-4003-ba9b-0fd46ffc716f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Not using data augmentation.\n",
      "Epoch 1/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.8016 - accuracy: 0.3418\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.46670, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.8011 - accuracy: 0.3421 - val_loss: 1.5264 - val_accuracy: 0.4667\n",
      "Epoch 2/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.4882 - accuracy: 0.4618\n",
      "Epoch 00002: val_accuracy improved from 0.46670 to 0.51670, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4877 - accuracy: 0.4620 - val_loss: 1.3569 - val_accuracy: 0.5167\n",
      "Epoch 3/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.3477 - accuracy: 0.5179\n",
      "Epoch 00003: val_accuracy improved from 0.51670 to 0.56910, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.3476 - accuracy: 0.5179 - val_loss: 1.2356 - val_accuracy: 0.5691\n",
      "Epoch 4/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.2433 - accuracy: 0.5539\n",
      "Epoch 00004: val_accuracy improved from 0.56910 to 0.58730, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.2434 - accuracy: 0.5538 - val_loss: 1.1756 - val_accuracy: 0.5873\n",
      "Epoch 5/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.1670 - accuracy: 0.5858\n",
      "Epoch 00005: val_accuracy improved from 0.58730 to 0.61770, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.1669 - accuracy: 0.5859 - val_loss: 1.0942 - val_accuracy: 0.6177\n",
      "Epoch 6/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.1038 - accuracy: 0.6116\n",
      "Epoch 00006: val_accuracy improved from 0.61770 to 0.64110, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.1034 - accuracy: 0.6116 - val_loss: 1.0194 - val_accuracy: 0.6411\n",
      "Epoch 7/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.0506 - accuracy: 0.6287\n",
      "Epoch 00007: val_accuracy improved from 0.64110 to 0.65590, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.0506 - accuracy: 0.6288 - val_loss: 0.9827 - val_accuracy: 0.6559\n",
      "Epoch 8/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.0133 - accuracy: 0.6435\n",
      "Epoch 00008: val_accuracy improved from 0.65590 to 0.65920, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.0129 - accuracy: 0.6436 - val_loss: 0.9631 - val_accuracy: 0.6592\n",
      "Epoch 9/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.9651 - accuracy: 0.6614\n",
      "Epoch 00009: val_accuracy improved from 0.65920 to 0.66980, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.9651 - accuracy: 0.6617 - val_loss: 0.9636 - val_accuracy: 0.6698\n",
      "Epoch 10/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.9329 - accuracy: 0.6732\n",
      "Epoch 00010: val_accuracy improved from 0.66980 to 0.68840, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.9330 - accuracy: 0.6731 - val_loss: 0.8917 - val_accuracy: 0.6884\n",
      "Epoch 11/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.8994 - accuracy: 0.6852\n",
      "Epoch 00011: val_accuracy improved from 0.68840 to 0.69060, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.8987 - accuracy: 0.6852 - val_loss: 0.8873 - val_accuracy: 0.6906\n",
      "Epoch 12/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.8710 - accuracy: 0.6955\n",
      "Epoch 00012: val_accuracy improved from 0.69060 to 0.70150, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8708 - accuracy: 0.6956 - val_loss: 0.8596 - val_accuracy: 0.7015\n",
      "Epoch 13/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.8495 - accuracy: 0.7053\n",
      "Epoch 00013: val_accuracy improved from 0.70150 to 0.71010, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.8500 - accuracy: 0.7052 - val_loss: 0.8354 - val_accuracy: 0.7101\n",
      "Epoch 14/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.8262 - accuracy: 0.7138\n",
      "Epoch 00014: val_accuracy improved from 0.71010 to 0.71840, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8261 - accuracy: 0.7138 - val_loss: 0.8106 - val_accuracy: 0.7184\n",
      "Epoch 15/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.8059 - accuracy: 0.7223\n",
      "Epoch 00015: val_accuracy improved from 0.71840 to 0.72660, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8063 - accuracy: 0.7222 - val_loss: 0.7998 - val_accuracy: 0.7266\n",
      "Epoch 16/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.7914 - accuracy: 0.7257\n",
      "Epoch 00016: val_accuracy did not improve from 0.72660\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7914 - accuracy: 0.7258 - val_loss: 0.8150 - val_accuracy: 0.7187\n",
      "Epoch 17/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.7820 - accuracy: 0.7295\n",
      "Epoch 00017: val_accuracy improved from 0.72660 to 0.72790, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.7820 - accuracy: 0.7294 - val_loss: 0.8009 - val_accuracy: 0.7279\n",
      "Epoch 18/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.7671 - accuracy: 0.7371\n",
      "Epoch 00018: val_accuracy improved from 0.72790 to 0.74110, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7672 - accuracy: 0.7372 - val_loss: 0.7648 - val_accuracy: 0.7411\n",
      "Epoch 19/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.7499 - accuracy: 0.7428\n",
      "Epoch 00019: val_accuracy did not improve from 0.74110\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7501 - accuracy: 0.7423 - val_loss: 0.7597 - val_accuracy: 0.7384\n",
      "Epoch 20/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.7404 - accuracy: 0.7462\n",
      "Epoch 00020: val_accuracy improved from 0.74110 to 0.74410, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.7403 - accuracy: 0.7462 - val_loss: 0.7577 - val_accuracy: 0.7441\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7360 - accuracy: 0.7479\n",
      "Epoch 00021: val_accuracy improved from 0.74410 to 0.74480, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7360 - accuracy: 0.7479 - val_loss: 0.7590 - val_accuracy: 0.7448\n",
      "Epoch 22/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7283 - accuracy: 0.7521\n",
      "Epoch 00022: val_accuracy improved from 0.74480 to 0.74690, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7283 - accuracy: 0.7521 - val_loss: 0.7413 - val_accuracy: 0.7469\n",
      "Epoch 23/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.7181 - accuracy: 0.7545\n",
      "Epoch 00023: val_accuracy improved from 0.74690 to 0.75460, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7181 - accuracy: 0.7546 - val_loss: 0.7379 - val_accuracy: 0.7546\n",
      "Epoch 24/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.7077 - accuracy: 0.7613\n",
      "Epoch 00024: val_accuracy improved from 0.75460 to 0.75590, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.7080 - accuracy: 0.7611 - val_loss: 0.7283 - val_accuracy: 0.7559\n",
      "Epoch 25/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.7028 - accuracy: 0.7631\n",
      "Epoch 00025: val_accuracy did not improve from 0.75590\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7038 - accuracy: 0.7628 - val_loss: 0.7508 - val_accuracy: 0.7421\n",
      "Epoch 26/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.6915 - accuracy: 0.7664\n",
      "Epoch 00026: val_accuracy improved from 0.75590 to 0.75690, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6916 - accuracy: 0.7663 - val_loss: 0.7286 - val_accuracy: 0.7569\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6861 - accuracy: 0.7683\n",
      "Epoch 00027: val_accuracy improved from 0.75690 to 0.75710, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6861 - accuracy: 0.7683 - val_loss: 0.7253 - val_accuracy: 0.7571\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6817 - accuracy: 0.7695\n",
      "Epoch 00028: val_accuracy did not improve from 0.75710\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6817 - accuracy: 0.7695 - val_loss: 0.7341 - val_accuracy: 0.7538\n",
      "Epoch 29/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6772 - accuracy: 0.7717\n",
      "Epoch 00029: val_accuracy did not improve from 0.75710\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6785 - accuracy: 0.7713 - val_loss: 0.7588 - val_accuracy: 0.7554\n",
      "Epoch 30/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6712 - accuracy: 0.7738\n",
      "Epoch 00030: val_accuracy improved from 0.75710 to 0.76590, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6716 - accuracy: 0.7736 - val_loss: 0.7075 - val_accuracy: 0.7659\n",
      "Epoch 31/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6671 - accuracy: 0.7756\n",
      "Epoch 00031: val_accuracy did not improve from 0.76590\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6674 - accuracy: 0.7755 - val_loss: 0.7416 - val_accuracy: 0.7495\n",
      "Epoch 32/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6650 - accuracy: 0.7759\n",
      "Epoch 00032: val_accuracy did not improve from 0.76590\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6651 - accuracy: 0.7758 - val_loss: 0.7136 - val_accuracy: 0.7637\n",
      "Epoch 33/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6628 - accuracy: 0.7792\n",
      "Epoch 00033: val_accuracy did not improve from 0.76590\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6628 - accuracy: 0.7793 - val_loss: 0.7073 - val_accuracy: 0.7644\n",
      "Epoch 34/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6540 - accuracy: 0.7800\n",
      "Epoch 00034: val_accuracy improved from 0.76590 to 0.76630, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6539 - accuracy: 0.7801 - val_loss: 0.7054 - val_accuracy: 0.7663\n",
      "Epoch 35/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6535 - accuracy: 0.7825\n",
      "Epoch 00035: val_accuracy did not improve from 0.76630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6530 - accuracy: 0.7825 - val_loss: 0.7023 - val_accuracy: 0.7649\n",
      "Epoch 36/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6450 - accuracy: 0.7835\n",
      "Epoch 00036: val_accuracy did not improve from 0.76630\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6450 - accuracy: 0.7835 - val_loss: 0.7353 - val_accuracy: 0.7626\n",
      "Epoch 37/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6442 - accuracy: 0.7840\n",
      "Epoch 00037: val_accuracy improved from 0.76630 to 0.76950, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6443 - accuracy: 0.7839 - val_loss: 0.7231 - val_accuracy: 0.7695\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6471 - accuracy: 0.7865\n",
      "Epoch 00038: val_accuracy did not improve from 0.76950\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6471 - accuracy: 0.7865 - val_loss: 0.7160 - val_accuracy: 0.7612\n",
      "Epoch 39/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6409 - accuracy: 0.7873\n",
      "Epoch 00039: val_accuracy did not improve from 0.76950\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6409 - accuracy: 0.7873 - val_loss: 0.7226 - val_accuracy: 0.7684\n",
      "Epoch 40/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6386 - accuracy: 0.7885\n",
      "Epoch 00040: val_accuracy did not improve from 0.76950\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6383 - accuracy: 0.7886 - val_loss: 0.7284 - val_accuracy: 0.7618\n",
      "Epoch 41/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6385 - accuracy: 0.7887\n",
      "Epoch 00041: val_accuracy improved from 0.76950 to 0.77110, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6381 - accuracy: 0.7888 - val_loss: 0.6971 - val_accuracy: 0.7711\n",
      "Epoch 42/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6374 - accuracy: 0.7880\n",
      "Epoch 00042: val_accuracy did not improve from 0.77110\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6369 - accuracy: 0.7879 - val_loss: 0.7212 - val_accuracy: 0.7586\n",
      "Epoch 43/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6283 - accuracy: 0.7921\n",
      "Epoch 00043: val_accuracy did not improve from 0.77110\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6279 - accuracy: 0.7923 - val_loss: 0.7409 - val_accuracy: 0.7595\n",
      "Epoch 44/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6332 - accuracy: 0.7923\n",
      "Epoch 00044: val_accuracy did not improve from 0.77110\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6328 - accuracy: 0.7924 - val_loss: 0.7284 - val_accuracy: 0.7600\n",
      "Epoch 45/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6268 - accuracy: 0.7922\n",
      "Epoch 00045: val_accuracy did not improve from 0.77110\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6269 - accuracy: 0.7922 - val_loss: 0.7777 - val_accuracy: 0.7697\n",
      "Epoch 46/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6272 - accuracy: 0.7941\n",
      "Epoch 00046: val_accuracy improved from 0.77110 to 0.77240, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6266 - accuracy: 0.7942 - val_loss: 0.6903 - val_accuracy: 0.7724\n",
      "Epoch 47/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6242 - accuracy: 0.7928\n",
      "Epoch 00047: val_accuracy improved from 0.77240 to 0.77410, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6245 - accuracy: 0.7927 - val_loss: 0.7289 - val_accuracy: 0.7741\n",
      "Epoch 48/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6202 - accuracy: 0.7957\n",
      "Epoch 00048: val_accuracy improved from 0.77410 to 0.77670, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6202 - accuracy: 0.7958 - val_loss: 0.6736 - val_accuracy: 0.7767\n",
      "Epoch 49/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.6186 - accuracy: 0.7961\n",
      "Epoch 00049: val_accuracy improved from 0.77670 to 0.77710, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6190 - accuracy: 0.7961 - val_loss: 0.7011 - val_accuracy: 0.7771\n",
      "Epoch 50/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6179 - accuracy: 0.7977\n",
      "Epoch 00050: val_accuracy did not improve from 0.77710\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6183 - accuracy: 0.7976 - val_loss: 0.7464 - val_accuracy: 0.7721\n",
      "Epoch 51/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6187 - accuracy: 0.7985\n",
      "Epoch 00051: val_accuracy did not improve from 0.77710\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6189 - accuracy: 0.7985 - val_loss: 0.7592 - val_accuracy: 0.7674\n",
      "Epoch 52/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6201 - accuracy: 0.7958\n",
      "Epoch 00052: val_accuracy did not improve from 0.77710\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6203 - accuracy: 0.7958 - val_loss: 0.7615 - val_accuracy: 0.7713\n",
      "Epoch 53/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6179 - accuracy: 0.7961\n",
      "Epoch 00053: val_accuracy improved from 0.77710 to 0.78160, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6169 - accuracy: 0.7965 - val_loss: 0.6799 - val_accuracy: 0.7816\n",
      "Epoch 54/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6177 - accuracy: 0.7998\n",
      "Epoch 00054: val_accuracy did not improve from 0.78160\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6187 - accuracy: 0.7997 - val_loss: 0.7231 - val_accuracy: 0.7765\n",
      "Epoch 55/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6147 - accuracy: 0.8006\n",
      "Epoch 00055: val_accuracy did not improve from 0.78160\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6145 - accuracy: 0.8006 - val_loss: 0.7155 - val_accuracy: 0.7770\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.7997\n",
      "Epoch 00056: val_accuracy did not improve from 0.78160\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6138 - accuracy: 0.7997 - val_loss: 0.7074 - val_accuracy: 0.7748\n",
      "Epoch 57/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6100 - accuracy: 0.7992\n",
      "Epoch 00057: val_accuracy did not improve from 0.78160\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6102 - accuracy: 0.7991 - val_loss: 0.7248 - val_accuracy: 0.7731\n",
      "Epoch 58/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6077 - accuracy: 0.8035\n",
      "Epoch 00058: val_accuracy improved from 0.78160 to 0.78210, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6076 - accuracy: 0.8036 - val_loss: 0.6851 - val_accuracy: 0.7821\n",
      "Epoch 59/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6124 - accuracy: 0.8002\n",
      "Epoch 00059: val_accuracy improved from 0.78210 to 0.78470, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6127 - accuracy: 0.8001 - val_loss: 0.6745 - val_accuracy: 0.7847\n",
      "Epoch 60/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6105 - accuracy: 0.8028\n",
      "Epoch 00060: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6114 - accuracy: 0.8023 - val_loss: 0.7421 - val_accuracy: 0.7788\n",
      "Epoch 61/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6125 - accuracy: 0.7999\n",
      "Epoch 00061: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6120 - accuracy: 0.8002 - val_loss: 0.6904 - val_accuracy: 0.7793\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6087 - accuracy: 0.8018\n",
      "Epoch 00062: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6087 - accuracy: 0.8018 - val_loss: 0.7742 - val_accuracy: 0.7615\n",
      "Epoch 63/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6087 - accuracy: 0.8030\n",
      "Epoch 00063: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6080 - accuracy: 0.8032 - val_loss: 0.7600 - val_accuracy: 0.7765\n",
      "Epoch 64/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6087 - accuracy: 0.8027\n",
      "Epoch 00064: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6091 - accuracy: 0.8026 - val_loss: 0.7391 - val_accuracy: 0.7795\n",
      "Epoch 65/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6075 - accuracy: 0.8003\n",
      "Epoch 00065: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6069 - accuracy: 0.8005 - val_loss: 0.6922 - val_accuracy: 0.7785\n",
      "Epoch 66/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6129 - accuracy: 0.8024\n",
      "Epoch 00066: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6127 - accuracy: 0.8023 - val_loss: 0.6771 - val_accuracy: 0.7815\n",
      "Epoch 67/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.6094 - accuracy: 0.8032\n",
      "Epoch 00067: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6095 - accuracy: 0.8029 - val_loss: 0.7061 - val_accuracy: 0.7757\n",
      "Epoch 68/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6032 - accuracy: 0.8025\n",
      "Epoch 00068: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6033 - accuracy: 0.8024 - val_loss: 0.7436 - val_accuracy: 0.7804\n",
      "Epoch 69/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6019 - accuracy: 0.8052\n",
      "Epoch 00069: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6020 - accuracy: 0.8051 - val_loss: 0.7191 - val_accuracy: 0.7807\n",
      "Epoch 70/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6058 - accuracy: 0.8057\n",
      "Epoch 00070: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6060 - accuracy: 0.8056 - val_loss: 0.7314 - val_accuracy: 0.7808\n",
      "Epoch 71/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6060 - accuracy: 0.8049\n",
      "Epoch 00071: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6062 - accuracy: 0.8049 - val_loss: 0.7810 - val_accuracy: 0.7779\n",
      "Epoch 72/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.5990 - accuracy: 0.8036\n",
      "Epoch 00072: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5992 - accuracy: 0.8035 - val_loss: 0.7795 - val_accuracy: 0.7712\n",
      "Epoch 73/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6040 - accuracy: 0.8041\n",
      "Epoch 00073: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6036 - accuracy: 0.8043 - val_loss: 0.6877 - val_accuracy: 0.7815\n",
      "Epoch 74/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.5951 - accuracy: 0.8062\n",
      "Epoch 00074: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5951 - accuracy: 0.8061 - val_loss: 0.7162 - val_accuracy: 0.7765\n",
      "Epoch 75/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.5989 - accuracy: 0.8039\n",
      "Epoch 00075: val_accuracy did not improve from 0.78470\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5996 - accuracy: 0.8036 - val_loss: 0.8186 - val_accuracy: 0.7761\n",
      "Epoch 76/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6033 - accuracy: 0.8043\n",
      "Epoch 00076: val_accuracy improved from 0.78470 to 0.78840, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6032 - accuracy: 0.8043 - val_loss: 0.6914 - val_accuracy: 0.7884\n",
      "Epoch 77/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.5971 - accuracy: 0.8050\n",
      "Epoch 00077: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5973 - accuracy: 0.8049 - val_loss: 0.7735 - val_accuracy: 0.7547\n",
      "Epoch 78/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.5996 - accuracy: 0.8083\n",
      "Epoch 00078: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6000 - accuracy: 0.8082 - val_loss: 0.7731 - val_accuracy: 0.7747\n",
      "Epoch 79/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6090 - accuracy: 0.8028\n",
      "Epoch 00079: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6088 - accuracy: 0.8028 - val_loss: 0.6974 - val_accuracy: 0.7801\n",
      "Epoch 80/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6003 - accuracy: 0.8025\n",
      "Epoch 00080: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6004 - accuracy: 0.8026 - val_loss: 0.7254 - val_accuracy: 0.7789\n",
      "Epoch 81/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6074 - accuracy: 0.8033\n",
      "Epoch 00081: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6077 - accuracy: 0.8031 - val_loss: 0.7605 - val_accuracy: 0.7669\n",
      "Epoch 82/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.5999 - accuracy: 0.8054\n",
      "Epoch 00082: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6001 - accuracy: 0.8055 - val_loss: 0.7326 - val_accuracy: 0.7811\n",
      "Epoch 83/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6069 - accuracy: 0.8044\n",
      "Epoch 00083: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6072 - accuracy: 0.8044 - val_loss: 0.8143 - val_accuracy: 0.7634\n",
      "Epoch 84/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6013 - accuracy: 0.8075\n",
      "Epoch 00084: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6013 - accuracy: 0.8075 - val_loss: 0.7779 - val_accuracy: 0.7755\n",
      "Epoch 85/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6102 - accuracy: 0.8047\n",
      "Epoch 00085: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6100 - accuracy: 0.8047 - val_loss: 0.7216 - val_accuracy: 0.7661\n",
      "Epoch 86/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6086 - accuracy: 0.8035\n",
      "Epoch 00086: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6083 - accuracy: 0.8036 - val_loss: 0.6916 - val_accuracy: 0.7880\n",
      "Epoch 87/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6045 - accuracy: 0.8043\n",
      "Epoch 00087: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6047 - accuracy: 0.8043 - val_loss: 0.7653 - val_accuracy: 0.7616\n",
      "Epoch 88/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6020 - accuracy: 0.8054\n",
      "Epoch 00088: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6024 - accuracy: 0.8053 - val_loss: 0.6862 - val_accuracy: 0.7883\n",
      "Epoch 89/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6123 - accuracy: 0.8041\n",
      "Epoch 00089: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6120 - accuracy: 0.8041 - val_loss: 0.6987 - val_accuracy: 0.7827\n",
      "Epoch 90/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6058 - accuracy: 0.8034\n",
      "Epoch 00090: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6060 - accuracy: 0.8033 - val_loss: 0.8149 - val_accuracy: 0.7606\n",
      "Epoch 91/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6152 - accuracy: 0.8037\n",
      "Epoch 00091: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6149 - accuracy: 0.8040 - val_loss: 0.8378 - val_accuracy: 0.7634\n",
      "Epoch 92/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6100 - accuracy: 0.8054\n",
      "Epoch 00092: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6101 - accuracy: 0.8055 - val_loss: 0.7335 - val_accuracy: 0.7730\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.8069\n",
      "Epoch 00093: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6071 - accuracy: 0.8069 - val_loss: 0.7264 - val_accuracy: 0.7788\n",
      "Epoch 94/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6105 - accuracy: 0.8030\n",
      "Epoch 00094: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6104 - accuracy: 0.8029 - val_loss: 0.7301 - val_accuracy: 0.7790\n",
      "Epoch 95/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6060 - accuracy: 0.8050\n",
      "Epoch 00095: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6063 - accuracy: 0.8051 - val_loss: 0.7070 - val_accuracy: 0.7801\n",
      "Epoch 96/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6094 - accuracy: 0.8061\n",
      "Epoch 00096: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6095 - accuracy: 0.8060 - val_loss: 0.8344 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.6139 - accuracy: 0.8025\n",
      "Epoch 00097: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6142 - accuracy: 0.8021 - val_loss: 0.6968 - val_accuracy: 0.7795\n",
      "Epoch 98/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6105 - accuracy: 0.8048\n",
      "Epoch 00098: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6102 - accuracy: 0.8049 - val_loss: 0.6913 - val_accuracy: 0.7793\n",
      "Epoch 99/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6120 - accuracy: 0.8041\n",
      "Epoch 00099: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6118 - accuracy: 0.8040 - val_loss: 0.7090 - val_accuracy: 0.7776\n",
      "Epoch 100/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6143 - accuracy: 0.8020\n",
      "Epoch 00100: val_accuracy did not improve from 0.78840\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6138 - accuracy: 0.8021 - val_loss: 0.7373 - val_accuracy: 0.7782\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Not using data augmentation.\n",
      "Epoch 1/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 2.2658 - accuracy: 0.1432\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.21180, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.2648 - accuracy: 0.1437 - val_loss: 2.1167 - val_accuracy: 0.2118\n",
      "Epoch 2/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 2.0376 - accuracy: 0.2479\n",
      "Epoch 00002: val_accuracy improved from 0.21180 to 0.29970, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.0373 - accuracy: 0.2481 - val_loss: 1.9601 - val_accuracy: 0.2997\n",
      "Epoch 3/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.9623 - accuracy: 0.2869\n",
      "Epoch 00003: val_accuracy improved from 0.29970 to 0.32420, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.9621 - accuracy: 0.2871 - val_loss: 1.9061 - val_accuracy: 0.3242\n",
      "Epoch 4/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.9135 - accuracy: 0.3107\n",
      "Epoch 00004: val_accuracy improved from 0.32420 to 0.34600, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.9133 - accuracy: 0.3108 - val_loss: 1.8549 - val_accuracy: 0.3460\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.8589 - accuracy: 0.3320\n",
      "Epoch 00005: val_accuracy improved from 0.34600 to 0.37170, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.8589 - accuracy: 0.3320 - val_loss: 1.7947 - val_accuracy: 0.3717\n",
      "Epoch 6/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.8054 - accuracy: 0.3569\n",
      "Epoch 00006: val_accuracy improved from 0.37170 to 0.38770, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.8052 - accuracy: 0.3568 - val_loss: 1.7390 - val_accuracy: 0.3877\n",
      "Epoch 7/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.7595 - accuracy: 0.3693\n",
      "Epoch 00007: val_accuracy improved from 0.38770 to 0.40370, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.7598 - accuracy: 0.3692 - val_loss: 1.7022 - val_accuracy: 0.4037\n",
      "Epoch 8/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.7232 - accuracy: 0.3825\n",
      "Epoch 00008: val_accuracy improved from 0.40370 to 0.41040, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.7231 - accuracy: 0.3826 - val_loss: 1.6584 - val_accuracy: 0.4104\n",
      "Epoch 9/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.6919 - accuracy: 0.3934\n",
      "Epoch 00009: val_accuracy improved from 0.41040 to 0.42170, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.6922 - accuracy: 0.3934 - val_loss: 1.6265 - val_accuracy: 0.4217\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.6629 - accuracy: 0.4034\n",
      "Epoch 00010: val_accuracy improved from 0.42170 to 0.42320, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.6629 - accuracy: 0.4034 - val_loss: 1.6105 - val_accuracy: 0.4232\n",
      "Epoch 11/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.6421 - accuracy: 0.4098\n",
      "Epoch 00011: val_accuracy improved from 0.42320 to 0.43530, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.6419 - accuracy: 0.4097 - val_loss: 1.5815 - val_accuracy: 0.4353\n",
      "Epoch 12/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.6225 - accuracy: 0.4146\n",
      "Epoch 00012: val_accuracy improved from 0.43530 to 0.44310, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.6224 - accuracy: 0.4147 - val_loss: 1.5651 - val_accuracy: 0.4431\n",
      "Epoch 13/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.5998 - accuracy: 0.4198\n",
      "Epoch 00013: val_accuracy improved from 0.44310 to 0.44690, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.5996 - accuracy: 0.4198 - val_loss: 1.5439 - val_accuracy: 0.4469\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.5876 - accuracy: 0.4263\n",
      "Epoch 00014: val_accuracy improved from 0.44690 to 0.45040, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.5876 - accuracy: 0.4263 - val_loss: 1.5331 - val_accuracy: 0.4504\n",
      "Epoch 15/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.5717 - accuracy: 0.4344\n",
      "Epoch 00015: val_accuracy improved from 0.45040 to 0.45840, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.5713 - accuracy: 0.4347 - val_loss: 1.5170 - val_accuracy: 0.4584\n",
      "Epoch 16/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5602 - accuracy: 0.4367\n",
      "Epoch 00016: val_accuracy improved from 0.45840 to 0.46160, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.5602 - accuracy: 0.4368 - val_loss: 1.5014 - val_accuracy: 0.4616\n",
      "Epoch 17/100\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 1.5498 - accuracy: 0.4398\n",
      "Epoch 00017: val_accuracy improved from 0.46160 to 0.46600, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.5489 - accuracy: 0.4401 - val_loss: 1.4906 - val_accuracy: 0.4660\n",
      "Epoch 18/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.5378 - accuracy: 0.4447\n",
      "Epoch 00018: val_accuracy improved from 0.46600 to 0.47170, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.5369 - accuracy: 0.4448 - val_loss: 1.4761 - val_accuracy: 0.4717\n",
      "Epoch 19/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.5237 - accuracy: 0.4481\n",
      "Epoch 00019: val_accuracy improved from 0.47170 to 0.47930, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.5237 - accuracy: 0.4484 - val_loss: 1.4663 - val_accuracy: 0.4793\n",
      "Epoch 20/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.5164 - accuracy: 0.4523\n",
      "Epoch 00020: val_accuracy improved from 0.47930 to 0.48160, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.5163 - accuracy: 0.4523 - val_loss: 1.4549 - val_accuracy: 0.4816\n",
      "Epoch 21/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.4995 - accuracy: 0.4567\n",
      "Epoch 00021: val_accuracy improved from 0.48160 to 0.48350, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4996 - accuracy: 0.4567 - val_loss: 1.4445 - val_accuracy: 0.4835\n",
      "Epoch 22/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.4944 - accuracy: 0.4587\n",
      "Epoch 00022: val_accuracy improved from 0.48350 to 0.48520, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4947 - accuracy: 0.4587 - val_loss: 1.4372 - val_accuracy: 0.4852\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.4805 - accuracy: 0.4654\n",
      "Epoch 00023: val_accuracy improved from 0.48520 to 0.48540, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4805 - accuracy: 0.4654 - val_loss: 1.4284 - val_accuracy: 0.4854\n",
      "Epoch 24/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.4708 - accuracy: 0.4707\n",
      "Epoch 00024: val_accuracy improved from 0.48540 to 0.49400, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4704 - accuracy: 0.4708 - val_loss: 1.4133 - val_accuracy: 0.4940\n",
      "Epoch 25/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.4613 - accuracy: 0.4719\n",
      "Epoch 00025: val_accuracy improved from 0.49400 to 0.49520, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4613 - accuracy: 0.4717 - val_loss: 1.4065 - val_accuracy: 0.4952\n",
      "Epoch 26/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.4496 - accuracy: 0.4749\n",
      "Epoch 00026: val_accuracy improved from 0.49520 to 0.50440, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4497 - accuracy: 0.4750 - val_loss: 1.3928 - val_accuracy: 0.5044\n",
      "Epoch 27/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.4387 - accuracy: 0.4770\n",
      "Epoch 00027: val_accuracy improved from 0.50440 to 0.50610, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4389 - accuracy: 0.4769 - val_loss: 1.3840 - val_accuracy: 0.5061\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.4298 - accuracy: 0.4813\n",
      "Epoch 00028: val_accuracy improved from 0.50610 to 0.50630, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4298 - accuracy: 0.4813 - val_loss: 1.3838 - val_accuracy: 0.5063\n",
      "Epoch 29/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.4224 - accuracy: 0.4868\n",
      "Epoch 00029: val_accuracy improved from 0.50630 to 0.51390, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4225 - accuracy: 0.4866 - val_loss: 1.3684 - val_accuracy: 0.5139\n",
      "Epoch 30/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.4143 - accuracy: 0.4890\n",
      "Epoch 00030: val_accuracy did not improve from 0.51390\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4138 - accuracy: 0.4891 - val_loss: 1.3594 - val_accuracy: 0.5129\n",
      "Epoch 31/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.4068 - accuracy: 0.4906\n",
      "Epoch 00031: val_accuracy improved from 0.51390 to 0.51970, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4069 - accuracy: 0.4907 - val_loss: 1.3509 - val_accuracy: 0.5197\n",
      "Epoch 32/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.3990 - accuracy: 0.4948\n",
      "Epoch 00032: val_accuracy improved from 0.51970 to 0.52330, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.3990 - accuracy: 0.4949 - val_loss: 1.3432 - val_accuracy: 0.5233\n",
      "Epoch 33/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.3886 - accuracy: 0.4970\n",
      "Epoch 00033: val_accuracy improved from 0.52330 to 0.52350, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.3883 - accuracy: 0.4970 - val_loss: 1.3366 - val_accuracy: 0.5235\n",
      "Epoch 34/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.3818 - accuracy: 0.5014\n",
      "Epoch 00034: val_accuracy improved from 0.52350 to 0.52840, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.3815 - accuracy: 0.5015 - val_loss: 1.3331 - val_accuracy: 0.5284\n",
      "Epoch 35/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.3778 - accuracy: 0.5043\n",
      "Epoch 00035: val_accuracy improved from 0.52840 to 0.53510, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.3775 - accuracy: 0.5045 - val_loss: 1.3197 - val_accuracy: 0.5351\n",
      "Epoch 36/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.3669 - accuracy: 0.5081\n",
      "Epoch 00036: val_accuracy did not improve from 0.53510\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3670 - accuracy: 0.5081 - val_loss: 1.3161 - val_accuracy: 0.5344\n",
      "Epoch 37/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.3621 - accuracy: 0.5064\n",
      "Epoch 00037: val_accuracy improved from 0.53510 to 0.54000, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3622 - accuracy: 0.5064 - val_loss: 1.3072 - val_accuracy: 0.5400\n",
      "Epoch 38/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.3587 - accuracy: 0.5132\n",
      "Epoch 00038: val_accuracy did not improve from 0.54000\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.3585 - accuracy: 0.5134 - val_loss: 1.3047 - val_accuracy: 0.5376\n",
      "Epoch 39/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.3497 - accuracy: 0.5145\n",
      "Epoch 00039: val_accuracy improved from 0.54000 to 0.54430, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.3500 - accuracy: 0.5144 - val_loss: 1.2954 - val_accuracy: 0.5443\n",
      "Epoch 40/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.3448 - accuracy: 0.5161\n",
      "Epoch 00040: val_accuracy improved from 0.54430 to 0.54730, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.3445 - accuracy: 0.5161 - val_loss: 1.2943 - val_accuracy: 0.5473\n",
      "Epoch 41/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.3390 - accuracy: 0.5202\n",
      "Epoch 00041: val_accuracy did not improve from 0.54730\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3391 - accuracy: 0.5202 - val_loss: 1.2872 - val_accuracy: 0.5469\n",
      "Epoch 42/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.3331 - accuracy: 0.5231\n",
      "Epoch 00042: val_accuracy did not improve from 0.54730\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3335 - accuracy: 0.5228 - val_loss: 1.2817 - val_accuracy: 0.5471\n",
      "Epoch 43/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.3325 - accuracy: 0.5216\n",
      "Epoch 00043: val_accuracy improved from 0.54730 to 0.55110, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3326 - accuracy: 0.5214 - val_loss: 1.2787 - val_accuracy: 0.5511\n",
      "Epoch 44/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.3223 - accuracy: 0.5226\n",
      "Epoch 00044: val_accuracy improved from 0.55110 to 0.55450, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.3225 - accuracy: 0.5224 - val_loss: 1.2717 - val_accuracy: 0.5545\n",
      "Epoch 45/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.3175 - accuracy: 0.5267\n",
      "Epoch 00045: val_accuracy improved from 0.55450 to 0.55750, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.3169 - accuracy: 0.5270 - val_loss: 1.2634 - val_accuracy: 0.5575\n",
      "Epoch 46/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.3144 - accuracy: 0.5281\n",
      "Epoch 00046: val_accuracy improved from 0.55750 to 0.55800, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.3142 - accuracy: 0.5282 - val_loss: 1.2608 - val_accuracy: 0.5580\n",
      "Epoch 47/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.3015 - accuracy: 0.5349\n",
      "Epoch 00047: val_accuracy improved from 0.55800 to 0.56250, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.3016 - accuracy: 0.5350 - val_loss: 1.2545 - val_accuracy: 0.5625\n",
      "Epoch 48/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.3006 - accuracy: 0.5338\n",
      "Epoch 00048: val_accuracy did not improve from 0.56250\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.3008 - accuracy: 0.5335 - val_loss: 1.2527 - val_accuracy: 0.5608\n",
      "Epoch 49/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.2957 - accuracy: 0.5366\n",
      "Epoch 00049: val_accuracy did not improve from 0.56250\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2954 - accuracy: 0.5367 - val_loss: 1.2487 - val_accuracy: 0.5623\n",
      "Epoch 50/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.2903 - accuracy: 0.5378\n",
      "Epoch 00050: val_accuracy improved from 0.56250 to 0.56900, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2900 - accuracy: 0.5377 - val_loss: 1.2378 - val_accuracy: 0.5690\n",
      "Epoch 51/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.2849 - accuracy: 0.5405\n",
      "Epoch 00051: val_accuracy did not improve from 0.56900\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2848 - accuracy: 0.5406 - val_loss: 1.2369 - val_accuracy: 0.5686\n",
      "Epoch 52/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.2819 - accuracy: 0.5417\n",
      "Epoch 00052: val_accuracy did not improve from 0.56900\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2819 - accuracy: 0.5416 - val_loss: 1.2363 - val_accuracy: 0.5683\n",
      "Epoch 53/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.2754 - accuracy: 0.5440\n",
      "Epoch 00053: val_accuracy improved from 0.56900 to 0.57080, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2755 - accuracy: 0.5439 - val_loss: 1.2301 - val_accuracy: 0.5708\n",
      "Epoch 54/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.2716 - accuracy: 0.5443\n",
      "Epoch 00054: val_accuracy improved from 0.57080 to 0.57930, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2717 - accuracy: 0.5443 - val_loss: 1.2176 - val_accuracy: 0.5793\n",
      "Epoch 55/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.2695 - accuracy: 0.5450\n",
      "Epoch 00055: val_accuracy did not improve from 0.57930\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2695 - accuracy: 0.5452 - val_loss: 1.2187 - val_accuracy: 0.5767\n",
      "Epoch 56/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.2634 - accuracy: 0.5480\n",
      "Epoch 00056: val_accuracy improved from 0.57930 to 0.58000, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2632 - accuracy: 0.5479 - val_loss: 1.2131 - val_accuracy: 0.5800\n",
      "Epoch 57/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.2588 - accuracy: 0.5516\n",
      "Epoch 00057: val_accuracy improved from 0.58000 to 0.58620, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2586 - accuracy: 0.5516 - val_loss: 1.2080 - val_accuracy: 0.5862\n",
      "Epoch 58/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.2580 - accuracy: 0.5515\n",
      "Epoch 00058: val_accuracy improved from 0.58620 to 0.58690, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2584 - accuracy: 0.5513 - val_loss: 1.2041 - val_accuracy: 0.5869\n",
      "Epoch 59/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.2520 - accuracy: 0.5540\n",
      "Epoch 00059: val_accuracy did not improve from 0.58690\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2521 - accuracy: 0.5537 - val_loss: 1.2060 - val_accuracy: 0.5845\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.2499 - accuracy: 0.5559\n",
      "Epoch 00060: val_accuracy improved from 0.58690 to 0.58990, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2499 - accuracy: 0.5559 - val_loss: 1.1983 - val_accuracy: 0.5899\n",
      "Epoch 61/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.2439 - accuracy: 0.5555\n",
      "Epoch 00061: val_accuracy did not improve from 0.58990\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2438 - accuracy: 0.5556 - val_loss: 1.1966 - val_accuracy: 0.5897\n",
      "Epoch 62/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.2393 - accuracy: 0.5584\n",
      "Epoch 00062: val_accuracy did not improve from 0.58990\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.2394 - accuracy: 0.5584 - val_loss: 1.1930 - val_accuracy: 0.5892\n",
      "Epoch 63/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.2370 - accuracy: 0.5575\n",
      "Epoch 00063: val_accuracy improved from 0.58990 to 0.59410, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.2375 - accuracy: 0.5574 - val_loss: 1.1850 - val_accuracy: 0.5941\n",
      "Epoch 64/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.2316 - accuracy: 0.5637\n",
      "Epoch 00064: val_accuracy improved from 0.59410 to 0.59550, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2315 - accuracy: 0.5637 - val_loss: 1.1801 - val_accuracy: 0.5955\n",
      "Epoch 65/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.2283 - accuracy: 0.5635\n",
      "Epoch 00065: val_accuracy did not improve from 0.59550\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2281 - accuracy: 0.5634 - val_loss: 1.1790 - val_accuracy: 0.5934\n",
      "Epoch 66/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.2237 - accuracy: 0.5659\n",
      "Epoch 00066: val_accuracy improved from 0.59550 to 0.59730, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2237 - accuracy: 0.5661 - val_loss: 1.1738 - val_accuracy: 0.5973\n",
      "Epoch 67/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.2205 - accuracy: 0.5640\n",
      "Epoch 00067: val_accuracy improved from 0.59730 to 0.60050, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2206 - accuracy: 0.5639 - val_loss: 1.1686 - val_accuracy: 0.6005\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.2125 - accuracy: 0.5712\n",
      "Epoch 00068: val_accuracy did not improve from 0.60050\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.2125 - accuracy: 0.5712 - val_loss: 1.1684 - val_accuracy: 0.5981\n",
      "Epoch 69/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.2142 - accuracy: 0.5703\n",
      "Epoch 00069: val_accuracy improved from 0.60050 to 0.60110, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2148 - accuracy: 0.5702 - val_loss: 1.1633 - val_accuracy: 0.6011\n",
      "Epoch 70/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.2094 - accuracy: 0.5694\n",
      "Epoch 00070: val_accuracy improved from 0.60110 to 0.60290, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2095 - accuracy: 0.5694 - val_loss: 1.1607 - val_accuracy: 0.6029\n",
      "Epoch 71/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.2062 - accuracy: 0.5682\n",
      "Epoch 00071: val_accuracy improved from 0.60290 to 0.60400, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2065 - accuracy: 0.5681 - val_loss: 1.1592 - val_accuracy: 0.6040\n",
      "Epoch 72/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.2032 - accuracy: 0.5734\n",
      "Epoch 00072: val_accuracy improved from 0.60400 to 0.60410, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.2032 - accuracy: 0.5733 - val_loss: 1.1549 - val_accuracy: 0.6041\n",
      "Epoch 73/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.1993 - accuracy: 0.5746\n",
      "Epoch 00073: val_accuracy improved from 0.60410 to 0.60540, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1993 - accuracy: 0.5746 - val_loss: 1.1503 - val_accuracy: 0.6054\n",
      "Epoch 74/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.1931 - accuracy: 0.5749\n",
      "Epoch 00074: val_accuracy did not improve from 0.60540\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1932 - accuracy: 0.5749 - val_loss: 1.1541 - val_accuracy: 0.6034\n",
      "Epoch 75/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.1914 - accuracy: 0.5759\n",
      "Epoch 00075: val_accuracy improved from 0.60540 to 0.61220, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1915 - accuracy: 0.5762 - val_loss: 1.1419 - val_accuracy: 0.6122\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.1852 - accuracy: 0.5783\n",
      "Epoch 00076: val_accuracy did not improve from 0.61220\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1852 - accuracy: 0.5783 - val_loss: 1.1375 - val_accuracy: 0.6121\n",
      "Epoch 77/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.1880 - accuracy: 0.5787\n",
      "Epoch 00077: val_accuracy did not improve from 0.61220\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1883 - accuracy: 0.5785 - val_loss: 1.1427 - val_accuracy: 0.6072\n",
      "Epoch 78/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.1803 - accuracy: 0.5836\n",
      "Epoch 00078: val_accuracy improved from 0.61220 to 0.61360, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1802 - accuracy: 0.5838 - val_loss: 1.1336 - val_accuracy: 0.6136\n",
      "Epoch 79/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.1824 - accuracy: 0.5826\n",
      "Epoch 00079: val_accuracy did not improve from 0.61360\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1819 - accuracy: 0.5828 - val_loss: 1.1363 - val_accuracy: 0.6105\n",
      "Epoch 80/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.1728 - accuracy: 0.5855\n",
      "Epoch 00080: val_accuracy did not improve from 0.61360\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1735 - accuracy: 0.5853 - val_loss: 1.1299 - val_accuracy: 0.6126\n",
      "Epoch 81/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.1710 - accuracy: 0.5854\n",
      "Epoch 00081: val_accuracy improved from 0.61360 to 0.61630, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1713 - accuracy: 0.5854 - val_loss: 1.1241 - val_accuracy: 0.6163\n",
      "Epoch 82/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.1670 - accuracy: 0.5865\n",
      "Epoch 00082: val_accuracy did not improve from 0.61630\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1677 - accuracy: 0.5864 - val_loss: 1.1258 - val_accuracy: 0.6141\n",
      "Epoch 83/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.1656 - accuracy: 0.5855\n",
      "Epoch 00083: val_accuracy improved from 0.61630 to 0.61770, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1658 - accuracy: 0.5854 - val_loss: 1.1218 - val_accuracy: 0.6177\n",
      "Epoch 84/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.1646 - accuracy: 0.5885\n",
      "Epoch 00084: val_accuracy improved from 0.61770 to 0.61780, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1643 - accuracy: 0.5885 - val_loss: 1.1179 - val_accuracy: 0.6178\n",
      "Epoch 85/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.1596 - accuracy: 0.5865\n",
      "Epoch 00085: val_accuracy improved from 0.61780 to 0.61950, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1593 - accuracy: 0.5867 - val_loss: 1.1164 - val_accuracy: 0.6195\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.1570 - accuracy: 0.5897\n",
      "Epoch 00086: val_accuracy improved from 0.61950 to 0.62220, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1570 - accuracy: 0.5897 - val_loss: 1.1100 - val_accuracy: 0.6222\n",
      "Epoch 87/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.1527 - accuracy: 0.5920\n",
      "Epoch 00087: val_accuracy did not improve from 0.62220\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1531 - accuracy: 0.5918 - val_loss: 1.1120 - val_accuracy: 0.6193\n",
      "Epoch 88/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.1504 - accuracy: 0.5941\n",
      "Epoch 00088: val_accuracy improved from 0.62220 to 0.62290, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1506 - accuracy: 0.5941 - val_loss: 1.1045 - val_accuracy: 0.6229\n",
      "Epoch 89/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.1493 - accuracy: 0.5906\n",
      "Epoch 00089: val_accuracy did not improve from 0.62290\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1490 - accuracy: 0.5907 - val_loss: 1.1076 - val_accuracy: 0.6193\n",
      "Epoch 90/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.1466 - accuracy: 0.5941\n",
      "Epoch 00090: val_accuracy improved from 0.62290 to 0.62550, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1466 - accuracy: 0.5942 - val_loss: 1.0996 - val_accuracy: 0.6255\n",
      "Epoch 91/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.1429 - accuracy: 0.5959\n",
      "Epoch 00091: val_accuracy did not improve from 0.62550\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1433 - accuracy: 0.5958 - val_loss: 1.1007 - val_accuracy: 0.6239\n",
      "Epoch 92/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.1405 - accuracy: 0.5973\n",
      "Epoch 00092: val_accuracy did not improve from 0.62550\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1406 - accuracy: 0.5973 - val_loss: 1.0987 - val_accuracy: 0.6241\n",
      "Epoch 93/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.1373 - accuracy: 0.6010\n",
      "Epoch 00093: val_accuracy did not improve from 0.62550\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.1379 - accuracy: 0.6008 - val_loss: 1.0938 - val_accuracy: 0.6236\n",
      "Epoch 94/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.1357 - accuracy: 0.5997\n",
      "Epoch 00094: val_accuracy improved from 0.62550 to 0.62740, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1354 - accuracy: 0.5996 - val_loss: 1.0911 - val_accuracy: 0.6274\n",
      "Epoch 95/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.1328 - accuracy: 0.6013\n",
      "Epoch 00095: val_accuracy improved from 0.62740 to 0.62840, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1328 - accuracy: 0.6014 - val_loss: 1.0870 - val_accuracy: 0.6284\n",
      "Epoch 96/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.1309 - accuracy: 0.6012\n",
      "Epoch 00096: val_accuracy improved from 0.62840 to 0.62990, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1313 - accuracy: 0.6010 - val_loss: 1.0833 - val_accuracy: 0.6299\n",
      "Epoch 97/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 1.1266 - accuracy: 0.6039\n",
      "Epoch 00097: val_accuracy improved from 0.62990 to 0.63150, saving model to best_model_3_DO_noDA_adagrad_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adagrad_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1264 - accuracy: 0.6041 - val_loss: 1.0822 - val_accuracy: 0.6315\n",
      "Epoch 98/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 1.1256 - accuracy: 0.6018\n",
      "Epoch 00098: val_accuracy did not improve from 0.63150\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1256 - accuracy: 0.6017 - val_loss: 1.0843 - val_accuracy: 0.6294\n",
      "Epoch 99/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.1196 - accuracy: 0.6046\n",
      "Epoch 00099: val_accuracy did not improve from 0.63150\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1195 - accuracy: 0.6048 - val_loss: 1.0766 - val_accuracy: 0.6311\n",
      "Epoch 100/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.1167 - accuracy: 0.6075\n",
      "Epoch 00100: val_accuracy did not improve from 0.63150\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.1162 - accuracy: 0.6075 - val_loss: 1.0784 - val_accuracy: 0.6292\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Not using data augmentation.\n",
      "Epoch 1/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.5534 - accuracy: 0.4307\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56010, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.5525 - accuracy: 0.4310 - val_loss: 1.2547 - val_accuracy: 0.5601\n",
      "Epoch 2/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.1752 - accuracy: 0.5827\n",
      "Epoch 00002: val_accuracy improved from 0.56010 to 0.65390, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.1743 - accuracy: 0.5827 - val_loss: 0.9950 - val_accuracy: 0.6539\n",
      "Epoch 3/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 1.0248 - accuracy: 0.6356\n",
      "Epoch 00003: val_accuracy improved from 0.65390 to 0.66820, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.0243 - accuracy: 0.6357 - val_loss: 0.9369 - val_accuracy: 0.6682\n",
      "Epoch 4/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.9228 - accuracy: 0.6746\n",
      "Epoch 00004: val_accuracy improved from 0.66820 to 0.71860, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.9225 - accuracy: 0.6747 - val_loss: 0.8096 - val_accuracy: 0.7186\n",
      "Epoch 5/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.8489 - accuracy: 0.7021\n",
      "Epoch 00005: val_accuracy improved from 0.71860 to 0.73010, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.8494 - accuracy: 0.7020 - val_loss: 0.7810 - val_accuracy: 0.7301\n",
      "Epoch 6/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.7875 - accuracy: 0.7239\n",
      "Epoch 00006: val_accuracy did not improve from 0.73010\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.7875 - accuracy: 0.7240 - val_loss: 0.7843 - val_accuracy: 0.7256\n",
      "Epoch 7/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.7310 - accuracy: 0.7438\n",
      "Epoch 00007: val_accuracy improved from 0.73010 to 0.73640, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.7307 - accuracy: 0.7439 - val_loss: 0.7631 - val_accuracy: 0.7364\n",
      "Epoch 8/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6994 - accuracy: 0.7523\n",
      "Epoch 00008: val_accuracy improved from 0.73640 to 0.74160, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6995 - accuracy: 0.7523 - val_loss: 0.7582 - val_accuracy: 0.7416\n",
      "Epoch 9/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6541 - accuracy: 0.7680\n",
      "Epoch 00009: val_accuracy improved from 0.74160 to 0.76010, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6542 - accuracy: 0.7680 - val_loss: 0.7008 - val_accuracy: 0.7601\n",
      "Epoch 10/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6172 - accuracy: 0.7830\n",
      "Epoch 00010: val_accuracy did not improve from 0.76010\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.6169 - accuracy: 0.7831 - val_loss: 0.7215 - val_accuracy: 0.7561\n",
      "Epoch 11/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.5915 - accuracy: 0.7913\n",
      "Epoch 00011: val_accuracy did not improve from 0.76010\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.5923 - accuracy: 0.7910 - val_loss: 0.7045 - val_accuracy: 0.7581\n",
      "Epoch 12/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.5696 - accuracy: 0.7972\n",
      "Epoch 00012: val_accuracy did not improve from 0.76010\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.5688 - accuracy: 0.7976 - val_loss: 0.7380 - val_accuracy: 0.7552\n",
      "Epoch 13/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.5394 - accuracy: 0.8098\n",
      "Epoch 00013: val_accuracy improved from 0.76010 to 0.76510, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.5394 - accuracy: 0.8096 - val_loss: 0.7064 - val_accuracy: 0.7651\n",
      "Epoch 14/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.5243 - accuracy: 0.8155\n",
      "Epoch 00014: val_accuracy improved from 0.76510 to 0.77170, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.5243 - accuracy: 0.8156 - val_loss: 0.6778 - val_accuracy: 0.7717\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.4947 - accuracy: 0.8266\n",
      "Epoch 00015: val_accuracy improved from 0.77170 to 0.77300, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.4947 - accuracy: 0.8266 - val_loss: 0.7005 - val_accuracy: 0.7730\n",
      "Epoch 16/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.4911 - accuracy: 0.8262\n",
      "Epoch 00016: val_accuracy did not improve from 0.77300\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4912 - accuracy: 0.8263 - val_loss: 0.7460 - val_accuracy: 0.7646\n",
      "Epoch 17/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.4658 - accuracy: 0.8332\n",
      "Epoch 00017: val_accuracy improved from 0.77300 to 0.77860, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.4657 - accuracy: 0.8334 - val_loss: 0.6841 - val_accuracy: 0.7786\n",
      "Epoch 18/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.4548 - accuracy: 0.8393\n",
      "Epoch 00018: val_accuracy improved from 0.77860 to 0.78020, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.4550 - accuracy: 0.8392 - val_loss: 0.6859 - val_accuracy: 0.7802\n",
      "Epoch 19/100\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 0.4396 - accuracy: 0.8435\n",
      "Epoch 00019: val_accuracy did not improve from 0.78020\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4395 - accuracy: 0.8436 - val_loss: 0.7192 - val_accuracy: 0.7694\n",
      "Epoch 20/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.4413 - accuracy: 0.8446\n",
      "Epoch 00020: val_accuracy did not improve from 0.78020\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4414 - accuracy: 0.8446 - val_loss: 0.6993 - val_accuracy: 0.7700\n",
      "Epoch 21/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.4175 - accuracy: 0.8532\n",
      "Epoch 00021: val_accuracy did not improve from 0.78020\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4178 - accuracy: 0.8532 - val_loss: 0.7227 - val_accuracy: 0.7744\n",
      "Epoch 22/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.4171 - accuracy: 0.8539\n",
      "Epoch 00022: val_accuracy did not improve from 0.78020\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4170 - accuracy: 0.8540 - val_loss: 0.7200 - val_accuracy: 0.7715\n",
      "Epoch 23/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.4000 - accuracy: 0.8590\n",
      "Epoch 00023: val_accuracy did not improve from 0.78020\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3996 - accuracy: 0.8593 - val_loss: 0.7738 - val_accuracy: 0.7787\n",
      "Epoch 24/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.3927 - accuracy: 0.8624\n",
      "Epoch 00024: val_accuracy did not improve from 0.78020\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3930 - accuracy: 0.8622 - val_loss: 0.7322 - val_accuracy: 0.7767\n",
      "Epoch 25/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.3886 - accuracy: 0.8660\n",
      "Epoch 00025: val_accuracy improved from 0.78020 to 0.78310, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.3886 - accuracy: 0.8660 - val_loss: 0.7109 - val_accuracy: 0.7831\n",
      "Epoch 26/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.3779 - accuracy: 0.8666\n",
      "Epoch 00026: val_accuracy improved from 0.78310 to 0.78340, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.3776 - accuracy: 0.8666 - val_loss: 0.7367 - val_accuracy: 0.7834\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.3721 - accuracy: 0.8683\n",
      "Epoch 00027: val_accuracy did not improve from 0.78340\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3721 - accuracy: 0.8683 - val_loss: 0.7355 - val_accuracy: 0.7801\n",
      "Epoch 28/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.3634 - accuracy: 0.8729\n",
      "Epoch 00028: val_accuracy did not improve from 0.78340\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3641 - accuracy: 0.8726 - val_loss: 0.7230 - val_accuracy: 0.7738\n",
      "Epoch 29/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.3673 - accuracy: 0.8715\n",
      "Epoch 00029: val_accuracy did not improve from 0.78340\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3677 - accuracy: 0.8713 - val_loss: 0.7843 - val_accuracy: 0.7661\n",
      "Epoch 30/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.3489 - accuracy: 0.8775\n",
      "Epoch 00030: val_accuracy did not improve from 0.78340\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3487 - accuracy: 0.8777 - val_loss: 0.7501 - val_accuracy: 0.7825\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.8743\n",
      "Epoch 00031: val_accuracy did not improve from 0.78340\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3605 - accuracy: 0.8743 - val_loss: 0.7305 - val_accuracy: 0.7778\n",
      "Epoch 32/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.3468 - accuracy: 0.8800\n",
      "Epoch 00032: val_accuracy improved from 0.78340 to 0.78430, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.3471 - accuracy: 0.8799 - val_loss: 0.7466 - val_accuracy: 0.7843\n",
      "Epoch 33/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.3425 - accuracy: 0.8808\n",
      "Epoch 00033: val_accuracy did not improve from 0.78430\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3423 - accuracy: 0.8809 - val_loss: 0.7770 - val_accuracy: 0.7817\n",
      "Epoch 34/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.3414 - accuracy: 0.8818\n",
      "Epoch 00034: val_accuracy improved from 0.78430 to 0.78570, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.3412 - accuracy: 0.8819 - val_loss: 0.7464 - val_accuracy: 0.7857\n",
      "Epoch 35/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.3353 - accuracy: 0.8844\n",
      "Epoch 00035: val_accuracy did not improve from 0.78570\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3354 - accuracy: 0.8844 - val_loss: 0.7549 - val_accuracy: 0.7741\n",
      "Epoch 36/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.3324 - accuracy: 0.8861\n",
      "Epoch 00036: val_accuracy did not improve from 0.78570\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3322 - accuracy: 0.8861 - val_loss: 0.7855 - val_accuracy: 0.7802\n",
      "Epoch 37/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.3232 - accuracy: 0.8882\n",
      "Epoch 00037: val_accuracy did not improve from 0.78570\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3233 - accuracy: 0.8882 - val_loss: 0.8037 - val_accuracy: 0.7800\n",
      "Epoch 38/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.3187 - accuracy: 0.8904\n",
      "Epoch 00038: val_accuracy did not improve from 0.78570\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3188 - accuracy: 0.8905 - val_loss: 0.7725 - val_accuracy: 0.7830\n",
      "Epoch 39/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.3140 - accuracy: 0.8932\n",
      "Epoch 00039: val_accuracy did not improve from 0.78570\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3137 - accuracy: 0.8933 - val_loss: 0.7778 - val_accuracy: 0.7855\n",
      "Epoch 40/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.3234 - accuracy: 0.8879\n",
      "Epoch 00040: val_accuracy did not improve from 0.78570\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3231 - accuracy: 0.8881 - val_loss: 0.7846 - val_accuracy: 0.7817\n",
      "Epoch 41/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.3059 - accuracy: 0.8943\n",
      "Epoch 00041: val_accuracy did not improve from 0.78570\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3059 - accuracy: 0.8944 - val_loss: 0.7567 - val_accuracy: 0.7812\n",
      "Epoch 42/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.3105 - accuracy: 0.8940\n",
      "Epoch 00042: val_accuracy did not improve from 0.78570\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3108 - accuracy: 0.8939 - val_loss: 0.8288 - val_accuracy: 0.7815\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.3065 - accuracy: 0.8949\n",
      "Epoch 00043: val_accuracy improved from 0.78570 to 0.78620, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.3065 - accuracy: 0.8949 - val_loss: 0.7846 - val_accuracy: 0.7862\n",
      "Epoch 44/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.3032 - accuracy: 0.8961\n",
      "Epoch 00044: val_accuracy did not improve from 0.78620\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3028 - accuracy: 0.8963 - val_loss: 0.7973 - val_accuracy: 0.7828\n",
      "Epoch 45/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.2989 - accuracy: 0.8966\n",
      "Epoch 00045: val_accuracy did not improve from 0.78620\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2991 - accuracy: 0.8965 - val_loss: 0.8021 - val_accuracy: 0.7831\n",
      "Epoch 46/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.3027 - accuracy: 0.8966\n",
      "Epoch 00046: val_accuracy did not improve from 0.78620\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3024 - accuracy: 0.8968 - val_loss: 0.8024 - val_accuracy: 0.7782\n",
      "Epoch 47/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.2998 - accuracy: 0.8982\n",
      "Epoch 00047: val_accuracy did not improve from 0.78620\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3000 - accuracy: 0.8982 - val_loss: 0.8052 - val_accuracy: 0.7823\n",
      "Epoch 48/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.2845 - accuracy: 0.9031\n",
      "Epoch 00048: val_accuracy did not improve from 0.78620\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2846 - accuracy: 0.9030 - val_loss: 0.8482 - val_accuracy: 0.7779\n",
      "Epoch 49/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.2883 - accuracy: 0.9004\n",
      "Epoch 00049: val_accuracy did not improve from 0.78620\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2887 - accuracy: 0.9003 - val_loss: 0.8134 - val_accuracy: 0.7850\n",
      "Epoch 50/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.2859 - accuracy: 0.9018\n",
      "Epoch 00050: val_accuracy did not improve from 0.78620\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2860 - accuracy: 0.9017 - val_loss: 0.8144 - val_accuracy: 0.7769\n",
      "Epoch 51/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.2916 - accuracy: 0.9012\n",
      "Epoch 00051: val_accuracy improved from 0.78620 to 0.78860, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.2914 - accuracy: 0.9013 - val_loss: 0.8763 - val_accuracy: 0.7886\n",
      "Epoch 52/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.2866 - accuracy: 0.9029\n",
      "Epoch 00052: val_accuracy did not improve from 0.78860\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2867 - accuracy: 0.9028 - val_loss: 0.8201 - val_accuracy: 0.7852\n",
      "Epoch 53/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.2841 - accuracy: 0.9028\n",
      "Epoch 00053: val_accuracy did not improve from 0.78860\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2839 - accuracy: 0.9028 - val_loss: 0.7961 - val_accuracy: 0.7878\n",
      "Epoch 54/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.2721 - accuracy: 0.9082\n",
      "Epoch 00054: val_accuracy did not improve from 0.78860\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2721 - accuracy: 0.9082 - val_loss: 0.8282 - val_accuracy: 0.7825\n",
      "Epoch 55/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.2731 - accuracy: 0.9065\n",
      "Epoch 00055: val_accuracy improved from 0.78860 to 0.78890, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.2731 - accuracy: 0.9064 - val_loss: 0.8312 - val_accuracy: 0.7889\n",
      "Epoch 56/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.2694 - accuracy: 0.9086\n",
      "Epoch 00056: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2697 - accuracy: 0.9085 - val_loss: 0.8179 - val_accuracy: 0.7798\n",
      "Epoch 57/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.2759 - accuracy: 0.9060\n",
      "Epoch 00057: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2760 - accuracy: 0.9060 - val_loss: 0.8561 - val_accuracy: 0.7789\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.2782 - accuracy: 0.9055\n",
      "Epoch 00058: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2782 - accuracy: 0.9055 - val_loss: 0.8192 - val_accuracy: 0.7801\n",
      "Epoch 59/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.2736 - accuracy: 0.9068\n",
      "Epoch 00059: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2736 - accuracy: 0.9068 - val_loss: 0.8146 - val_accuracy: 0.7881\n",
      "Epoch 60/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.2633 - accuracy: 0.9118\n",
      "Epoch 00060: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2640 - accuracy: 0.9115 - val_loss: 0.8434 - val_accuracy: 0.7828\n",
      "Epoch 61/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.2648 - accuracy: 0.9113\n",
      "Epoch 00061: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2646 - accuracy: 0.9114 - val_loss: 0.8872 - val_accuracy: 0.7829\n",
      "Epoch 62/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.2665 - accuracy: 0.9106\n",
      "Epoch 00062: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2663 - accuracy: 0.9106 - val_loss: 0.8481 - val_accuracy: 0.7864\n",
      "Epoch 63/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.2687 - accuracy: 0.9085\n",
      "Epoch 00063: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2686 - accuracy: 0.9085 - val_loss: 0.8506 - val_accuracy: 0.7871\n",
      "Epoch 64/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.2637 - accuracy: 0.9122\n",
      "Epoch 00064: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2641 - accuracy: 0.9122 - val_loss: 0.8496 - val_accuracy: 0.7809\n",
      "Epoch 65/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.2639 - accuracy: 0.9119\n",
      "Epoch 00065: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2639 - accuracy: 0.9119 - val_loss: 0.8189 - val_accuracy: 0.7804\n",
      "Epoch 66/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.2611 - accuracy: 0.9124\n",
      "Epoch 00066: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2614 - accuracy: 0.9124 - val_loss: 0.8384 - val_accuracy: 0.7848\n",
      "Epoch 67/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.2558 - accuracy: 0.9157\n",
      "Epoch 00067: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2557 - accuracy: 0.9157 - val_loss: 0.8341 - val_accuracy: 0.7819\n",
      "Epoch 68/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.2672 - accuracy: 0.9106\n",
      "Epoch 00068: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2670 - accuracy: 0.9105 - val_loss: 0.8486 - val_accuracy: 0.7798\n",
      "Epoch 69/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.2523 - accuracy: 0.9143\n",
      "Epoch 00069: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2526 - accuracy: 0.9141 - val_loss: 0.8766 - val_accuracy: 0.7826\n",
      "Epoch 70/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.2647 - accuracy: 0.9121\n",
      "Epoch 00070: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2647 - accuracy: 0.9122 - val_loss: 0.8919 - val_accuracy: 0.7832\n",
      "Epoch 71/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.2489 - accuracy: 0.9166\n",
      "Epoch 00071: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2492 - accuracy: 0.9165 - val_loss: 0.8493 - val_accuracy: 0.7852\n",
      "Epoch 72/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.2523 - accuracy: 0.9153\n",
      "Epoch 00072: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2522 - accuracy: 0.9154 - val_loss: 0.8683 - val_accuracy: 0.7875\n",
      "Epoch 73/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.2536 - accuracy: 0.9154\n",
      "Epoch 00073: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2539 - accuracy: 0.9154 - val_loss: 0.8814 - val_accuracy: 0.7807\n",
      "Epoch 74/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.2511 - accuracy: 0.9170\n",
      "Epoch 00074: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2511 - accuracy: 0.9169 - val_loss: 0.8450 - val_accuracy: 0.7834\n",
      "Epoch 75/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.2505 - accuracy: 0.9149\n",
      "Epoch 00075: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2507 - accuracy: 0.9149 - val_loss: 0.8496 - val_accuracy: 0.7791\n",
      "Epoch 76/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.2471 - accuracy: 0.9167\n",
      "Epoch 00076: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2468 - accuracy: 0.9168 - val_loss: 0.9225 - val_accuracy: 0.7827\n",
      "Epoch 77/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.2556 - accuracy: 0.9152\n",
      "Epoch 00077: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2558 - accuracy: 0.9151 - val_loss: 0.8860 - val_accuracy: 0.7735\n",
      "Epoch 78/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.2449 - accuracy: 0.9179\n",
      "Epoch 00078: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2448 - accuracy: 0.9178 - val_loss: 0.8645 - val_accuracy: 0.7872\n",
      "Epoch 79/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.2443 - accuracy: 0.9190\n",
      "Epoch 00079: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2445 - accuracy: 0.9188 - val_loss: 0.8975 - val_accuracy: 0.7853\n",
      "Epoch 80/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.2377 - accuracy: 0.9217\n",
      "Epoch 00080: val_accuracy did not improve from 0.78890\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2379 - accuracy: 0.9216 - val_loss: 0.8891 - val_accuracy: 0.7828\n",
      "Epoch 81/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.2467 - accuracy: 0.9189\n",
      "Epoch 00081: val_accuracy improved from 0.78890 to 0.78950, saving model to best_model_3_DO_noDA_adam_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_adam_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.2465 - accuracy: 0.9190 - val_loss: 0.8981 - val_accuracy: 0.7895\n",
      "Epoch 82/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.2482 - accuracy: 0.9187\n",
      "Epoch 00082: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2477 - accuracy: 0.9189 - val_loss: 0.9131 - val_accuracy: 0.7860\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.9209\n",
      "Epoch 00083: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2416 - accuracy: 0.9209 - val_loss: 0.9175 - val_accuracy: 0.7833\n",
      "Epoch 84/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.2409 - accuracy: 0.9202\n",
      "Epoch 00084: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2408 - accuracy: 0.9201 - val_loss: 0.8565 - val_accuracy: 0.7812\n",
      "Epoch 85/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.2383 - accuracy: 0.9194\n",
      "Epoch 00085: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2383 - accuracy: 0.9194 - val_loss: 0.8537 - val_accuracy: 0.7838\n",
      "Epoch 86/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.2373 - accuracy: 0.9216\n",
      "Epoch 00086: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2370 - accuracy: 0.9217 - val_loss: 0.8793 - val_accuracy: 0.7852\n",
      "Epoch 87/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.2408 - accuracy: 0.9193\n",
      "Epoch 00087: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2411 - accuracy: 0.9193 - val_loss: 0.8744 - val_accuracy: 0.7843\n",
      "Epoch 88/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.2363 - accuracy: 0.9223\n",
      "Epoch 00088: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2366 - accuracy: 0.9220 - val_loss: 0.9484 - val_accuracy: 0.7770\n",
      "Epoch 89/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.2414 - accuracy: 0.9192\n",
      "Epoch 00089: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2411 - accuracy: 0.9193 - val_loss: 0.8657 - val_accuracy: 0.7891\n",
      "Epoch 90/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.2361 - accuracy: 0.9214\n",
      "Epoch 00090: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2363 - accuracy: 0.9214 - val_loss: 0.8820 - val_accuracy: 0.7848\n",
      "Epoch 91/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.2405 - accuracy: 0.9205\n",
      "Epoch 00091: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2408 - accuracy: 0.9204 - val_loss: 0.8980 - val_accuracy: 0.7844\n",
      "Epoch 92/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.2362 - accuracy: 0.9224\n",
      "Epoch 00092: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2363 - accuracy: 0.9224 - val_loss: 0.8243 - val_accuracy: 0.7831\n",
      "Epoch 93/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.2341 - accuracy: 0.9244\n",
      "Epoch 00093: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2340 - accuracy: 0.9244 - val_loss: 0.9428 - val_accuracy: 0.7803\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.2376 - accuracy: 0.9215\n",
      "Epoch 00094: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2376 - accuracy: 0.9215 - val_loss: 0.9425 - val_accuracy: 0.7799\n",
      "Epoch 95/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.2313 - accuracy: 0.9241\n",
      "Epoch 00095: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2317 - accuracy: 0.9241 - val_loss: 0.8763 - val_accuracy: 0.7857\n",
      "Epoch 96/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.2303 - accuracy: 0.9250\n",
      "Epoch 00096: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2304 - accuracy: 0.9250 - val_loss: 0.9237 - val_accuracy: 0.7850\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.9208\n",
      "Epoch 00097: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2378 - accuracy: 0.9208 - val_loss: 0.8910 - val_accuracy: 0.7895\n",
      "Epoch 98/100\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9235\n",
      "Epoch 00098: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.2313 - accuracy: 0.9233 - val_loss: 0.8600 - val_accuracy: 0.7856\n",
      "Epoch 99/100\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 0.2268 - accuracy: 0.9259\n",
      "Epoch 00099: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2266 - accuracy: 0.9259 - val_loss: 0.9745 - val_accuracy: 0.7805\n",
      "Epoch 100/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.2225 - accuracy: 0.9274\n",
      "Epoch 00100: val_accuracy did not improve from 0.78950\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.2224 - accuracy: 0.9274 - val_loss: 1.0313 - val_accuracy: 0.7798\n"
     ]
    }
   ],
   "source": [
    "# initiate RMSprop optimizer\n",
    "history_rmsopt = create_model(optName=\"rmsopt\", epochs=100)\n",
    "history_adagrad = create_model(optName=\"adagrad\", epochs=100)\n",
    "history_adam = create_model(optName=\"adam\", epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "Ghhd-BHqfpy1",
    "outputId": "0cb39d5a-56b1-4039-a708-b8ed2a240390"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.7029 - accuracy: 0.7806\n",
      "RMSopt Test accuracy: 0.7806000113487244\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9797 - accuracy: 0.7690\n",
      "Adam Test accuracy: 0.7689999938011169\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0769 - accuracy: 0.6251\n",
      "Adagrad Test accuracy: 0.6251000165939331\n"
     ]
    }
   ],
   "source": [
    "plt.plot(history_rmsopt.history['accuracy'])\n",
    "plt.plot(history_adam.history['accuracy'])\n",
    "plt.plot(history_adagrad.history['accuracy'])\n",
    "plt.title('training accuracy')\n",
    "plt.ylabel('training accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend([\"rmsprop\", \"adam\", \"adagrad\"], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.plot(history_rmsopt.history['val_accuracy'])\n",
    "plt.plot(history_adam.history['val_accuracy'])\n",
    "plt.plot(history_adagrad.history['val_accuracy'])\n",
    "plt.title('validation accuracy')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend([\"rmsprop\", \"adam\", \"adagrad\"], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the best model saved (i.e., model with best validation accuracy) on the test set\n",
    "\n",
    "scores = load_model('best_model_3_DO_noDA_rmsopt_relu').evaluate(x_test, y_test, verbose=1)\n",
    "print('RMSProp Test accuracy:', scores[1])\n",
    "scores = load_model('best_model_3_DO_noDA_adam_relu').evaluate(x_test, y_test, verbose=1)\n",
    "print('Adam Test accuracy:', scores[1])\n",
    "scores = load_model('best_model_3_DO_noDA_adagrad_relu').evaluate(x_test, y_test, verbose=1)\n",
    "print('Adagrad Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bzfn2pRMMbQ0"
   },
   "source": [
    "### Explanation\n",
    "\n",
    "Adagrad has the worst accuracy, this could be due to the fact that learning rates decay too quickly. \n",
    "\n",
    "RmsProp has better accuracy than Adagrad but less accuracy than Adam. This could be due to the fact that RmsProp improves upon the AdaGrad with weighted gradients and reduces its aggressive, monotonically decreasing learning rate. However RmsProp also lacks momentum, which is why it's not as good as Adam.\n",
    "\n",
    "Adam uses the gradient's moving average and takes a step in that direction. This creates more momentum and allows Adam to perform better than both RmsProp and Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCrGz0XBVEck"
   },
   "source": [
    "# Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4xARthXVVGpD",
    "outputId": "f6198a1f-c3f2-4b94-bc3b-cbee1197ee0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,168,362\n",
      "Trainable params: 2,168,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Not using data augmentation.\n",
      "Epoch 1/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 1.8253 - accuracy: 0.3327\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44220, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.8235 - accuracy: 0.3335 - val_loss: 1.5656 - val_accuracy: 0.4422\n",
      "Epoch 2/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.4973 - accuracy: 0.4610\n",
      "Epoch 00002: val_accuracy improved from 0.44220 to 0.51120, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4969 - accuracy: 0.4613 - val_loss: 1.3669 - val_accuracy: 0.5112\n",
      "Epoch 3/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.3424 - accuracy: 0.5215\n",
      "Epoch 00003: val_accuracy improved from 0.51120 to 0.56870, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.3422 - accuracy: 0.5216 - val_loss: 1.2238 - val_accuracy: 0.5687\n",
      "Epoch 4/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.2419 - accuracy: 0.5608\n",
      "Epoch 00004: val_accuracy improved from 0.56870 to 0.59000, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.2418 - accuracy: 0.5609 - val_loss: 1.1634 - val_accuracy: 0.5900\n",
      "Epoch 5/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.1601 - accuracy: 0.5917\n",
      "Epoch 00005: val_accuracy improved from 0.59000 to 0.62620, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.1598 - accuracy: 0.5917 - val_loss: 1.0774 - val_accuracy: 0.6262\n",
      "Epoch 6/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.0994 - accuracy: 0.6125\n",
      "Epoch 00006: val_accuracy improved from 0.62620 to 0.64320, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.0989 - accuracy: 0.6127 - val_loss: 1.0213 - val_accuracy: 0.6432\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.0397 - accuracy: 0.6366\n",
      "Epoch 00007: val_accuracy improved from 0.64320 to 0.66690, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0397 - accuracy: 0.6366 - val_loss: 0.9724 - val_accuracy: 0.6669\n",
      "Epoch 8/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9956 - accuracy: 0.6505\n",
      "Epoch 00008: val_accuracy did not improve from 0.66690\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9955 - accuracy: 0.6506 - val_loss: 0.9932 - val_accuracy: 0.6511\n",
      "Epoch 9/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.9581 - accuracy: 0.6660\n",
      "Epoch 00009: val_accuracy improved from 0.66690 to 0.68800, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.9577 - accuracy: 0.6661 - val_loss: 0.9085 - val_accuracy: 0.6880\n",
      "Epoch 10/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9233 - accuracy: 0.6792\n",
      "Epoch 00010: val_accuracy improved from 0.68800 to 0.69540, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.9232 - accuracy: 0.6793 - val_loss: 0.8786 - val_accuracy: 0.6954\n",
      "Epoch 11/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.8906 - accuracy: 0.6917\n",
      "Epoch 00011: val_accuracy improved from 0.69540 to 0.70180, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8909 - accuracy: 0.6916 - val_loss: 0.8588 - val_accuracy: 0.7018\n",
      "Epoch 12/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.8623 - accuracy: 0.7020\n",
      "Epoch 00012: val_accuracy improved from 0.70180 to 0.71150, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.8628 - accuracy: 0.7020 - val_loss: 0.8304 - val_accuracy: 0.7115\n",
      "Epoch 13/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.8377 - accuracy: 0.7092\n",
      "Epoch 00013: val_accuracy improved from 0.71150 to 0.71900, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8377 - accuracy: 0.7093 - val_loss: 0.8195 - val_accuracy: 0.7190\n",
      "Epoch 14/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.8185 - accuracy: 0.7144\n",
      "Epoch 00014: val_accuracy did not improve from 0.71900\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8187 - accuracy: 0.7142 - val_loss: 0.8108 - val_accuracy: 0.7180\n",
      "Epoch 15/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.8027 - accuracy: 0.7214\n",
      "Epoch 00015: val_accuracy improved from 0.71900 to 0.72870, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.8027 - accuracy: 0.7214 - val_loss: 0.7931 - val_accuracy: 0.7287\n",
      "Epoch 16/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.7885 - accuracy: 0.7286\n",
      "Epoch 00016: val_accuracy improved from 0.72870 to 0.73210, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7889 - accuracy: 0.7284 - val_loss: 0.7982 - val_accuracy: 0.7321\n",
      "Epoch 17/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.7697 - accuracy: 0.7352\n",
      "Epoch 00017: val_accuracy improved from 0.73210 to 0.73570, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.7703 - accuracy: 0.7351 - val_loss: 0.7722 - val_accuracy: 0.7357\n",
      "Epoch 18/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7618 - accuracy: 0.7378\n",
      "Epoch 00018: val_accuracy improved from 0.73570 to 0.73830, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7619 - accuracy: 0.7377 - val_loss: 0.7853 - val_accuracy: 0.7383\n",
      "Epoch 19/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.7489 - accuracy: 0.7436\n",
      "Epoch 00019: val_accuracy improved from 0.73830 to 0.74390, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7487 - accuracy: 0.7437 - val_loss: 0.7658 - val_accuracy: 0.7439\n",
      "Epoch 20/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.7400 - accuracy: 0.7473\n",
      "Epoch 00020: val_accuracy improved from 0.74390 to 0.74520, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7397 - accuracy: 0.7474 - val_loss: 0.7653 - val_accuracy: 0.7452\n",
      "Epoch 21/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.7265 - accuracy: 0.7527\n",
      "Epoch 00021: val_accuracy improved from 0.74520 to 0.74810, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7261 - accuracy: 0.7527 - val_loss: 0.7522 - val_accuracy: 0.7481\n",
      "Epoch 22/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.7181 - accuracy: 0.7544\n",
      "Epoch 00022: val_accuracy improved from 0.74810 to 0.75680, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7182 - accuracy: 0.7545 - val_loss: 0.7295 - val_accuracy: 0.7568\n",
      "Epoch 23/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.7131 - accuracy: 0.7578\n",
      "Epoch 00023: val_accuracy did not improve from 0.75680\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7133 - accuracy: 0.7577 - val_loss: 0.7582 - val_accuracy: 0.7478\n",
      "Epoch 24/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7063 - accuracy: 0.7611\n",
      "Epoch 00024: val_accuracy improved from 0.75680 to 0.75760, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.7061 - accuracy: 0.7612 - val_loss: 0.7302 - val_accuracy: 0.7576\n",
      "Epoch 25/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7041 - accuracy: 0.7605\n",
      "Epoch 00025: val_accuracy did not improve from 0.75760\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7042 - accuracy: 0.7605 - val_loss: 0.7326 - val_accuracy: 0.7548\n",
      "Epoch 26/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6990 - accuracy: 0.7615\n",
      "Epoch 00026: val_accuracy improved from 0.75760 to 0.75920, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6992 - accuracy: 0.7616 - val_loss: 0.7504 - val_accuracy: 0.7592\n",
      "Epoch 27/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6874 - accuracy: 0.7647\n",
      "Epoch 00027: val_accuracy did not improve from 0.75920\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6874 - accuracy: 0.7647 - val_loss: 0.7248 - val_accuracy: 0.7578\n",
      "Epoch 28/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6804 - accuracy: 0.7718\n",
      "Epoch 00028: val_accuracy improved from 0.75920 to 0.75930, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.6808 - accuracy: 0.7717 - val_loss: 0.7323 - val_accuracy: 0.7593\n",
      "Epoch 29/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6768 - accuracy: 0.7706\n",
      "Epoch 00029: val_accuracy improved from 0.75930 to 0.76490, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6766 - accuracy: 0.7707 - val_loss: 0.7056 - val_accuracy: 0.7649\n",
      "Epoch 30/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6723 - accuracy: 0.7736\n",
      "Epoch 00030: val_accuracy did not improve from 0.76490\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6719 - accuracy: 0.7737 - val_loss: 0.7244 - val_accuracy: 0.7533\n",
      "Epoch 31/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6684 - accuracy: 0.7738\n",
      "Epoch 00031: val_accuracy did not improve from 0.76490\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6684 - accuracy: 0.7737 - val_loss: 0.7424 - val_accuracy: 0.7543\n",
      "Epoch 32/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6652 - accuracy: 0.7767\n",
      "Epoch 00032: val_accuracy did not improve from 0.76490\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6651 - accuracy: 0.7768 - val_loss: 0.7230 - val_accuracy: 0.7600\n",
      "Epoch 33/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6619 - accuracy: 0.7787\n",
      "Epoch 00033: val_accuracy improved from 0.76490 to 0.77030, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.6615 - accuracy: 0.7788 - val_loss: 0.6916 - val_accuracy: 0.7703\n",
      "Epoch 34/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6550 - accuracy: 0.7799\n",
      "Epoch 00034: val_accuracy did not improve from 0.77030\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6552 - accuracy: 0.7799 - val_loss: 0.7392 - val_accuracy: 0.7664\n",
      "Epoch 35/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6509 - accuracy: 0.7820\n",
      "Epoch 00035: val_accuracy did not improve from 0.77030\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6511 - accuracy: 0.7819 - val_loss: 0.7203 - val_accuracy: 0.7651\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6483 - accuracy: 0.7833\n",
      "Epoch 00036: val_accuracy did not improve from 0.77030\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6483 - accuracy: 0.7833 - val_loss: 0.7217 - val_accuracy: 0.7663\n",
      "Epoch 37/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6473 - accuracy: 0.7852\n",
      "Epoch 00037: val_accuracy did not improve from 0.77030\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6475 - accuracy: 0.7850 - val_loss: 0.7240 - val_accuracy: 0.7598\n",
      "Epoch 38/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6432 - accuracy: 0.7857\n",
      "Epoch 00038: val_accuracy improved from 0.77030 to 0.77070, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6434 - accuracy: 0.7856 - val_loss: 0.6975 - val_accuracy: 0.7707\n",
      "Epoch 39/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6429 - accuracy: 0.7857\n",
      "Epoch 00039: val_accuracy did not improve from 0.77070\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6430 - accuracy: 0.7859 - val_loss: 0.7256 - val_accuracy: 0.7700\n",
      "Epoch 40/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6402 - accuracy: 0.7878\n",
      "Epoch 00040: val_accuracy did not improve from 0.77070\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6402 - accuracy: 0.7878 - val_loss: 0.7294 - val_accuracy: 0.7625\n",
      "Epoch 41/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6349 - accuracy: 0.7872\n",
      "Epoch 00041: val_accuracy did not improve from 0.77070\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6349 - accuracy: 0.7872 - val_loss: 0.7090 - val_accuracy: 0.7660\n",
      "Epoch 42/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6294 - accuracy: 0.7909\n",
      "Epoch 00042: val_accuracy did not improve from 0.77070\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6291 - accuracy: 0.7910 - val_loss: 0.7158 - val_accuracy: 0.7650\n",
      "Epoch 43/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6322 - accuracy: 0.7878\n",
      "Epoch 00043: val_accuracy did not improve from 0.77070\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6325 - accuracy: 0.7877 - val_loss: 0.7215 - val_accuracy: 0.7664\n",
      "Epoch 44/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6365 - accuracy: 0.7898\n",
      "Epoch 00044: val_accuracy improved from 0.77070 to 0.77350, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6366 - accuracy: 0.7897 - val_loss: 0.7297 - val_accuracy: 0.7735\n",
      "Epoch 45/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6255 - accuracy: 0.7931\n",
      "Epoch 00045: val_accuracy did not improve from 0.77350\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6255 - accuracy: 0.7932 - val_loss: 0.7459 - val_accuracy: 0.7713\n",
      "Epoch 46/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6288 - accuracy: 0.7895\n",
      "Epoch 00046: val_accuracy did not improve from 0.77350\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6288 - accuracy: 0.7897 - val_loss: 0.7469 - val_accuracy: 0.7695\n",
      "Epoch 47/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6284 - accuracy: 0.7910\n",
      "Epoch 00047: val_accuracy improved from 0.77350 to 0.77470, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6284 - accuracy: 0.7908 - val_loss: 0.6913 - val_accuracy: 0.7747\n",
      "Epoch 48/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6229 - accuracy: 0.7918\n",
      "Epoch 00048: val_accuracy improved from 0.77470 to 0.77690, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6228 - accuracy: 0.7919 - val_loss: 0.7083 - val_accuracy: 0.7769\n",
      "Epoch 49/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6243 - accuracy: 0.7940\n",
      "Epoch 00049: val_accuracy did not improve from 0.77690\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6255 - accuracy: 0.7937 - val_loss: 0.7411 - val_accuracy: 0.7648\n",
      "Epoch 50/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6231 - accuracy: 0.7942\n",
      "Epoch 00050: val_accuracy did not improve from 0.77690\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6225 - accuracy: 0.7942 - val_loss: 0.6997 - val_accuracy: 0.7706\n",
      "Epoch 51/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6168 - accuracy: 0.7961\n",
      "Epoch 00051: val_accuracy improved from 0.77690 to 0.77790, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6173 - accuracy: 0.7961 - val_loss: 0.6951 - val_accuracy: 0.7779\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.7959\n",
      "Epoch 00052: val_accuracy did not improve from 0.77790\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6243 - accuracy: 0.7959 - val_loss: 0.7055 - val_accuracy: 0.7777\n",
      "Epoch 53/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6201 - accuracy: 0.7947\n",
      "Epoch 00053: val_accuracy did not improve from 0.77790\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6208 - accuracy: 0.7947 - val_loss: 0.7607 - val_accuracy: 0.7714\n",
      "Epoch 54/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6153 - accuracy: 0.7984\n",
      "Epoch 00054: val_accuracy did not improve from 0.77790\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6153 - accuracy: 0.7984 - val_loss: 0.7219 - val_accuracy: 0.7749\n",
      "Epoch 55/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6237 - accuracy: 0.7942\n",
      "Epoch 00055: val_accuracy improved from 0.77790 to 0.78000, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.6237 - accuracy: 0.7943 - val_loss: 0.6931 - val_accuracy: 0.7800\n",
      "Epoch 56/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6156 - accuracy: 0.7964\n",
      "Epoch 00056: val_accuracy did not improve from 0.78000\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6164 - accuracy: 0.7961 - val_loss: 0.7495 - val_accuracy: 0.7643\n",
      "Epoch 57/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6140 - accuracy: 0.7969\n",
      "Epoch 00057: val_accuracy did not improve from 0.78000\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6137 - accuracy: 0.7969 - val_loss: 0.6984 - val_accuracy: 0.7781\n",
      "Epoch 58/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6127 - accuracy: 0.7993\n",
      "Epoch 00058: val_accuracy did not improve from 0.78000\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6124 - accuracy: 0.7995 - val_loss: 0.7146 - val_accuracy: 0.7720\n",
      "Epoch 59/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6201 - accuracy: 0.7960\n",
      "Epoch 00059: val_accuracy improved from 0.78000 to 0.78090, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6199 - accuracy: 0.7962 - val_loss: 0.6751 - val_accuracy: 0.7809\n",
      "Epoch 60/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.6126 - accuracy: 0.7971\n",
      "Epoch 00060: val_accuracy did not improve from 0.78090\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6127 - accuracy: 0.7971 - val_loss: 0.7047 - val_accuracy: 0.7753\n",
      "Epoch 61/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6111 - accuracy: 0.7995\n",
      "Epoch 00061: val_accuracy did not improve from 0.78090\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6109 - accuracy: 0.7995 - val_loss: 0.7030 - val_accuracy: 0.7768\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.8001\n",
      "Epoch 00062: val_accuracy improved from 0.78090 to 0.78400, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6111 - accuracy: 0.8001 - val_loss: 0.6923 - val_accuracy: 0.7840\n",
      "Epoch 63/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6144 - accuracy: 0.7973\n",
      "Epoch 00063: val_accuracy did not improve from 0.78400\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6145 - accuracy: 0.7972 - val_loss: 0.7538 - val_accuracy: 0.7746\n",
      "Epoch 64/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6121 - accuracy: 0.8006\n",
      "Epoch 00064: val_accuracy did not improve from 0.78400\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6116 - accuracy: 0.8007 - val_loss: 0.7652 - val_accuracy: 0.7703\n",
      "Epoch 65/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6108 - accuracy: 0.7987\n",
      "Epoch 00065: val_accuracy improved from 0.78400 to 0.78410, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6112 - accuracy: 0.7986 - val_loss: 0.7246 - val_accuracy: 0.7841\n",
      "Epoch 66/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6168 - accuracy: 0.7983\n",
      "Epoch 00066: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6170 - accuracy: 0.7983 - val_loss: 0.7998 - val_accuracy: 0.7648\n",
      "Epoch 67/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6107 - accuracy: 0.8017\n",
      "Epoch 00067: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6115 - accuracy: 0.8015 - val_loss: 0.6956 - val_accuracy: 0.7825\n",
      "Epoch 68/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6146 - accuracy: 0.7967\n",
      "Epoch 00068: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6152 - accuracy: 0.7965 - val_loss: 0.7209 - val_accuracy: 0.7756\n",
      "Epoch 69/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6121 - accuracy: 0.7999\n",
      "Epoch 00069: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6120 - accuracy: 0.8000 - val_loss: 0.6983 - val_accuracy: 0.7742\n",
      "Epoch 70/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6108 - accuracy: 0.7996\n",
      "Epoch 00070: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6110 - accuracy: 0.7995 - val_loss: 0.7240 - val_accuracy: 0.7705\n",
      "Epoch 71/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6101 - accuracy: 0.8022\n",
      "Epoch 00071: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6109 - accuracy: 0.8020 - val_loss: 0.7926 - val_accuracy: 0.7686\n",
      "Epoch 72/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6085 - accuracy: 0.8025\n",
      "Epoch 00072: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.6083 - accuracy: 0.8026 - val_loss: 0.7133 - val_accuracy: 0.7679\n",
      "Epoch 73/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6095 - accuracy: 0.8014\n",
      "Epoch 00073: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6096 - accuracy: 0.8013 - val_loss: 0.7326 - val_accuracy: 0.7796\n",
      "Epoch 74/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6095 - accuracy: 0.8006\n",
      "Epoch 00074: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6103 - accuracy: 0.8005 - val_loss: 0.9129 - val_accuracy: 0.7551\n",
      "Epoch 75/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.6064 - accuracy: 0.8030\n",
      "Epoch 00075: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6065 - accuracy: 0.8029 - val_loss: 0.6993 - val_accuracy: 0.7819\n",
      "Epoch 76/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6124 - accuracy: 0.8010\n",
      "Epoch 00076: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6125 - accuracy: 0.8009 - val_loss: 0.7619 - val_accuracy: 0.7664\n",
      "Epoch 77/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6072 - accuracy: 0.8011\n",
      "Epoch 00077: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6070 - accuracy: 0.8012 - val_loss: 0.7515 - val_accuracy: 0.7617\n",
      "Epoch 78/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6076 - accuracy: 0.8031\n",
      "Epoch 00078: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6079 - accuracy: 0.8030 - val_loss: 0.7908 - val_accuracy: 0.7567\n",
      "Epoch 79/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6110 - accuracy: 0.8020\n",
      "Epoch 00079: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6108 - accuracy: 0.8022 - val_loss: 0.7253 - val_accuracy: 0.7807\n",
      "Epoch 80/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6173 - accuracy: 0.7996\n",
      "Epoch 00080: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6171 - accuracy: 0.7996 - val_loss: 0.7119 - val_accuracy: 0.7786\n",
      "Epoch 81/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6122 - accuracy: 0.8016\n",
      "Epoch 00081: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6126 - accuracy: 0.8015 - val_loss: 0.7169 - val_accuracy: 0.7735\n",
      "Epoch 82/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6098 - accuracy: 0.8024\n",
      "Epoch 00082: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6098 - accuracy: 0.8024 - val_loss: 0.7360 - val_accuracy: 0.7764\n",
      "Epoch 83/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.6038 - accuracy: 0.8042\n",
      "Epoch 00083: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6043 - accuracy: 0.8040 - val_loss: 0.6961 - val_accuracy: 0.7824\n",
      "Epoch 84/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6077 - accuracy: 0.8017\n",
      "Epoch 00084: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6082 - accuracy: 0.8017 - val_loss: 0.8825 - val_accuracy: 0.7588\n",
      "Epoch 85/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6119 - accuracy: 0.7989\n",
      "Epoch 00085: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6119 - accuracy: 0.7990 - val_loss: 0.7235 - val_accuracy: 0.7752\n",
      "Epoch 86/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.6122 - accuracy: 0.8007\n",
      "Epoch 00086: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6119 - accuracy: 0.8008 - val_loss: 0.6866 - val_accuracy: 0.7823\n",
      "Epoch 87/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6123 - accuracy: 0.8010\n",
      "Epoch 00087: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6129 - accuracy: 0.8008 - val_loss: 0.9087 - val_accuracy: 0.7656\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6151 - accuracy: 0.8008\n",
      "Epoch 00088: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6151 - accuracy: 0.8008 - val_loss: 0.8677 - val_accuracy: 0.7621\n",
      "Epoch 89/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6149 - accuracy: 0.8015\n",
      "Epoch 00089: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6149 - accuracy: 0.8014 - val_loss: 0.7653 - val_accuracy: 0.7745\n",
      "Epoch 90/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.6186 - accuracy: 0.8003\n",
      "Epoch 00090: val_accuracy did not improve from 0.78410\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6187 - accuracy: 0.8004 - val_loss: 0.7610 - val_accuracy: 0.7705\n",
      "Epoch 91/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6139 - accuracy: 0.8015\n",
      "Epoch 00091: val_accuracy improved from 0.78410 to 0.78510, saving model to best_model_3_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_3_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 0.6132 - accuracy: 0.8018 - val_loss: 0.6772 - val_accuracy: 0.7851\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.6225 - accuracy: 0.7970\n",
      "Epoch 00092: val_accuracy did not improve from 0.78510\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6225 - accuracy: 0.7970 - val_loss: 0.9840 - val_accuracy: 0.7340\n",
      "Epoch 93/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6116 - accuracy: 0.8016\n",
      "Epoch 00093: val_accuracy did not improve from 0.78510\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6116 - accuracy: 0.8015 - val_loss: 0.7449 - val_accuracy: 0.7834\n",
      "Epoch 94/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6187 - accuracy: 0.7992\n",
      "Epoch 00094: val_accuracy did not improve from 0.78510\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6186 - accuracy: 0.7992 - val_loss: 0.7367 - val_accuracy: 0.7762\n",
      "Epoch 95/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6284 - accuracy: 0.7983\n",
      "Epoch 00095: val_accuracy did not improve from 0.78510\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6283 - accuracy: 0.7983 - val_loss: 0.7550 - val_accuracy: 0.7676\n",
      "Epoch 96/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.6190 - accuracy: 0.7986\n",
      "Epoch 00096: val_accuracy did not improve from 0.78510\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6186 - accuracy: 0.7987 - val_loss: 0.7494 - val_accuracy: 0.7655\n",
      "Epoch 97/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6203 - accuracy: 0.8008\n",
      "Epoch 00097: val_accuracy did not improve from 0.78510\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6203 - accuracy: 0.8008 - val_loss: 0.8896 - val_accuracy: 0.7398\n",
      "Epoch 98/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.6192 - accuracy: 0.8001\n",
      "Epoch 00098: val_accuracy did not improve from 0.78510\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6188 - accuracy: 0.8003 - val_loss: 0.7426 - val_accuracy: 0.7784\n",
      "Epoch 99/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.6198 - accuracy: 0.8003\n",
      "Epoch 00099: val_accuracy did not improve from 0.78510\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6198 - accuracy: 0.8002 - val_loss: 0.8105 - val_accuracy: 0.7647\n",
      "Epoch 100/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.6173 - accuracy: 0.8011\n",
      "Epoch 00100: val_accuracy did not improve from 0.78510\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6175 - accuracy: 0.8009 - val_loss: 0.6908 - val_accuracy: 0.7822\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_50 (Conv2D)           (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,156,490\n",
      "Trainable params: 2,156,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Not using data augmentation.\n",
      "Epoch 1/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.8277 - accuracy: 0.3395\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.45350, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.8259 - accuracy: 0.3401 - val_loss: 1.5834 - val_accuracy: 0.4535\n",
      "Epoch 2/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.5341 - accuracy: 0.4475\n",
      "Epoch 00002: val_accuracy improved from 0.45350 to 0.50860, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.5340 - accuracy: 0.4475 - val_loss: 1.4142 - val_accuracy: 0.5086\n",
      "Epoch 3/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.3918 - accuracy: 0.5016\n",
      "Epoch 00003: val_accuracy improved from 0.50860 to 0.54670, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3922 - accuracy: 0.5015 - val_loss: 1.3138 - val_accuracy: 0.5467\n",
      "Epoch 4/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 1.3036 - accuracy: 0.5374\n",
      "Epoch 00004: val_accuracy improved from 0.54670 to 0.58760, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3033 - accuracy: 0.5375 - val_loss: 1.2042 - val_accuracy: 0.5876\n",
      "Epoch 5/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 1.2301 - accuracy: 0.5634\n",
      "Epoch 00005: val_accuracy improved from 0.58760 to 0.59820, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.2295 - accuracy: 0.5635 - val_loss: 1.1553 - val_accuracy: 0.5982\n",
      "Epoch 6/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 1.1700 - accuracy: 0.5881\n",
      "Epoch 00006: val_accuracy improved from 0.59820 to 0.61980, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.1699 - accuracy: 0.5882 - val_loss: 1.1021 - val_accuracy: 0.6198\n",
      "Epoch 7/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 1.1186 - accuracy: 0.6075\n",
      "Epoch 00007: val_accuracy improved from 0.61980 to 0.63290, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.1191 - accuracy: 0.6073 - val_loss: 1.0609 - val_accuracy: 0.6329\n",
      "Epoch 8/100\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 1.0766 - accuracy: 0.6207\n",
      "Epoch 00008: val_accuracy improved from 0.63290 to 0.64510, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0769 - accuracy: 0.6207 - val_loss: 1.0399 - val_accuracy: 0.6451\n",
      "Epoch 9/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 1.0392 - accuracy: 0.6380\n",
      "Epoch 00009: val_accuracy improved from 0.64510 to 0.65950, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0386 - accuracy: 0.6382 - val_loss: 0.9868 - val_accuracy: 0.6595\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.0079 - accuracy: 0.6478\n",
      "Epoch 00010: val_accuracy improved from 0.65950 to 0.66480, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.0079 - accuracy: 0.6478 - val_loss: 0.9689 - val_accuracy: 0.6648\n",
      "Epoch 11/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.9805 - accuracy: 0.6578\n",
      "Epoch 00011: val_accuracy improved from 0.66480 to 0.68070, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9804 - accuracy: 0.6577 - val_loss: 0.9316 - val_accuracy: 0.6807\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.9558 - accuracy: 0.6677\n",
      "Epoch 00012: val_accuracy improved from 0.68070 to 0.68540, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9558 - accuracy: 0.6677 - val_loss: 0.9264 - val_accuracy: 0.6854\n",
      "Epoch 13/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.9345 - accuracy: 0.6772\n",
      "Epoch 00013: val_accuracy improved from 0.68540 to 0.68630, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9341 - accuracy: 0.6775 - val_loss: 0.9223 - val_accuracy: 0.6863\n",
      "Epoch 14/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.9151 - accuracy: 0.6840\n",
      "Epoch 00014: val_accuracy improved from 0.68630 to 0.69490, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.9152 - accuracy: 0.6839 - val_loss: 0.8966 - val_accuracy: 0.6949\n",
      "Epoch 15/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.8994 - accuracy: 0.6888\n",
      "Epoch 00015: val_accuracy improved from 0.69490 to 0.70260, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.8999 - accuracy: 0.6888 - val_loss: 0.8957 - val_accuracy: 0.7026\n",
      "Epoch 16/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.8811 - accuracy: 0.6942\n",
      "Epoch 00016: val_accuracy improved from 0.70260 to 0.70540, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8807 - accuracy: 0.6942 - val_loss: 0.8735 - val_accuracy: 0.7054\n",
      "Epoch 17/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8668 - accuracy: 0.6999\n",
      "Epoch 00017: val_accuracy did not improve from 0.70540\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8666 - accuracy: 0.6999 - val_loss: 0.8678 - val_accuracy: 0.6991\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.8546 - accuracy: 0.7054\n",
      "Epoch 00018: val_accuracy improved from 0.70540 to 0.71030, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8546 - accuracy: 0.7054 - val_loss: 0.8795 - val_accuracy: 0.7103\n",
      "Epoch 19/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.8461 - accuracy: 0.7104\n",
      "Epoch 00019: val_accuracy did not improve from 0.71030\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8457 - accuracy: 0.7106 - val_loss: 0.8605 - val_accuracy: 0.7043\n",
      "Epoch 20/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.8311 - accuracy: 0.7174\n",
      "Epoch 00020: val_accuracy improved from 0.71030 to 0.71190, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8315 - accuracy: 0.7173 - val_loss: 0.8733 - val_accuracy: 0.7119\n",
      "Epoch 21/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.8258 - accuracy: 0.7198\n",
      "Epoch 00021: val_accuracy improved from 0.71190 to 0.71880, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8262 - accuracy: 0.7200 - val_loss: 0.8681 - val_accuracy: 0.7188\n",
      "Epoch 22/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.8142 - accuracy: 0.7241\n",
      "Epoch 00022: val_accuracy improved from 0.71880 to 0.71940, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8139 - accuracy: 0.7242 - val_loss: 0.8308 - val_accuracy: 0.7194\n",
      "Epoch 23/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.8086 - accuracy: 0.7253\n",
      "Epoch 00023: val_accuracy improved from 0.71940 to 0.72110, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8087 - accuracy: 0.7253 - val_loss: 0.8904 - val_accuracy: 0.7211\n",
      "Epoch 24/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.7988 - accuracy: 0.7304\n",
      "Epoch 00024: val_accuracy did not improve from 0.72110\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7988 - accuracy: 0.7305 - val_loss: 0.8915 - val_accuracy: 0.7077\n",
      "Epoch 25/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.8001 - accuracy: 0.7297\n",
      "Epoch 00025: val_accuracy did not improve from 0.72110\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7995 - accuracy: 0.7299 - val_loss: 0.8697 - val_accuracy: 0.7146\n",
      "Epoch 26/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.7886 - accuracy: 0.7338\n",
      "Epoch 00026: val_accuracy improved from 0.72110 to 0.72660, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7890 - accuracy: 0.7336 - val_loss: 0.8683 - val_accuracy: 0.7266\n",
      "Epoch 27/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.7911 - accuracy: 0.7323\n",
      "Epoch 00027: val_accuracy did not improve from 0.72660\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7905 - accuracy: 0.7326 - val_loss: 0.8569 - val_accuracy: 0.7172\n",
      "Epoch 28/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7822 - accuracy: 0.7380\n",
      "Epoch 00028: val_accuracy did not improve from 0.72660\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7823 - accuracy: 0.7378 - val_loss: 0.9045 - val_accuracy: 0.7148\n",
      "Epoch 29/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7790 - accuracy: 0.7398\n",
      "Epoch 00029: val_accuracy did not improve from 0.72660\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7795 - accuracy: 0.7397 - val_loss: 0.9088 - val_accuracy: 0.7094\n",
      "Epoch 30/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.7782 - accuracy: 0.7429\n",
      "Epoch 00030: val_accuracy did not improve from 0.72660\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7784 - accuracy: 0.7428 - val_loss: 0.8787 - val_accuracy: 0.7257\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7724 - accuracy: 0.7427\n",
      "Epoch 00031: val_accuracy improved from 0.72660 to 0.72750, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7724 - accuracy: 0.7427 - val_loss: 0.8836 - val_accuracy: 0.7275\n",
      "Epoch 32/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7700 - accuracy: 0.7415\n",
      "Epoch 00032: val_accuracy did not improve from 0.72750\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7701 - accuracy: 0.7415 - val_loss: 0.8859 - val_accuracy: 0.7221\n",
      "Epoch 33/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.7684 - accuracy: 0.7453\n",
      "Epoch 00033: val_accuracy did not improve from 0.72750\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7684 - accuracy: 0.7452 - val_loss: 0.9608 - val_accuracy: 0.7126\n",
      "Epoch 34/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.7689 - accuracy: 0.7443\n",
      "Epoch 00034: val_accuracy did not improve from 0.72750\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7690 - accuracy: 0.7442 - val_loss: 0.9474 - val_accuracy: 0.7266\n",
      "Epoch 35/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.7629 - accuracy: 0.7476\n",
      "Epoch 00035: val_accuracy did not improve from 0.72750\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7624 - accuracy: 0.7478 - val_loss: 0.9264 - val_accuracy: 0.7174\n",
      "Epoch 36/100\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 0.7532 - accuracy: 0.7508\n",
      "Epoch 00036: val_accuracy improved from 0.72750 to 0.72850, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7543 - accuracy: 0.7503 - val_loss: 1.0199 - val_accuracy: 0.7285\n",
      "Epoch 37/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7600 - accuracy: 0.7465\n",
      "Epoch 00037: val_accuracy did not improve from 0.72850\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7603 - accuracy: 0.7464 - val_loss: 1.0158 - val_accuracy: 0.7248\n",
      "Epoch 38/100\n",
      "1238/1250 [============================>.] - ETA: 0s - loss: 0.7571 - accuracy: 0.7510\n",
      "Epoch 00038: val_accuracy did not improve from 0.72850\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7577 - accuracy: 0.7508 - val_loss: 0.8821 - val_accuracy: 0.7256\n",
      "Epoch 39/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.7577 - accuracy: 0.7510\n",
      "Epoch 00039: val_accuracy did not improve from 0.72850\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7575 - accuracy: 0.7510 - val_loss: 0.8693 - val_accuracy: 0.7281\n",
      "Epoch 40/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.7542 - accuracy: 0.7504\n",
      "Epoch 00040: val_accuracy improved from 0.72850 to 0.72880, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 0.7540 - accuracy: 0.7505 - val_loss: 0.8886 - val_accuracy: 0.7288\n",
      "Epoch 41/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.7590 - accuracy: 0.7515\n",
      "Epoch 00041: val_accuracy did not improve from 0.72880\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7587 - accuracy: 0.7514 - val_loss: 0.9189 - val_accuracy: 0.7281\n",
      "Epoch 42/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.7574 - accuracy: 0.7525\n",
      "Epoch 00042: val_accuracy did not improve from 0.72880\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7569 - accuracy: 0.7525 - val_loss: 0.8557 - val_accuracy: 0.7256\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7531 - accuracy: 0.7512\n",
      "Epoch 00043: val_accuracy did not improve from 0.72880\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7531 - accuracy: 0.7512 - val_loss: 0.9879 - val_accuracy: 0.7099\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7529 - accuracy: 0.7533\n",
      "Epoch 00044: val_accuracy improved from 0.72880 to 0.73330, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7529 - accuracy: 0.7533 - val_loss: 0.9056 - val_accuracy: 0.7333\n",
      "Epoch 45/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.7520 - accuracy: 0.7532\n",
      "Epoch 00045: val_accuracy did not improve from 0.73330\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7514 - accuracy: 0.7533 - val_loss: 1.0232 - val_accuracy: 0.7205\n",
      "Epoch 46/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.7526 - accuracy: 0.7506\n",
      "Epoch 00046: val_accuracy did not improve from 0.73330\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7528 - accuracy: 0.7507 - val_loss: 0.9332 - val_accuracy: 0.7078\n",
      "Epoch 47/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7567 - accuracy: 0.7531\n",
      "Epoch 00047: val_accuracy did not improve from 0.73330\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7567 - accuracy: 0.7531 - val_loss: 0.9478 - val_accuracy: 0.7314\n",
      "Epoch 48/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7519 - accuracy: 0.7546\n",
      "Epoch 00048: val_accuracy improved from 0.73330 to 0.73390, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7519 - accuracy: 0.7545 - val_loss: 0.9060 - val_accuracy: 0.7339\n",
      "Epoch 49/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.7482 - accuracy: 0.7560\n",
      "Epoch 00049: val_accuracy did not improve from 0.73390\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7485 - accuracy: 0.7559 - val_loss: 1.1028 - val_accuracy: 0.7173\n",
      "Epoch 50/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7472 - accuracy: 0.7545\n",
      "Epoch 00050: val_accuracy did not improve from 0.73390\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7468 - accuracy: 0.7546 - val_loss: 0.8673 - val_accuracy: 0.7224\n",
      "Epoch 51/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.7423 - accuracy: 0.7572\n",
      "Epoch 00051: val_accuracy did not improve from 0.73390\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7420 - accuracy: 0.7571 - val_loss: 0.9328 - val_accuracy: 0.7328\n",
      "Epoch 52/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.7481 - accuracy: 0.7561\n",
      "Epoch 00052: val_accuracy did not improve from 0.73390\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7477 - accuracy: 0.7563 - val_loss: 0.9824 - val_accuracy: 0.7202\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7477 - accuracy: 0.7566\n",
      "Epoch 00053: val_accuracy did not improve from 0.73390\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7477 - accuracy: 0.7566 - val_loss: 1.1416 - val_accuracy: 0.7163\n",
      "Epoch 54/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.7382 - accuracy: 0.7595\n",
      "Epoch 00054: val_accuracy did not improve from 0.73390\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7388 - accuracy: 0.7592 - val_loss: 0.9607 - val_accuracy: 0.7305\n",
      "Epoch 55/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7347 - accuracy: 0.7603\n",
      "Epoch 00055: val_accuracy did not improve from 0.73390\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7348 - accuracy: 0.7602 - val_loss: 1.0223 - val_accuracy: 0.6991\n",
      "Epoch 56/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.7410 - accuracy: 0.7579\n",
      "Epoch 00056: val_accuracy did not improve from 0.73390\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7420 - accuracy: 0.7578 - val_loss: 1.0026 - val_accuracy: 0.7194\n",
      "Epoch 57/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7453 - accuracy: 0.7587\n",
      "Epoch 00057: val_accuracy did not improve from 0.73390\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7453 - accuracy: 0.7586 - val_loss: 1.1308 - val_accuracy: 0.6959\n",
      "Epoch 58/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.7381 - accuracy: 0.7606\n",
      "Epoch 00058: val_accuracy did not improve from 0.73390\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7379 - accuracy: 0.7607 - val_loss: 0.9822 - val_accuracy: 0.7276\n",
      "Epoch 59/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.7347 - accuracy: 0.7611\n",
      "Epoch 00059: val_accuracy did not improve from 0.73390\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7350 - accuracy: 0.7610 - val_loss: 0.9086 - val_accuracy: 0.7317\n",
      "Epoch 60/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.7383 - accuracy: 0.7589\n",
      "Epoch 00060: val_accuracy did not improve from 0.73390\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7381 - accuracy: 0.7591 - val_loss: 0.8970 - val_accuracy: 0.7283\n",
      "Epoch 61/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.7367 - accuracy: 0.7599\n",
      "Epoch 00061: val_accuracy improved from 0.73390 to 0.75130, saving model to best_model_5_DO_noDA_rmsopt_relu\n",
      "INFO:tensorflow:Assets written to: best_model_5_DO_noDA_rmsopt_relu/assets\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7364 - accuracy: 0.7600 - val_loss: 0.8499 - val_accuracy: 0.7513\n",
      "Epoch 62/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7436 - accuracy: 0.7581\n",
      "Epoch 00062: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7435 - accuracy: 0.7581 - val_loss: 1.0044 - val_accuracy: 0.7269\n",
      "Epoch 63/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.7427 - accuracy: 0.7572\n",
      "Epoch 00063: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 0.7430 - accuracy: 0.7570 - val_loss: 1.1147 - val_accuracy: 0.7024\n",
      "Epoch 64/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7393 - accuracy: 0.7607\n",
      "Epoch 00064: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7398 - accuracy: 0.7607 - val_loss: 1.1811 - val_accuracy: 0.7061\n",
      "Epoch 65/100\n",
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.7386 - accuracy: 0.7624\n",
      "Epoch 00065: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7383 - accuracy: 0.7625 - val_loss: 0.9646 - val_accuracy: 0.7423\n",
      "Epoch 66/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7385 - accuracy: 0.7594\n",
      "Epoch 00066: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7387 - accuracy: 0.7594 - val_loss: 1.1001 - val_accuracy: 0.7193\n",
      "Epoch 67/100\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.7391 - accuracy: 0.7596\n",
      "Epoch 00067: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7392 - accuracy: 0.7596 - val_loss: 0.9556 - val_accuracy: 0.7396\n",
      "Epoch 68/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.7377 - accuracy: 0.7602\n",
      "Epoch 00068: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7379 - accuracy: 0.7602 - val_loss: 0.8894 - val_accuracy: 0.7312\n",
      "Epoch 69/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.7363 - accuracy: 0.7628\n",
      "Epoch 00069: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7359 - accuracy: 0.7628 - val_loss: 1.1763 - val_accuracy: 0.6928\n",
      "Epoch 70/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.7342 - accuracy: 0.7622\n",
      "Epoch 00070: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7341 - accuracy: 0.7620 - val_loss: 1.0109 - val_accuracy: 0.7317\n",
      "Epoch 71/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7331 - accuracy: 0.7614\n",
      "Epoch 00071: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7332 - accuracy: 0.7614 - val_loss: 0.9303 - val_accuracy: 0.7221\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7408 - accuracy: 0.7614\n",
      "Epoch 00072: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7408 - accuracy: 0.7614 - val_loss: 0.9335 - val_accuracy: 0.7380\n",
      "Epoch 73/100\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 0.7310 - accuracy: 0.7619\n",
      "Epoch 00073: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7297 - accuracy: 0.7624 - val_loss: 0.9068 - val_accuracy: 0.7328\n",
      "Epoch 74/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7352 - accuracy: 0.7627\n",
      "Epoch 00074: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7351 - accuracy: 0.7628 - val_loss: 0.9722 - val_accuracy: 0.7127\n",
      "Epoch 75/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.7297 - accuracy: 0.7638\n",
      "Epoch 00075: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7293 - accuracy: 0.7637 - val_loss: 0.9076 - val_accuracy: 0.7336\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7371 - accuracy: 0.7614\n",
      "Epoch 00076: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7371 - accuracy: 0.7614 - val_loss: 1.3198 - val_accuracy: 0.6967\n",
      "Epoch 77/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.7300 - accuracy: 0.7623\n",
      "Epoch 00077: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7300 - accuracy: 0.7620 - val_loss: 0.9486 - val_accuracy: 0.7338\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7357 - accuracy: 0.7616\n",
      "Epoch 00078: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7357 - accuracy: 0.7616 - val_loss: 1.0760 - val_accuracy: 0.7161\n",
      "Epoch 79/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.7315 - accuracy: 0.7626\n",
      "Epoch 00079: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7306 - accuracy: 0.7630 - val_loss: 0.9459 - val_accuracy: 0.7243\n",
      "Epoch 80/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.7386 - accuracy: 0.7613\n",
      "Epoch 00080: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7385 - accuracy: 0.7614 - val_loss: 0.9895 - val_accuracy: 0.7250\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7396 - accuracy: 0.7627\n",
      "Epoch 00081: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7396 - accuracy: 0.7627 - val_loss: 1.1476 - val_accuracy: 0.7103\n",
      "Epoch 82/100\n",
      "1247/1250 [============================>.] - ETA: 0s - loss: 0.7367 - accuracy: 0.7620\n",
      "Epoch 00082: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7378 - accuracy: 0.7617 - val_loss: 1.1022 - val_accuracy: 0.7123\n",
      "Epoch 83/100\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 0.7321 - accuracy: 0.7615\n",
      "Epoch 00083: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7315 - accuracy: 0.7616 - val_loss: 1.0335 - val_accuracy: 0.7033\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7379 - accuracy: 0.7587\n",
      "Epoch 00084: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7379 - accuracy: 0.7587 - val_loss: 1.1917 - val_accuracy: 0.6753\n",
      "Epoch 85/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7328 - accuracy: 0.7642\n",
      "Epoch 00085: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7327 - accuracy: 0.7643 - val_loss: 0.9661 - val_accuracy: 0.7254\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.7339 - accuracy: 0.7636\n",
      "Epoch 00086: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7339 - accuracy: 0.7636 - val_loss: 1.1378 - val_accuracy: 0.6920\n",
      "Epoch 87/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.7337 - accuracy: 0.7629\n",
      "Epoch 00087: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7333 - accuracy: 0.7631 - val_loss: 1.1598 - val_accuracy: 0.6864\n",
      "Epoch 88/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7265 - accuracy: 0.7661\n",
      "Epoch 00088: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7263 - accuracy: 0.7660 - val_loss: 1.0271 - val_accuracy: 0.7018\n",
      "Epoch 89/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.7363 - accuracy: 0.7602\n",
      "Epoch 00089: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7353 - accuracy: 0.7607 - val_loss: 1.1171 - val_accuracy: 0.7012\n",
      "Epoch 90/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7414 - accuracy: 0.7603\n",
      "Epoch 00090: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7412 - accuracy: 0.7604 - val_loss: 0.9214 - val_accuracy: 0.7313\n",
      "Epoch 91/100\n",
      "1244/1250 [============================>.] - ETA: 0s - loss: 0.7341 - accuracy: 0.7636\n",
      "Epoch 00091: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7344 - accuracy: 0.7635 - val_loss: 1.0401 - val_accuracy: 0.7157\n",
      "Epoch 92/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7316 - accuracy: 0.7635\n",
      "Epoch 00092: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7318 - accuracy: 0.7635 - val_loss: 1.0029 - val_accuracy: 0.7258\n",
      "Epoch 93/100\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7267 - accuracy: 0.7670\n",
      "Epoch 00093: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7264 - accuracy: 0.7671 - val_loss: 0.9615 - val_accuracy: 0.7100\n",
      "Epoch 94/100\n",
      "1246/1250 [============================>.] - ETA: 0s - loss: 0.7391 - accuracy: 0.7615\n",
      "Epoch 00094: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7394 - accuracy: 0.7613 - val_loss: 0.9545 - val_accuracy: 0.7196\n",
      "Epoch 95/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.7320 - accuracy: 0.7657\n",
      "Epoch 00095: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7329 - accuracy: 0.7656 - val_loss: 1.1741 - val_accuracy: 0.6707\n",
      "Epoch 96/100\n",
      "1241/1250 [============================>.] - ETA: 0s - loss: 0.7300 - accuracy: 0.7643\n",
      "Epoch 00096: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7295 - accuracy: 0.7643 - val_loss: 1.0136 - val_accuracy: 0.6982\n",
      "Epoch 97/100\n",
      "1242/1250 [============================>.] - ETA: 0s - loss: 0.7298 - accuracy: 0.7623\n",
      "Epoch 00097: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7303 - accuracy: 0.7620 - val_loss: 1.2409 - val_accuracy: 0.6737\n",
      "Epoch 98/100\n",
      "1240/1250 [============================>.] - ETA: 0s - loss: 0.7360 - accuracy: 0.7633\n",
      "Epoch 00098: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7361 - accuracy: 0.7632 - val_loss: 1.1174 - val_accuracy: 0.6943\n",
      "Epoch 99/100\n",
      "1239/1250 [============================>.] - ETA: 0s - loss: 0.7261 - accuracy: 0.7669\n",
      "Epoch 00099: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7271 - accuracy: 0.7664 - val_loss: 1.0075 - val_accuracy: 0.6806\n",
      "Epoch 100/100\n",
      "1243/1250 [============================>.] - ETA: 0s - loss: 0.7350 - accuracy: 0.7646\n",
      "Epoch 00100: val_accuracy did not improve from 0.75130\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7346 - accuracy: 0.7646 - val_loss: 1.0154 - val_accuracy: 0.7223\n"
     ]
    }
   ],
   "source": [
    "history3x3 = create_model(size=3, epochs=100)\n",
    "history5x5 = create_model(size=5, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "hMqHfcn4WBv_",
    "outputId": "e8c2267c-ca40-40be-fddd-19696bc8c4a1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.7818\n",
      "CNN with 3X3 Test accuracy: 0.7817999720573425\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8558 - accuracy: 0.7369\n",
      "CNN with 5X5 Test accuracy: 0.7368999719619751\n"
     ]
    }
   ],
   "source": [
    "# Plot training accuracy\n",
    "plt.plot(history3x3.history['accuracy'])\n",
    "plt.plot(history5x5.history['accuracy'])\n",
    "plt.title('training accuracy')\n",
    "plt.ylabel('training accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['3x3', '5x5'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.plot(history3x3.history['val_accuracy'])\n",
    "plt.plot(history5x5.history['val_accuracy'])\n",
    "plt.title('validation accuracy')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['3x3', '5x5'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the best model saved (i.e., model with best validation accuracy) on the test set\n",
    "saved_model = load_model('best_model_3_DO_noDA_rmsopt_relu')\n",
    "scores = saved_model.evaluate(x_test, y_test, verbose=1)\n",
    "print('CNN with 3X3 Test accuracy:', scores[1])\n",
    "scores = load_model('best_model_5_DO_noDA_rmsopt_relu').evaluate(x_test, y_test, verbose=1)\n",
    "print('CNN with 5X5 Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4gOnoAMJWZ0"
   },
   "source": [
    "### Explanation\n",
    "\n",
    "The graph shows that the 3x3 filters with more layers better accuracy than 5x5 filters with less layers in both training and validation. \n",
    "\n",
    "The 3x3 filters have more layers, which makes the network deeper. In general, deeper networks are more expressive and gives better accuracy as they are able to learn from hierarchical features.  At the same time, the graph results could mean that the smaller and more local features could differentiate the images better.\n",
    "\n",
    "In lecture 15, we learned that stacks of small filters is often preferred to a single large filter. This is because smaller filters have fewer parameters which makes it more computationally efficient. The 3x3 has 18 parameters to train while the 5x5 filter has 25 parameters to train, so the 3x3 filters is also more computationally efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBwi4WWzZZX7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cs480_fall20_asst4_cnn_cifar10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
